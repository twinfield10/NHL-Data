{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NHL Expected Goals Model\n",
    "\n",
    "This notebook will look to create a predictive model using xGBoost to predict the liklihood of a goal occuring on a shot. Using data from 10 NHL seasons, I will look to emulate EvolvingWild's xGoal model using Polars and Pandas (rather than R). I want to give them full credit for the idea of building this model. Their model was built out in R and I wanted to better my skills using Polars, Pandas, and Python using their methodology. I also want to credit Evolving Wild with their incredible ability to pique my interest in building a model of this sort as they are wonderful content creators and ask/answer great questions from the NHL analytic community. The methodology of building this model is heavily based on thier methodology (with some additions from myself) and I do not want to take credit for their work without seriously crediting them. This notebook is essentially a way for me to better my skills in different languages and should be considered a translation of their model from R into Python.\n",
    "\n",
    "\n",
    "Please read their fantastic article [here](https://evolving-hockey.com/blog/a-new-expected-goals-model-for-predicting-goals-in-the-nhl/) to learn more about their methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "\n",
    "# Polars\n",
    "import polars as pl\n",
    "pl.Config.set_tbl_rows(n=-1)\n",
    "pl.Config.set_tbl_cols(n=-1)\n",
    "\n",
    "\n",
    "# General\n",
    "from math import pi\n",
    "import time\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, precision_recall_fscore_support, mean_squared_error, accuracy_score, roc_curve, roc_auc_score, auc, make_scorer, precision_score, recall_score, log_loss, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# HyperTuning\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Save\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load NHL Play By Play Data\n",
    "\n",
    "Here, I will create 3 functions to help clean and tweak play-by-play data that will be sourced from the NHL API and loaded as a Polars DF with the help of SportsDataVerse. Learn more about SportsDataVerse [here](https://sportsdataverse-py.sportsdataverse.org/docs/nhl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *a) Identify Constants (Keys for Events, Game States and Rosters)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Event Type Classification ###\n",
    "xG_Events = ['GOAL', 'SHOT', 'MISSED_SHOT', 'BLOCKED_SHOT', 'FACEOFF', 'TAKEAWAY', 'GIVEAWAY', 'HIT']\n",
    "fenwick_events = ['SHOT', 'GOAL', 'MISSED_SHOT']\n",
    "corsi_events = ['SHOT', 'GOAL', 'MISSED_SHOT', 'BLOCKED_SHOT']\n",
    "\n",
    "# Strength States\n",
    "EV_STR_Codes = ['5v5', '4v4', '3v3']\n",
    "PP_STR_Codes = [\"5v4\", \"4v5\", \"5v3\", \"3v5\", \"4v3\", \"3v4\"]\n",
    "UE_STR_Codes = [\"5v4\", \"4v5\", \"5v3\", \"3v5\", \"4v3\", \"3v4\", \"5vE\", \"Ev5\", \"4vE\", \"Ev4\", \"3vE\", \"Ev3\"]\n",
    "SH_STR_Codes = ['5v6', '4v5', '3v4', '4v6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Rosters\n",
    "roster_file = 'https://raw.githubusercontent.com/twinfield10/NHL-Data/main/Rosters/parquet/all/NHL_Roster_AllSeasons_Slim.parquet'\n",
    "ROSTER_DF_RAW = pl.read_parquet(roster_file)\n",
    "ROSTER_DF = (\n",
    "    ROSTER_DF_RAW\n",
    "    .rename({\"player_id\": \"event_player_1_id\"})\n",
    "    .with_columns([\n",
    "        pl.col(\"event_player_1_id\").cast(pl.Utf8),\n",
    "        pl.when((pl.col('pos_F') == 0) & (pl.col('pos_G') == 0)).then(pl.lit(1)).otherwise(pl.lit(0)).alias('pos_D')\n",
    "        ])\n",
    "    .select(['event_player_1_id', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G'])\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# Create Goalie DF\n",
    "GOALIES = (\n",
    "    ROSTER_DF_RAW\n",
    "    .filter(pl.col('pos_G') == 1)\n",
    "    .with_columns([pl.col(\"player_id\").cast(pl.Utf8)])\n",
    "    .select('player_id','hand_R', 'hand_L')\n",
    ")\n",
    "GOALIES.columns = ['event_goalie_id', 'G_hand_R', 'G_hand_L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_goalie_id</th><th>G_hand_R</th><th>G_hand_L</th></tr><tr><td>str</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>&quot;8480591&quot;</td><td>0</td><td>1</td></tr><tr><td>&quot;8471403&quot;</td><td>0</td><td>1</td></tr><tr><td>&quot;8460704&quot;</td><td>0</td><td>1</td></tr><tr><td>&quot;8474682&quot;</td><td>0</td><td>1</td></tr><tr><td>&quot;8475622&quot;</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────┬──────────┬──────────┐\n",
       "│ event_goalie_id ┆ G_hand_R ┆ G_hand_L │\n",
       "│ ---             ┆ ---      ┆ ---      │\n",
       "│ str             ┆ i32      ┆ i32      │\n",
       "╞═════════════════╪══════════╪══════════╡\n",
       "│ 8480591         ┆ 0        ┆ 1        │\n",
       "│ 8471403         ┆ 0        ┆ 1        │\n",
       "│ 8460704         ┆ 0        ┆ 1        │\n",
       "│ 8474682         ┆ 0        ┆ 1        │\n",
       "│ 8475622         ┆ 0        ┆ 1        │\n",
       "└─────────────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOALIES.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *b) Function: Spatial Normalization and Feature Creation*\n",
    "\n",
    "- First, I want to clean some of the spatial data. NHL API uses \"x_fixed\" and \"y_fixed\" to locate events.\n",
    "    - x_fixed and y_fixed are cooridates that are \"fixed\" from perspective of the home team.\n",
    "    - Since this is an expected goals model, I want the frame of reference to e the location of the event from how far away the event is from the goal of the attacking taem.\n",
    "- Then I continue to clean and create metrics for the shot distance and angle.\n",
    "- I also add in some clean classifications for which zone the events occured in\n",
    "- Finally, we classify penalty shots as their own \"game state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pbp_data(data):\n",
    "    \"\"\" This function will use inputs from play-by-play data to build usable features in a model.\n",
    "    Notes:\n",
    "        1) x_fixed and y_fixed are independent of period and remain constant (Home attacking zone is x_fixed > 0 and Away attacking zone is y_fixed < 0)\n",
    "        2) Neutral Zone calculation assumes that x coord is > abs(25). >= abs(25) is considered OZ and DZ\n",
    "    \"\"\"\n",
    "    ### EVENT CALCULATIONS ###\n",
    "\n",
    "    # 1) Create Columns Relative To Event Team\n",
    "    data = data.with_columns([\n",
    "        pl.when(pl.col('event_team_id') == pl.col('away_id')).then(pl.col('away_abbreviation'))\n",
    "          .when(pl.col('event_team_id') == pl.col('home_id')).then(pl.col('home_abbreviation'))\n",
    "          .otherwise(pl.lit(None)).alias('event_team')\n",
    "      ])\n",
    "    # 2) Create Zones Using Coordinates\n",
    "    data = data.with_columns(\n",
    "      [\n",
    "        pl.when(data['x_abs'] >= 25).then(pl.lit('OZ'))\n",
    "        .when((data['x_abs'] > -25) & (data['x_abs'] < 25)).then(pl.lit('NZ'))\n",
    "        .when(data['x_abs'] <= -25).then(pl.lit('DZ'))\n",
    "        .otherwise(None)\n",
    "        .alias('event_zone')\n",
    "      ]\n",
    "    )\n",
    "\n",
    "    data = data.with_columns(\n",
    "      [\n",
    "        pl.when((data['event_zone'] == 'OZ') & (data['event_team_type'] == 'home')).then(pl.lit('OZ'))\n",
    "        .when((data['event_zone'] == 'OZ') & (data['event_team_type'] == 'away')).then(pl.lit('DZ'))\n",
    "        .when((data['event_zone'] == 'DZ') & (data['event_team_type'] == 'home')).then(pl.lit('DZ'))\n",
    "        .when((data['event_zone'] == 'DZ') & (data['event_team_type'] == 'away')).then(pl.lit('OZ'))\n",
    "        .when((data['event_zone'] == 'NZ')).then(pl.lit('NZ'))\n",
    "        .otherwise(None)\n",
    "        .alias('home_event_zone')\n",
    "      ]\n",
    "    )\n",
    "    # 3) Create Event Distance Calculation\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns([\n",
    "          pl.when(data['x_abs'] >= 0).then(pl.Series.sqrt((89.25 - pl.Series.abs(data['x_abs']))**2 + data['y_abs']**2))\n",
    "          .when(data['x_abs'] <  0).then(pl.Series.sqrt((pl.Series.abs(data['x_abs']) + 89.25)**2 + data['y_abs']**2))\n",
    "          .alias('event_distance')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.when((pl.col('event_distance').abs() == 0.0)).then(pl.lit(0.25))\n",
    "            .otherwise(pl.col('event_distance').round(3)).alias('event_distance')\n",
    "        ])\n",
    "    )\n",
    "    # 4) Create Event Angle Calculation\n",
    "    data = (\n",
    "        data\n",
    "        .with_columns(\n",
    "        pl.when(data['x_abs'] >= 0)\n",
    "          .then(pl.Series.arctan(data['y_abs'] / (89.25 - pl.Series.abs(data['x_abs'])))\n",
    "                .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "          .when(data['x_abs'] < 0)\n",
    "          .then(pl.Series.arctan(data['y_abs'] / (pl.Series.abs(data['x_abs']) + 89.25))\n",
    "                .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "          .alias('event_angle')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs') > 89.25).then((180 - pl.col('event_angle'))).otherwise(pl.col('event_angle')).alias('event_angle')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col('event_angle').round(3)\n",
    "        )\n",
    "    )\n",
    "    # 5) Adjust Penalty Shot Game State\n",
    "    data = data.with_columns(\n",
    "        [\n",
    "            pl.when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'home')\n",
    "            ).then(pl.lit('Ev1'))\n",
    "            .when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'away')\n",
    "            ).then(pl.lit('1vE'))\n",
    "            .otherwise(data['strength_state']).alias('strength_state'),\n",
    "\n",
    "            pl.when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'home')\n",
    "            ).then(pl.lit(1))\n",
    "            .when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'away')\n",
    "            ).then(pl.lit(0))\n",
    "            .otherwise(data['home_skaters']).alias('home_skaters'),\n",
    "\n",
    "            pl.when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'home')\n",
    "            ).then(pl.lit(0))\n",
    "            .when(\n",
    "                (data['secondary_type'] == 'Penalty Shot') &\n",
    "                (data['event_team_type'] == 'away')\n",
    "            ).then(pl.lit(1))\n",
    "            .otherwise(data['away_skaters']).alias('away_skaters')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ### END EVENT CALCULATION ###\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *c) Function: Indexing Operations*\n",
    "\n",
    "- Now that we have some cleaner data, I want to build some indexes to help organize the play by play data to create time variables used in the model.\n",
    "- We look to create an index for:\n",
    "    - Faceoffs\n",
    "        - *Also used to create which zone in which a play started.*\n",
    "    - Shifts\n",
    "    - Penalties\n",
    "- These indexes will help us to create model features related to time relative to when events occured previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_input_data(data):\n",
    "    \"\"\" This Function will create indexes and ID's for certain types of plays/events.\"\"\"\n",
    "\n",
    "    # 1) Add Zone Start For Corsi Events (i.e., shots)\n",
    "    #fc_idx = (\n",
    "    #    data\n",
    "    #    .filter((pl.col('event_type').is_in(['FACEOFF'] + xG_Events)) &\n",
    "    #    (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P'))\n",
    "    #    )\n",
    "    #    .sort('game_id', 'period', 'event_idx')\n",
    "    #    .with_columns(pl.when(pl.col('event_type') == \"FACEOFF\").then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_fac'))\n",
    "    #    .with_columns(pl.col('is_fac').cum_sum().alias('face_index'))\n",
    "    #    .select(['game_id', 'event_idx', 'face_index', 'home_zone'])\n",
    "    #    .sort('game_id', 'event_idx', 'face_index')\n",
    "    #    .with_columns(pl.col('home_zone').first().over(['game_id', 'face_index']).alias('first_home_zone'))\n",
    "    #    .with_columns(\n",
    "    #        pl.when(pl.first('first_home_zone') == 'OZ').then(1)\n",
    "    #        .when(pl.first('first_home_zone') == 'NZ').then(2)\n",
    "    #        .when(pl.first('first_home_zone') == 'DZ').then(3)\n",
    "    #        .otherwise(pl.lit(None))\n",
    "    #        .alias('home_zonestart')\n",
    "    #    )\n",
    "    #    .select(['game_id', 'event_idx', 'home_zonestart'])\n",
    "    #)\n",
    "    #data = data.join(fc_idx, on=[\"game_id\", \"event_idx\"], how=\"left\")\n",
    "\n",
    "\n",
    "    # 2) Create Indexes For Shift and Penalties\n",
    "    home_player_id_col_struct = [\"home_1_on_id\", \"home_2_on_id\", \"home_3_on_id\", \"home_4_on_id\", \"home_5_on_id\", \"home_6_on_id\", \"home_goalie\"]\n",
    "    away_player_id_col_struct = [\"away_1_on_id\", \"away_2_on_id\", \"away_3_on_id\", \"away_4_on_id\", \"away_5_on_id\", \"away_6_on_id\", \"away_goalie\"]\n",
    "    all_player_id_col_struct = home_player_id_col_struct + away_player_id_col_struct\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        .sort([\"season\",\"game_id\", \"period\", \"event_idx\"])\n",
    "        .with_columns([\n",
    "            pl.when(pl.col(\"event_type\") == \"FACEOFF\").then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_fac'),\n",
    "            pl.when(pl.col(\"event_type\") == \"PENALTY\").then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_pen'),\n",
    "            pl.when((pl.struct(all_player_id_col_struct) != pl.struct(all_player_id_col_struct).shift()) | (pl.col('event_type').shift() == 'PERIOD_START')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_shi'),\n",
    "            pl.when((pl.struct(home_player_id_col_struct) != pl.struct(home_player_id_col_struct).shift()) | (pl.col('event_type').shift() == 'PERIOD_START')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_H_shi'),\n",
    "            pl.when((pl.struct(away_player_id_col_struct) != pl.struct(away_player_id_col_struct).shift()) | (pl.col('event_type').shift() == 'PERIOD_START')).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_A_shi'),\n",
    "          ])\n",
    "        .with_columns([\n",
    "            pl.col('is_fac').cum_sum().alias('face_index'),\n",
    "            pl.col('is_pen').cum_sum().alias('pen_index'),\n",
    "            pl.col('is_shi').cum_sum().alias('all_shift_index'),\n",
    "            pl.col('is_H_shi').cum_sum().alias('home_shift_index'),\n",
    "            pl.col('is_A_shi').cum_sum().alias('away_shift_index'),\n",
    "        ])\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .with_columns([\n",
    "            (pl.col('game_seconds').first().over([\"season\",\"game_id\", \"period\", \"all_shift_index\"])).alias(\"all_shift_start_seconds\"),\n",
    "            (pl.col('game_seconds').last().over([\"season\",\"game_id\", \"period\", \"all_shift_index\"])).alias(\"all_shift_end_seconds\"),\n",
    "            (pl.col('game_seconds').first().over([\"season\",\"game_id\", \"period\", \"home_shift_index\"])).alias(\"home_shift_start_seconds\"),\n",
    "            (pl.col('game_seconds').last().over([\"season\",\"game_id\", \"period\", \"home_shift_index\"])).alias(\"home_shift_end_seconds\"),\n",
    "            (pl.col('game_seconds').first().over([\"season\",\"game_id\", \"period\", \"away_shift_index\"])).alias(\"away_shift_start_seconds\"),\n",
    "            (pl.col('game_seconds').last().over([\"season\",\"game_id\", \"period\", \"away_shift_index\"])).alias(\"away_shift_end_seconds\")\n",
    "            ])\n",
    "        .drop(['is_fac', 'is_shi', 'is_pen', 'is_H_shi', 'is_A_shi'])\n",
    "        )\n",
    "\n",
    "\n",
    "    gb_cols_1 = [\"game_id\", \"period\", \"face_index\", \"pen_index\"]\n",
    "\n",
    "    idx_df = (\n",
    "        data\n",
    "        .filter(\n",
    "            (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P'))\n",
    "        )\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns([\n",
    "            pl.when(pl.struct(gb_cols_1 + ['all_shift_index']) != pl.struct(gb_cols_1 + ['all_shift_index']).shift()).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_all_new_shift'),\n",
    "            pl.when(pl.struct([\"game_id\", \"period\",'home_shift_index']) != pl.struct([\"game_id\", \"period\",'home_shift_index']).shift()).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_home_new_shift'),\n",
    "            pl.when(pl.struct([\"game_id\", \"period\",'away_shift_index']) != pl.struct([\"game_id\", \"period\",'away_shift_index']).shift()).then(pl.lit(1)).otherwise(pl.lit(0)).alias('is_away_new_shift'),\n",
    "                   ])\n",
    "        .with_columns([\n",
    "            pl.col('is_all_new_shift').cum_sum().alias('all_shift_ID'),\n",
    "            pl.col('is_home_new_shift').cum_sum().alias('home_shift_ID'),\n",
    "            pl.col('is_away_new_shift').cum_sum().alias('away_shift_ID')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('game_seconds') - pl.col('all_shift_start_seconds')).alias('all_shift_length'),\n",
    "            (pl.col('game_seconds') - pl.col('home_shift_start_seconds')).alias('home_shift_length'),\n",
    "            (pl.col('game_seconds') - pl.col('away_shift_start_seconds')).alias('away_shift_length')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_shift_length'))\n",
    "              .when(pl.col('event_team_type') == 'away').then(pl.col('away_shift_length'))\n",
    "              .otherwise(None).alias('event_team_toi'),\n",
    "            pl.when(pl.col('event_team_type') == 'away').then(pl.col('home_shift_length'))\n",
    "              .when(pl.col('event_team_type') == 'home').then(pl.col('away_shift_length'))\n",
    "              .otherwise(None).alias('def_team_toi'),\n",
    "            pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_shift_length') - pl.col('away_shift_length'))\n",
    "              .when(pl.col('event_team_type') == 'away').then(pl.col('away_shift_length') - pl.col('home_shift_length'))\n",
    "              .otherwise(None).alias('event_team_shift_time_diff')\n",
    "        ])\n",
    "        .select(\"game_id\", \"period\", \"event_idx\", \"face_index\", \"all_shift_index\", \"home_shift_index\", \"away_shift_index\", \"pen_index\",\n",
    "                \"all_shift_ID\", \"home_shift_ID\", \"away_shift_ID\",\n",
    "                \"all_shift_length\", \"home_shift_length\", \"away_shift_length\")\n",
    "    )\n",
    "\n",
    "    # Join Indexes To Data (Join All Common Columns)\n",
    "    idx_cols = idx_df.columns\n",
    "    data_cols = data.columns\n",
    "    common_cols = list(set(idx_cols) & set(data_cols))\n",
    "\n",
    "    data =  data.join(\n",
    "             idx_df,\n",
    "             on=common_cols,\n",
    "             how=\"left\"\n",
    "         )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *d) Function: Separate Data by Game Strength Stae*\n",
    "\n",
    "Here I am following Evolving Wild's method of splitting data into 4 dataframes to build 4 models for 4 game states:\n",
    "- Even Strength (5v5, 4v4, 3v3)\n",
    "- Power-Play/Unequal Advantage (6v5, 6v4, 5v4, 5v3, 4v3)\n",
    "- Short-Handed (4v5, 3v5, 3v4)\n",
    "- Empty Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_strength(data):\n",
    "    \"\"\"This function will split and clean indexed play-by-play data into 4 categories (EV, PP, SH, and EN)\"\"\"\n",
    "\n",
    "    EV_DF = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(xG_Events)) &\n",
    "            (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P')) &\n",
    "            (~pl.col('x_abs').is_null()) &\n",
    "            (~pl.col('y_abs').is_null())\n",
    "        )\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns([\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').shift(1).over(['season', 'game_id', 'period']))).alias('seconds_since_last'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'home_shift_ID']))).alias('home_skaters_toi'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'away_shift_ID']))).alias('away_skaters_toi'),\n",
    "            ((pl.col('event_type').shift(1).over(['season', 'game_id', 'period']))).alias('event_type_last'),\n",
    "            ((pl.col('event_team_abbr').shift(1).over(['season', 'game_id', 'period']))).alias('event_team_last'),\n",
    "            ((pl.col('strength_state').shift(1).over(['season', 'game_id', 'period']))).alias('event_strength_last'),\n",
    "            ((pl.col('x_abs').shift(1).over(['season', 'game_id', 'period']))).alias('x_abs_last'),\n",
    "            ((pl.col('y_abs').shift(1).over(['season', 'game_id', 'period']))).alias('y_abs_last'),\n",
    "            ((pl.col('home_score').shift(1).over(['season', 'game_id', 'period']))).alias('home_score'),\n",
    "            ((pl.col('away_score').shift(1).over(['season', 'game_id', 'period']))).alias('away_score'),\n",
    "            (pl.when((pl.col('event_team_type') == 'home')).then((pl.col('home_goalie')).str.to_uppercase()).otherwise((pl.col('away_goalie').str.to_uppercase())).alias('event_goalie_id'))\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'away').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('event_team_toi'),\n",
    "            (pl.when(pl.col('event_team_type') == 'away').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'home').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('def_team_toi')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('def_team_toi') - pl.col('event_team_toi')).alias('event_team_shift_time_diff')\n",
    "        ])\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(fenwick_events)) &\n",
    "            (pl.col('strength_state').is_in(EV_STR_Codes)) &\n",
    "            (~pl.col('x_abs_last').is_null()) &\n",
    "            (~pl.col('y_abs_last').is_null())\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('x_abs_last')).otherwise(pl.col('x_abs_last') * -1).alias('x_abs_last')),\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('y_abs_last')).otherwise(pl.col('y_abs_last') * -1).alias('y_abs_last')),\n",
    "            (pl.when(pl.col('home_score').is_null()).then(pl.lit(0)).otherwise(pl.col('home_score'))).alias('home_score'),\n",
    "            (pl.when(pl.col('away_score').is_null()).then(pl.lit(0)).otherwise(pl.col('away_score'))).alias('away_score')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_abbr') == pl.col('event_team_last')).then(pl.lit(1)).otherwise(pl.lit(0))).alias('same_team_last'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_home'),\n",
    "            (pl.when(pl.col('period') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_overtime'),\n",
    "            (pl.when(pl.col('season_type') == 'P').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_playoff'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_score') - pl.col('away_score')).otherwise(pl.col('away_score') - pl.col('home_score'))).alias('score_state'),\n",
    "            #(pl.when((pl.col('seconds_since_last') == 0) & (pl.col('event_type_last') == 'FACEOFF')).then(pl.col(\"shift_length\")).otherwise(pl.col('seconds_since_last'))).alias('seconds_since_last'),\n",
    "            ((((pl.col('x_abs') - pl.col('x_abs_last')) ** 2) + ((pl.col('y_abs') - pl.col('y_abs_last')) ** 2)).sqrt()).alias('distance_from_last')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('seconds_since_last') == 0).then(pl.lit(0.5)).otherwise(pl.col('seconds_since_last')).alias('seconds_since_last'),\n",
    "            pl.when(pl.col('x_abs_last') >= 0)\n",
    "            .then((pl.col('y_abs_last') / (89.25 - (pl.col('x_abs_last').abs()))).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .when(pl.col('x_abs_last') < 0)\n",
    "            .then((pl.col('y_abs_last') / ((pl.col('x_abs_last').abs()) + 89.25)).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs_last') > 89.25).then((180 - pl.col('event_angle_last'))).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.col('distance_from_last') / pl.col('seconds_since_last')).alias('puck_speed_since_last'),\n",
    "            ((pl.col('event_angle') - pl.col('event_angle_last')).abs()).alias('event_angle_change')\n",
    "            ])\n",
    "        .with_columns((pl.col('event_angle_change') / pl.col('seconds_since_last')).alias('event_angle_change_speed'))\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('puck_speed_since_last').is_infinite()).then(pl.col('distance_from_last') / pl.lit(0.5)).otherwise(pl.col('puck_speed_since_last')).alias('puck_speed_since_last'),\n",
    "            pl.when(pl.col('event_angle_last').is_infinite()).then(None).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "            ])\n",
    "        .select(['season', 'game_id', 'game_date', 'event_idx', 'period', 'game_seconds', 'is_overtime', 'is_playoff',\n",
    "                'strength_state', 'score_state', 'is_home', \n",
    "                'event_player_1_id', 'home_goalie', 'away_goalie', 'event_player_2_id', 'event_goalie_id',\n",
    "                'home_score', 'away_score', 'home_abbreviation', 'away_abbreviation', 'home_skaters', 'away_skaters',\n",
    "                'event_type', 'event_team', 'event_team_abbr', 'secondary_type',\n",
    "                'x_abs', 'y_abs', 'event_angle_last', 'event_angle', 'event_distance',\n",
    "                'event_angle_change', 'event_angle_change_speed',\n",
    "                'event_team_last', 'same_team_last', 'event_strength_last', 'event_type_last',\n",
    "                'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "                'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'])\n",
    "    )\n",
    "\n",
    "    ## Build PP DataFrame ##\n",
    "    PP_DF = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(xG_Events)) &\n",
    "            (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P')) &\n",
    "            (~pl.col('x_abs').is_null()) &\n",
    "            (~pl.col('y_abs').is_null())\n",
    "        )\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns([\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').shift(1).over(['season', 'game_id', 'period']))).alias('seconds_since_last'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'home_shift_ID']))).alias('home_skaters_toi'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'away_shift_ID']))).alias('away_skaters_toi'),\n",
    "            ((pl.col('event_type').shift(1).over(['season', 'game_id', 'period']))).alias('event_type_last'),\n",
    "            ((pl.col('event_team_abbr').shift(1).over(['season', 'game_id', 'period']))).alias('event_team_last'),\n",
    "            ((pl.col('strength_state').shift(1).over(['season', 'game_id', 'period']))).alias('event_strength_last'),\n",
    "            ((pl.col('x_abs').shift(1).over(['season', 'game_id', 'period']))).alias('x_abs_last'),\n",
    "            ((pl.col('y_abs').shift(1).over(['season', 'game_id', 'period']))).alias('y_abs_last'),\n",
    "            ((pl.col('event_angle').shift(1).over(['season', 'game_id', 'period']))).alias('event_angle_last'),\n",
    "            ((pl.col('home_score').shift(1).over(['season', 'game_id', 'period']))).alias('home_score'),\n",
    "            ((pl.col('away_score').shift(1).over(['season', 'game_id', 'period']))).alias('away_score'),\n",
    "            (pl.when(pl.col('strength_state').is_in(PP_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_pen'),\n",
    "            (pl.when(((pl.col('home_skaters') - pl.col('away_skaters')) >= 2) | ((pl.col('away_skaters') - pl.col('home_skaters')) >= 2)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_two_ma'),\n",
    "            (pl.when((pl.col('event_team_type') == 'home')).then((pl.col('home_goalie')).str.to_uppercase()).otherwise((pl.col('away_goalie').str.to_uppercase())).alias('event_goalie_id'))\n",
    "        ])\n",
    "        .with_columns(((pl.col('is_pen')) * ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'pen_index'])))).alias('pen_seconds_since'))\n",
    "        .with_columns([\n",
    "            (pl.when((pl.col('pen_seconds_since') > 0) & (pl.col('pen_seconds_since') >= 300)).then(pl.lit(120)).otherwise(pl.col('pen_seconds_since'))).alias('pen_seconds_since')\n",
    "            ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'away').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('event_team_toi'),\n",
    "            (pl.when(pl.col('event_team_type') == 'away').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'home').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('def_team_toi')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('def_team_toi') - pl.col('event_team_toi')).alias('event_team_shift_time_diff')\n",
    "        ])\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(fenwick_events)) &\n",
    "            (((pl.col('event_team_type') == 'home') & (pl.col('true_strength_state').is_in([\"6v5\", \"6v4\", \"5v4\", \"5v3\", \"4v3\"]))) |\n",
    "            ((pl.col('event_team_type') == 'away') & (pl.col('true_strength_state').is_in([\"5v6\", \"4v6\", \"4v5\", \"3v5\", \"3v4\"])))) &\n",
    "            (~pl.col('x_abs_last').is_null()) &\n",
    "            (~pl.col('y_abs_last').is_null())\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('x_abs_last')).otherwise(pl.col('x_abs_last') * -1).alias('x_abs_last')),\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('y_abs_last')).otherwise(pl.col('y_abs_last') * -1).alias('y_abs_last')),\n",
    "            (pl.when(pl.col('home_score').is_null()).then(pl.lit(0)).otherwise(pl.col('home_score'))).alias('home_score'),\n",
    "            (pl.when(pl.col('away_score').is_null()).then(pl.lit(0)).otherwise(pl.col('away_score'))).alias('away_score')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_abbr') == pl.col('event_team_last')).then(pl.lit(1)).otherwise(pl.lit(0))).alias('same_team_last'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_home'),\n",
    "            (pl.when(pl.col('period') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_overtime'),\n",
    "            (pl.when(pl.col('season_type') == 'P').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_playoff'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_score') - pl.col('away_score')).otherwise(pl.col('away_score') - pl.col('home_score'))).alias('score_state'),\n",
    "            #(pl.when((pl.col('seconds_since_last') == 0) & (pl.col('event_type_last') == 'FACEOFF')).then(pl.col(\"shift_length\")).otherwise(pl.col('seconds_since_last'))).alias('seconds_since_last'),\n",
    "            ((((pl.col('x_abs') - pl.col('x_abs_last')) ** 2) + ((pl.col('y_abs') - pl.col('y_abs_last')) ** 2)).sqrt()).alias('distance_from_last'),\n",
    "            (pl.when(pl.col('event_strength_last').is_in(EV_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_event_EV')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('seconds_since_last') == 0).then(pl.lit(0.5)).otherwise(pl.col('seconds_since_last')).alias('seconds_since_last'),\n",
    "            pl.when(pl.col('x_abs_last') >= 0)\n",
    "            .then((pl.col('y_abs_last') / (89.25 - (pl.col('x_abs_last').abs()))).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .when(pl.col('x_abs_last') < 0)\n",
    "            .then((pl.col('y_abs_last') / ((pl.col('x_abs_last').abs()) + 89.25)).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs_last') > 89.25).then((180 - pl.col('event_angle_last'))).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.col('distance_from_last') / pl.col('seconds_since_last')).alias('puck_speed_since_last'),\n",
    "            ((pl.col('event_angle') - pl.col('event_angle_last')).abs()).alias('event_angle_change')\n",
    "            ])\n",
    "        .with_columns((pl.col('event_angle_change') / pl.col('seconds_since_last')).alias('event_angle_change_speed'))\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('puck_speed_since_last').is_infinite()).then(pl.col('distance_from_last') / pl.lit(0.5)).otherwise(pl.col('puck_speed_since_last')).alias('puck_speed_since_last'),\n",
    "            pl.when(pl.col('event_angle_last').is_infinite()).then(None).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "            ])\n",
    "        .select([\n",
    "            'season', 'game_id', 'game_date', 'event_idx', 'period', 'game_seconds', 'is_overtime', 'is_playoff',\n",
    "            'strength_state', 'true_strength_state', 'score_state', 'is_home', 'is_two_ma',\n",
    "            'event_player_1_id', 'home_goalie', 'away_goalie', 'event_player_2_id', 'event_goalie_id',\n",
    "            'home_score', 'away_score', 'home_abbreviation', 'away_abbreviation', 'home_skaters', 'away_skaters',\n",
    "            'event_type', 'event_team', 'event_team_abbr', 'event_team_type', 'secondary_type',\n",
    "            'x_abs', 'y_abs', 'event_angle_last', 'event_angle', 'event_distance',\n",
    "            'event_angle_change', 'event_angle_change_speed',\n",
    "            'event_team_last', 'same_team_last', 'event_strength_last', 'prior_event_EV', 'event_type_last',\n",
    "            'seconds_since_last', 'pen_seconds_since', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "            'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    ## Build SH DataFrame ##\n",
    "    SH_DF = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(xG_Events)) &\n",
    "            (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P')) &\n",
    "            (~pl.col('x_abs').is_null()) &\n",
    "            (~pl.col('y_abs').is_null())\n",
    "        )\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns([\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').shift(1).over(['season', 'game_id', 'period']))).alias('seconds_since_last'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'home_shift_ID']))).alias('home_skaters_toi'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'away_shift_ID']))).alias('away_skaters_toi'),\n",
    "            ((pl.col('event_type').shift(1).over(['season', 'game_id', 'period']))).alias('event_type_last'),\n",
    "            ((pl.col('event_team_abbr').shift(1).over(['season', 'game_id', 'period']))).alias('event_team_last'),\n",
    "            ((pl.col('strength_state').shift(1).over(['season', 'game_id', 'period']))).alias('event_strength_last'),\n",
    "            ((pl.col('x_abs').shift(1).over(['season', 'game_id', 'period']))).alias('x_abs_last'),\n",
    "            ((pl.col('y_abs').shift(1).over(['season', 'game_id', 'period']))).alias('y_abs_last'),\n",
    "            ((pl.col('event_angle').shift(1).over(['season', 'game_id', 'period']))).alias('event_angle_last'),\n",
    "            ((pl.col('home_score').shift(1).over(['season', 'game_id', 'period']))).alias('home_score'),\n",
    "            ((pl.col('away_score').shift(1).over(['season', 'game_id', 'period']))).alias('away_score'),\n",
    "            (pl.concat_str([pl.col('home_skaters'), pl.lit('v'), pl.col('away_skaters')])).alias('true_strength_state'),\n",
    "            (pl.when(pl.col('strength_state').is_in(PP_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_pen'),\n",
    "            (pl.when(((pl.col('home_skaters') - pl.col('away_skaters')) >= 2) | ((pl.col('away_skaters') - pl.col('home_skaters')) >= 2)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_two_ma'),\n",
    "            (pl.when((pl.col('event_team_type') == 'home')).then((pl.col('home_goalie')).str.to_uppercase()).otherwise((pl.col('away_goalie').str.to_uppercase())).alias('event_goalie_id'))\n",
    "        ])\n",
    "        .with_columns([((pl.col('is_pen')) * ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'pen_index'])))).alias('pen_seconds_since')\n",
    "            ])\n",
    "        .with_columns((pl.when((pl.col('pen_seconds_since') > 0) & (pl.col('pen_seconds_since') >= 300)).then(pl.lit(120)).otherwise(pl.col('pen_seconds_since'))).alias('pen_seconds_since'))\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'away').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('event_team_toi'),\n",
    "            (pl.when(pl.col('event_team_type') == 'away').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'home').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('def_team_toi')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('def_team_toi') - pl.col('event_team_toi')).alias('event_team_shift_time_diff')\n",
    "        ])\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(fenwick_events)) &\n",
    "            (((pl.col('event_team_type') == 'away') & (pl.col('true_strength_state').is_in([\"5v4\", \"5v3\", \"4v3\"]))) |\n",
    "            ((pl.col('event_team_type') == 'home') & (pl.col('true_strength_state').is_in([\"4v5\", \"3v5\", \"3v4\"])))) &\n",
    "            (~pl.col('x_abs_last').is_null()) &\n",
    "            (~pl.col('y_abs_last').is_null())\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('x_abs_last')).otherwise(pl.col('x_abs_last') * -1).alias('x_abs_last')),\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('y_abs_last')).otherwise(pl.col('y_abs_last') * -1).alias('y_abs_last')),\n",
    "            (pl.when(pl.col('home_score').is_null()).then(pl.lit(0)).otherwise(pl.col('home_score'))).alias('home_score'),\n",
    "            (pl.when(pl.col('away_score').is_null()).then(pl.lit(0)).otherwise(pl.col('away_score'))).alias('away_score')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_abbr') == pl.col('event_team_last')).then(pl.lit(1)).otherwise(pl.lit(0))).alias('same_team_last'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_home'),\n",
    "            (pl.when(pl.col('period') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_overtime'),\n",
    "            (pl.when(pl.col('season_type') == 'P').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_playoff'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_score') - pl.col('away_score')).otherwise(pl.col('away_score') - pl.col('home_score'))).alias('score_state'),\n",
    "            #(pl.when((pl.col('seconds_since_last') == 0) & (pl.col('event_type_last') == 'FACEOFF')).then(pl.col(\"shift_length\")).otherwise(pl.col('seconds_since_last'))).alias('seconds_since_last'),\n",
    "            ((((pl.col('x_abs') - pl.col('x_abs_last')) ** 2) + ((pl.col('y_abs') - pl.col('y_abs_last')) ** 2)).sqrt()).alias('distance_from_last'),\n",
    "            (pl.when(pl.col('event_strength_last').is_in(EV_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_event_EV')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('seconds_since_last') == 0).then(pl.lit(0.5)).otherwise(pl.col('seconds_since_last')).alias('seconds_since_last'),\n",
    "            pl.when(pl.col('x_abs_last') >= 0)\n",
    "            .then((pl.col('y_abs_last') / (89.25 - (pl.col('x_abs_last').abs()))).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .when(pl.col('x_abs_last') < 0)\n",
    "            .then((pl.col('y_abs_last') / ((pl.col('x_abs_last').abs()) + 89.25)).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs_last') > 89.25).then((180 - pl.col('event_angle_last'))).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.col('distance_from_last') / pl.col('seconds_since_last')).alias('puck_speed_since_last'),\n",
    "            ((pl.col('event_angle') - pl.col('event_angle_last')).abs()).alias('event_angle_change')\n",
    "            ])\n",
    "        .with_columns((pl.col('event_angle_change') / pl.col('seconds_since_last')).alias('event_angle_change_speed'))\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('puck_speed_since_last').is_infinite()).then(pl.col('distance_from_last') / pl.lit(0.5)).otherwise(pl.col('puck_speed_since_last')).alias('puck_speed_since_last'),\n",
    "            pl.when(pl.col('event_angle_last').is_infinite()).then(None).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "            ])\n",
    "        .select([\n",
    "            'season', 'game_id', 'game_date', 'event_idx', 'period', 'game_seconds', 'is_overtime', 'is_playoff',\n",
    "            'strength_state', 'true_strength_state', 'score_state', 'is_home', 'is_two_ma',\n",
    "            'event_player_1_id', 'home_goalie', 'away_goalie', 'event_player_2_id', 'event_goalie_id',\n",
    "            'home_score', 'away_score', 'home_abbreviation', 'away_abbreviation', 'home_skaters', 'away_skaters',\n",
    "            'event_type', 'event_team', 'event_team_abbr', 'event_team_type', 'secondary_type',\n",
    "            'x_abs', 'y_abs', 'event_angle_last', 'event_angle', 'event_distance',\n",
    "            'event_angle_change', 'event_angle_change_speed',\n",
    "            'event_team_last', 'same_team_last', 'event_strength_last', 'prior_event_EV', 'event_type_last',\n",
    "            'seconds_since_last', 'pen_seconds_since', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "            'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    ## Build Empty Net DataFrame ##\n",
    "    EN_DF = (\n",
    "        data\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(xG_Events)) &\n",
    "            (((pl.col('period') < 5) & (pl.col('season_type') == 'R')) | (pl.col('season_type') == 'P')) &\n",
    "            (~pl.col('x_abs').is_null()) &\n",
    "            (~pl.col('y_abs').is_null())\n",
    "        )\n",
    "        .sort('season', 'game_id', 'period', 'event_idx')\n",
    "        .with_columns([\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').shift(1).over(['season', 'game_id', 'period']))).alias('seconds_since_last'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'home_shift_index']))).alias('home_skaters_toi'),\n",
    "            ((pl.col('game_seconds')) - (pl.col('game_seconds').first().over(['season', 'game_id', 'period', 'away_shift_index']))).alias('away_skaters_toi'),\n",
    "            ((pl.col('event_type').shift(1).over(['season', 'game_id', 'period']))).alias('event_type_last'),\n",
    "            ((pl.col('event_team_abbr').shift(1).over(['season', 'game_id', 'period']))).alias('event_team_last'),\n",
    "            ((pl.col('strength_state').shift(1).over(['season', 'game_id', 'period']))).alias('event_strength_last'),\n",
    "            ((pl.col('x_abs').shift(1).over(['season', 'game_id', 'period']))).alias('x_abs_last'),\n",
    "            ((pl.col('y_abs').shift(1).over(['season', 'game_id', 'period']))).alias('y_abs_last'),\n",
    "            ((pl.col('home_score').shift(1).over(['season', 'game_id', 'period']))).alias('home_score'),\n",
    "            ((pl.col('away_score').shift(1).over(['season', 'game_id', 'period']))).alias('away_score'),\n",
    "            ((pl.col('event_angle').shift(1).over(['season', 'game_id', 'period']))).alias('event_angle_last'),\n",
    "            (pl.when(pl.col('strength_state').is_in(PP_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_pen'),\n",
    "            (pl.when(((pl.col('home_skaters') - pl.col('away_skaters')) >= 2) | ((pl.col('away_skaters') - pl.col('home_skaters')) >= 2)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_two_ma')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'away').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('event_team_toi'),\n",
    "            (pl.when(pl.col('event_team_type') == 'away').then(pl.col('home_skaters_toi'))\n",
    "               .when(pl.col('event_team_type') == 'home').then(pl.col('away_skaters_toi'))\n",
    "               .otherwise(pl.lit(None))\n",
    "            ).alias('def_team_toi')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.col('def_team_toi') - pl.col('event_team_toi')).alias('event_team_shift_time_diff')\n",
    "        ])\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .filter(\n",
    "            (pl.col('event_type').is_in(fenwick_events)) &\n",
    "            (((pl.col('event_team_type') == 'away') & (pl.col('true_strength_state').is_in([\"Ev5\", \"Ev4\", \"Ev3\"]))) |\n",
    "            ((pl.col('event_team_type') == 'home') & (pl.col('true_strength_state').is_in([\"5vE\", \"4vE\", \"3vE\"])))) &\n",
    "            (~pl.col('x_abs_last').is_null()) &\n",
    "            (~pl.col('y_abs_last').is_null())\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('x_abs_last')).otherwise(pl.col('x_abs_last') * -1).alias('x_abs_last')),\n",
    "            (pl.when(pl.col('event_team_last') == pl.col('event_team_abbr')).then(pl.col('y_abs_last')).otherwise(pl.col('y_abs_last') * -1).alias('y_abs_last')),\n",
    "            (pl.when(pl.col('home_score').is_null()).then(pl.lit(0)).otherwise(pl.col('home_score'))).alias('home_score'),\n",
    "            (pl.when(pl.col('away_score').is_null()).then(pl.lit(0)).otherwise(pl.col('away_score'))).alias('away_score')\n",
    "        ])\n",
    "        .with_columns([\n",
    "            (pl.when(pl.col('event_team_abbr') == pl.col('event_team_last')).then(pl.lit(1)).otherwise(pl.lit(0))).alias('same_team_last'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_home'),\n",
    "            (pl.when(pl.col('period') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_overtime'),\n",
    "            (pl.when(pl.col('season_type') == 'P').then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_playoff'),\n",
    "            (pl.when(pl.col('event_team_type') == 'home').then(pl.col('home_score') - pl.col('away_score')).otherwise(pl.col('away_score') - pl.col('home_score'))).alias('score_state'),\n",
    "            #(pl.when((pl.col('seconds_since_last') == 0) & (pl.col('event_type_last') == 'FACEOFF')).then(pl.col(\"shift_length\")).otherwise(pl.col('seconds_since_last'))).alias('seconds_since_last'),\n",
    "            ((((pl.col('x_abs') - pl.col('x_abs_last')) ** 2) + ((pl.col('y_abs') - pl.col('y_abs_last')) ** 2)).sqrt()).alias('distance_from_last'),\n",
    "            (pl.when(pl.col('event_strength_last').is_in(EV_STR_Codes)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_event_EV'),\n",
    "            (pl.when(pl.col('strength_state').is_in(EV_STR_Codes + ['6v6'])).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_EV')\n",
    "        ])\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('seconds_since_last') == 0).then(pl.lit(0.5)).otherwise(pl.col('seconds_since_last')).alias('seconds_since_last'),\n",
    "            pl.when(pl.col('x_abs_last') >= 0)\n",
    "            .then((pl.col('y_abs_last') / (89.25 - (pl.col('x_abs_last').abs()))).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .when(pl.col('x_abs_last') < 0)\n",
    "            .then((pl.col('y_abs_last') / ((pl.col('x_abs_last').abs()) + 89.25)).arctan()\n",
    "                    .map_elements(lambda x: abs(x * (180 / pi))))\n",
    "            .alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.when(pl.col('x_abs_last') > 89.25).then((180 - pl.col('event_angle_last'))).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "        )\n",
    "        .with_columns([\n",
    "            (pl.col('distance_from_last') / pl.col('seconds_since_last')).alias('puck_speed_since_last'),\n",
    "            ((pl.col('event_angle') - pl.col('event_angle_last')).abs()).alias('event_angle_change')\n",
    "            ])\n",
    "        .with_columns((pl.col('event_angle_change') / pl.col('seconds_since_last')).alias('event_angle_change_speed'))\n",
    "        .with_columns([\n",
    "            pl.when(pl.col('puck_speed_since_last').is_infinite()).then(pl.col('distance_from_last') / pl.lit(0.5)).otherwise(pl.col('puck_speed_since_last')).alias('puck_speed_since_last'),\n",
    "            pl.when(pl.col('event_angle_last').is_infinite()).then(None).otherwise(pl.col('event_angle_last')).alias('event_angle_last')\n",
    "            ])\n",
    "        .select([\n",
    "            'season', 'game_id', 'game_date', 'event_idx', 'period', 'game_seconds', 'is_overtime', 'is_playoff',\n",
    "            'strength_state', 'true_strength_state', 'score_state', 'is_home', 'is_two_ma', 'is_pen', 'is_EV',\n",
    "            'event_player_1_id', 'home_goalie', 'away_goalie', 'event_player_2_id',\n",
    "            'home_score', 'away_score', 'home_abbreviation', 'away_abbreviation', 'home_skaters', 'away_skaters',\n",
    "            'event_type', 'event_team', 'event_team_abbr', 'event_team_type', 'secondary_type', \n",
    "            'x_abs', 'y_abs', 'event_angle', 'event_distance',\n",
    "            'event_angle_change', 'event_angle_change_speed',\n",
    "            'event_team_last', 'same_team_last', 'event_strength_last', 'prior_event_EV', 'event_type_last',\n",
    "            'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "            'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'\n",
    "        ])\n",
    "    )\n",
    "    return EV_DF, PP_DF, SH_DF, EN_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *e) Function: One Hot Encoding and Other Feature Engineering*\n",
    "\n",
    "Here, I wil look to build some binary columns related to each event to better help the model recognize and categorize each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prep(data, prep_type):\n",
    "    \"\"\" This function will prep each dataframe to be inputted into a classification model to predict expected goals \"\"\"\n",
    "\n",
    "    if(prep_type == 'EV'):\n",
    "        model_prep = (\n",
    "            data\n",
    "            .join(ROSTER_DF.with_columns(pl.col('event_player_1_id').cast(pl.Utf8)), on=[\"event_player_1_id\"], how = 'left')\n",
    "            #.join(GOALIES, on=[\"event_goalie_id\"], how = 'left')\n",
    "            .with_columns([\n",
    "                # Target Variable\n",
    "                (pl.when(pl.col('event_type') == \"GOAL\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_goal'),\n",
    "                # Game State\n",
    "                (pl.when(pl.col('strength_state') == \"5v5\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_5v5'),\n",
    "                (pl.when(pl.col('strength_state') == \"4v4\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_4v4'),\n",
    "                (pl.when(pl.col('strength_state') == \"3v3\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_3v3'),\n",
    "                # Score State\n",
    "                (pl.when(pl.col('score_state') <= -4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_4'),\n",
    "                (pl.when(pl.col('score_state') == -3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_3'),\n",
    "                (pl.when(pl.col('score_state') == -2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_2'),\n",
    "                (pl.when(pl.col('score_state') == -1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_1'),\n",
    "                (pl.when(pl.col('score_state') == 0).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_even'),\n",
    "                (pl.when(pl.col('score_state') == 1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_1'),\n",
    "                (pl.when(pl.col('score_state') == 2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_2'),\n",
    "                (pl.when(pl.col('score_state') == 3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_3'),\n",
    "                (pl.when(pl.col('score_state') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_4'),\n",
    "                # Prior Shot Outcome\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_opp'),\n",
    "                # Prior Event - Non Shot\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_win'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_lose'),\n",
    "                # Handiness\n",
    "                (pl.when(\n",
    "                    ((pl.col('hand_R') == 1) & (pl.col('y_abs') > 0) & ((pl.col('event_angle') > 10))) |\n",
    "                    ((pl.col('hand_L') == 1) & (pl.col('y_abs') < 0) & ((pl.col('event_angle') > 10)))\n",
    "                    ).then(pl.lit(1)).otherwise(pl.lit(0)).alias('off_wing'))\n",
    "            ])\n",
    "            .with_columns([\n",
    "                # Create Rebound Flag\n",
    "                (pl.when(\n",
    "                (pl.col('prior_shot_same') == 1) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rebound'),\n",
    "                (pl.when(\n",
    "                ((pl.col('prior_miss_same') == 1) | (pl.col('prior_block_same') == 1)) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_post_miss_shot'),\n",
    "                # Set Play (Faceoff Win + Shot In 5 Seconds)\n",
    "                (pl.when(\n",
    "                (pl.col('prior_face_win') == 1) &\n",
    "                (pl.col('x_abs_last') > 25) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_set_play'),\n",
    "                # Rush (Transition Play after Turnover)\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 0) &\n",
    "                (pl.col('seconds_since_last') <= 5) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rush_play'),\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 25) &\n",
    "                (pl.col('seconds_since_last') <= 3) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_fast_rush_play')\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        # Get Creates Column Names + Slim\n",
    "        new_cols = model_prep.columns[-32:]\n",
    "        model_prep = (\n",
    "            model_prep\n",
    "            .select([ 'season', 'game_id', 'event_idx', 'secondary_type',\n",
    "                'is_goal',\n",
    "                'period', 'game_seconds','is_home', 'is_overtime', 'is_playoff',\n",
    "                'x_abs', 'y_abs', 'event_distance', 'event_angle',\n",
    "                'event_angle_change', 'event_angle_change_speed',\n",
    "                'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "                'pos_F', 'pos_D', 'pos_G', 'hand_R', 'hand_L', #'G_hand_R', 'G_hand_L',\n",
    "                'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'] + new_cols\n",
    "            )\n",
    "        )\n",
    "\n",
    "    elif(prep_type == 'PP'):\n",
    "        model_prep = (\n",
    "            data\n",
    "            .join(ROSTER_DF.with_columns(pl.col('event_player_1_id').cast(pl.Utf8)), on=[\"event_player_1_id\"], how = 'left')\n",
    "            #.join(GOALIES, on=[\"event_goalie_id\"], how = 'left')\n",
    "            .with_columns([\n",
    "                # Target Variable\n",
    "                (pl.when(pl.col('event_type') == \"GOAL\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_goal'),\n",
    "                # Game State\n",
    "                (pl.when(((pl.col('true_strength_state') == \"5v4\") & (pl.col('event_team_type') == 'home')) | \n",
    "                         ((pl.col('true_strength_state') == \"4v5\") & (pl.col('event_team_type') == 'away'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_5v4'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"5v3\") & (pl.col('event_team_type') == 'home')) | \n",
    "                         ((pl.col('true_strength_state') == \"3v5\") & (pl.col('event_team_type') == 'away'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_5v3'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"4v3\") & (pl.col('event_team_type') == 'home')) | \n",
    "                         ((pl.col('true_strength_state') == \"3v4\") & (pl.col('event_team_type') == 'away'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_4v3'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"6v5\") & (pl.col('event_team_type') == 'home')) | \n",
    "                         ((pl.col('true_strength_state') == \"5v6\") & (pl.col('event_team_type') == 'away'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_6v5'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"6v4\") & (pl.col('event_team_type') == 'home')) | \n",
    "                         ((pl.col('true_strength_state') == \"4v6\") & (pl.col('event_team_type') == 'away'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_6v4'),\n",
    "                # Score State\n",
    "                (pl.when(pl.col('score_state') <= -4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_4'),\n",
    "                (pl.when(pl.col('score_state') == -3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_3'),\n",
    "                (pl.when(pl.col('score_state') == -2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_2'),\n",
    "                (pl.when(pl.col('score_state') == -1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_1'),\n",
    "                (pl.when(pl.col('score_state') == 0).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_even'),\n",
    "                (pl.when(pl.col('score_state') == 1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_1'),\n",
    "                (pl.when(pl.col('score_state') == 2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_2'),\n",
    "                (pl.when(pl.col('score_state') == 3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_3'),\n",
    "                (pl.when(pl.col('score_state') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_4'),\n",
    "                # Prior Shot Outcome\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_opp'),\n",
    "                # Prior Event - Non Shot\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_win'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_lose'),\n",
    "                # Handiness\n",
    "                (pl.when(\n",
    "                    ((pl.col('hand_R') == 1) & (pl.col('y_abs') > 0) & ((pl.col('event_angle') > 10))) |\n",
    "                    ((pl.col('hand_L') == 1) & (pl.col('y_abs') < 0) & ((pl.col('event_angle') > 10)))\n",
    "                    ).then(pl.lit(1)).otherwise(pl.lit(0)).alias('off_wing'))\n",
    "            ])\n",
    "            .with_columns([\n",
    "                # Create Rebound Flag\n",
    "                (pl.when(\n",
    "                (pl.col('prior_shot_same') == 1) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rebound'),\n",
    "                (pl.when(\n",
    "                ((pl.col('prior_miss_same') == 1) | (pl.col('prior_block_same') == 1)) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_post_miss_shot'),\n",
    "                # Set Play (Faceoff Win + Shot In 5 Seconds)\n",
    "                (pl.when(\n",
    "                (pl.col('prior_face_win') == 1) &\n",
    "                (pl.col('x_abs_last') > 25) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_set_play'),\n",
    "                # Rush (Transition Play after Turnover)\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 0) &\n",
    "                (pl.col('seconds_since_last') <= 5) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rush_play'),\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 25) &\n",
    "                (pl.col('seconds_since_last') <= 3) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_fast_rush_play')\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        # Get Creates Column Names + Slim\n",
    "        new_cols = model_prep.columns[-34:]\n",
    "        model_prep = (\n",
    "            model_prep\n",
    "            .select([ 'season', 'game_id', 'event_idx', 'secondary_type',\n",
    "                'is_goal',\n",
    "                'period', 'game_seconds','is_home', 'is_overtime', 'is_playoff',\n",
    "                'x_abs', 'y_abs', 'event_angle', 'event_distance',\n",
    "                'event_angle_change', 'event_angle_change_speed',\n",
    "                'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "                'pen_seconds_since', 'prior_event_EV', 'is_two_ma',\n",
    "                'pos_F', 'pos_D', 'pos_G', 'hand_R', 'hand_L', #'G_hand_R', 'G_hand_L',\n",
    "                'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'] + new_cols\n",
    "            )\n",
    "        )\n",
    "\n",
    "    elif(prep_type == 'SH'):\n",
    "        model_prep = (\n",
    "            data\n",
    "            .join(ROSTER_DF.with_columns(pl.col('event_player_1_id').cast(pl.Utf8)), on=[\"event_player_1_id\"], how = 'left')\n",
    "            #.join(GOALIES, on=[\"event_goalie_id\"], how = 'left')\n",
    "            .with_columns([\n",
    "                # Target Variable\n",
    "                (pl.when(pl.col('event_type') == \"GOAL\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_goal'),\n",
    "                # Game State\n",
    "                (pl.when(((pl.col('true_strength_state') == \"5v4\") & (pl.col('event_team_type') == 'away')) | \n",
    "                         ((pl.col('true_strength_state') == \"4v5\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_4v5'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"5v3\") & (pl.col('event_team_type') == 'away')) | \n",
    "                         ((pl.col('true_strength_state') == \"3v5\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_3v5'),\n",
    "                (pl.when(((pl.col('true_strength_state') == \"4v3\") & (pl.col('event_team_type') == 'away')) | \n",
    "                         ((pl.col('true_strength_state') == \"3v4\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_3v4'),\n",
    "                # Score State\n",
    "                (pl.when(pl.col('score_state') <= -4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_4'),\n",
    "                (pl.when(pl.col('score_state') == -3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_3'),\n",
    "                (pl.when(pl.col('score_state') == -2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_2'),\n",
    "                (pl.when(pl.col('score_state') == -1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_1'),\n",
    "                (pl.when(pl.col('score_state') == 0).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_even'),\n",
    "                (pl.when(pl.col('score_state') == 1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_1'),\n",
    "                (pl.when(pl.col('score_state') == 2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_2'),\n",
    "                (pl.when(pl.col('score_state') == 3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_3'),\n",
    "                (pl.when(pl.col('score_state') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_4'),\n",
    "                # Prior Shot Outcome\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_opp'),\n",
    "                # Prior Event - Non Shot\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_opp'),\n",
    "                (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_same'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_win'),\n",
    "                (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_lose'),\n",
    "                # Handiness\n",
    "                (pl.when(\n",
    "                    ((pl.col('hand_R') == 1) & (pl.col('y_abs') > 0) & ((pl.col('event_angle') > 10))) |\n",
    "                    ((pl.col('hand_L') == 1) & (pl.col('y_abs') < 0) & ((pl.col('event_angle') > 10)))\n",
    "                    ).then(pl.lit(1)).otherwise(pl.lit(0)).alias('off_wing'))\n",
    "            ])\n",
    "            .with_columns([\n",
    "                # Create Rebound Flag\n",
    "                (pl.when(\n",
    "                (pl.col('prior_shot_same') == 1) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rebound'),\n",
    "                (pl.when(\n",
    "                ((pl.col('prior_miss_same') == 1) | (pl.col('prior_block_same') == 1)) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_post_miss_shot'),\n",
    "                # Set Play (Faceoff Win + Shot In 5 Seconds)\n",
    "                (pl.when(\n",
    "                (pl.col('prior_face_win') == 1) &\n",
    "                (pl.col('x_abs_last') > 25) &\n",
    "                (pl.col('seconds_since_last') <= 3)\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_set_play'),\n",
    "                # Rush (Transition Play after Turnover)\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 0) &\n",
    "                (pl.col('seconds_since_last') <= 5) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rush_play'),\n",
    "                (pl.when(\n",
    "                (pl.col('x_abs_last') < 25) &\n",
    "                (pl.col('seconds_since_last') <= 3) &\n",
    "                ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "                ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_fast_rush_play')\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        # Get Creates Column Names + Slim\n",
    "        new_cols = model_prep.columns[-32:]\n",
    "        model_prep = (\n",
    "            model_prep\n",
    "            .select([ 'season', 'game_id', 'event_idx', 'secondary_type',\n",
    "                'is_goal',\n",
    "                'period', 'game_seconds','is_home', 'is_overtime', 'is_playoff',\n",
    "                'x_abs', 'y_abs', 'event_angle', 'event_distance',\n",
    "                'event_angle_change', 'event_angle_change_speed',\n",
    "                'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "                'pen_seconds_since', 'prior_event_EV',\n",
    "                'pos_F', 'pos_D', 'pos_G', 'hand_R', 'hand_L', #'G_hand_R', 'G_hand_L',\n",
    "                'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'] + new_cols\n",
    "            )\n",
    "        )\n",
    "\n",
    "    elif(prep_type == 'EN'):\n",
    "        model_prep = (\n",
    "        data\n",
    "        .join(ROSTER_DF.with_columns(pl.col('event_player_1_id').cast(pl.Utf8)), on=[\"event_player_1_id\"], how = 'left')\n",
    "        .with_columns([\n",
    "            # Target Variable\n",
    "            (pl.when(pl.col('event_type') == \"GOAL\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_goal'),\n",
    "            # Game State\n",
    "            (pl.when(((pl.col('true_strength_state') == \"Ev5\") & (pl.col('event_team_type') == 'away')) | \n",
    "                     ((pl.col('true_strength_state') == \"5vE\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_Ev5'),\n",
    "            (pl.when(((pl.col('true_strength_state') == \"Ev4\") & (pl.col('event_team_type') == 'away')) | \n",
    "                     ((pl.col('true_strength_state') == \"4vE\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_Ev4'),\n",
    "            (pl.when(((pl.col('true_strength_state') == \"Ev3\") & (pl.col('event_team_type') == 'away')) | \n",
    "                     ((pl.col('true_strength_state') == \"3vE\") & (pl.col('event_team_type') == 'home'))).then(pl.lit(1)).otherwise(pl.lit(0))).alias('state_Ev3'),\n",
    "            # Score State\n",
    "            (pl.when(pl.col('score_state') <= -4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_4'),\n",
    "            (pl.when(pl.col('score_state') == -3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_3'),\n",
    "            (pl.when(pl.col('score_state') == -2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_2'),\n",
    "            (pl.when(pl.col('score_state') == -1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_down_1'),\n",
    "            (pl.when(pl.col('score_state') == 0).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_even'),\n",
    "            (pl.when(pl.col('score_state') == 1).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_1'),\n",
    "            (pl.when(pl.col('score_state') == 2).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_2'),\n",
    "            (pl.when(pl.col('score_state') == 3).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_3'),\n",
    "            (pl.when(pl.col('score_state') >= 4).then(pl.lit(1)).otherwise(pl.lit(0))).alias('score_up_4'),\n",
    "            # Prior Shot Outcome\n",
    "            (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_shot_opp'),\n",
    "            (pl.when((pl.col('event_type_last') == \"MISSED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_miss_opp'),\n",
    "            (pl.when((pl.col('event_type_last') == \"BLOCKED_SHOT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_block_opp'),\n",
    "            # Prior Event - Non Shot\n",
    "            (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_opp'),\n",
    "            (pl.when((pl.col('event_type_last') == \"GIVEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_give_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_opp'),\n",
    "            (pl.when((pl.col('event_type_last') == \"TAKEAWAY\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_take_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_opp'),\n",
    "            (pl.when((pl.col('event_type_last') == \"HIT\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_hit_same'),\n",
    "            (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 1)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_win'),\n",
    "            (pl.when((pl.col('event_type_last') == \"FACEOFF\") & (pl.col('same_team_last') == 0)).then(pl.lit(1)).otherwise(pl.lit(0))).alias('prior_face_lose'),\n",
    "            # Handiness\n",
    "            (pl.when(\n",
    "                    ((pl.col('hand_R') == 1) & (pl.col('y_abs') > 0) & ((pl.col('event_angle') > 10))) |\n",
    "                    ((pl.col('hand_L') == 1) & (pl.col('y_abs') < 0) & ((pl.col('event_angle') > 10)))\n",
    "                    ).then(pl.lit(1)).otherwise(pl.lit(0)).alias('off_wing'))\n",
    "        ])\n",
    "        .with_columns([\n",
    "            # Create Rebound Flag\n",
    "            (pl.when(\n",
    "            (pl.col('prior_shot_same') == 1) &\n",
    "            (pl.col('seconds_since_last') <= 3)\n",
    "            ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rebound'),\n",
    "            (pl.when(\n",
    "            ((pl.col('prior_miss_same') == 1) | (pl.col('prior_block_same') == 1)) &\n",
    "            (pl.col('seconds_since_last') <= 3)\n",
    "            ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_post_miss_shot'),\n",
    "            # Set Play (Faceoff Win + Shot In 5 Seconds)\n",
    "            (pl.when(\n",
    "            (pl.col('prior_face_win') == 1) &\n",
    "            (pl.col('x_abs_last') > 25) &\n",
    "            (pl.col('seconds_since_last') <= 3)\n",
    "            ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_set_play'),\n",
    "            # Rush (Transition Play after Turnover)\n",
    "            (pl.when(\n",
    "            (pl.col('x_abs_last') < 0) &\n",
    "            (pl.col('seconds_since_last') <= 5) &\n",
    "            ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "            ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_rush_play'),\n",
    "            (pl.when(\n",
    "            (pl.col('x_abs_last') < 25) &\n",
    "            (pl.col('seconds_since_last') <= 3) &\n",
    "            ((pl.col('prior_give_opp') == 1) | (pl.col('prior_shot_opp') == 1) | (pl.col('prior_miss_opp') == 1) | (pl.col('prior_block_opp') == 1) | (pl.col('prior_take_same') == 1))\n",
    "            ).then(pl.lit(1)).otherwise(pl.lit(0))).alias('is_fast_rush_play')\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        # Get Creates Column Names + Slim\n",
    "        new_cols = model_prep.columns[-32:]\n",
    "        model_prep = (\n",
    "            model_prep\n",
    "            .select(['season', 'game_id', 'event_idx', 'secondary_type',\n",
    "                'is_goal',\n",
    "                'period', 'game_seconds','is_home', 'is_overtime', 'is_playoff',\n",
    "                'x_abs', 'y_abs', 'event_distance', 'event_angle',\n",
    "                'event_angle_change', 'event_angle_change_speed',\n",
    "                'seconds_since_last', 'distance_from_last', 'x_abs_last', 'y_abs_last', 'puck_speed_since_last',\n",
    "                'prior_event_EV',\n",
    "                'pos_F', 'pos_D', 'pos_G', 'hand_R', 'hand_L',\n",
    "                'event_team_shift_time_diff', 'event_team_toi', 'def_team_toi'] + new_cols\n",
    "            )\n",
    "        )\n",
    "    return model_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *f) Impute Secondary Type - Guess Using xGBoost*\n",
    "\n",
    "In 2023, the NGL Began using different shot_type categories, such as:\n",
    "- Poke\n",
    "- Batted\n",
    "- Between Legs\n",
    "- Cradle\n",
    "\n",
    "With these new classificiations, I wanted to impute the values here using a multi-classification model. I may hard code these reclassifications based on the type of how the type of sjot compares to the existing categories (ex: is a batted shot a deflected? is between teh legs a wrist shot?)\n",
    "| Shot Type     | EV               | PP               | SH               | EN               |\n",
    "|-------------- | ---------------- | ---------------- | ---------------- | ---------------- |\n",
    "| Wrist Shot    | 364 (80.00%)     | 99 (71.22%)      | 7 (77.78%)       | 1 (50.00%)       |\n",
    "| Slap Shot     | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        |\n",
    "| Tip-In        | 80 (17.58%)      | 39 (28.06%)      | 0 (0.00%)        | 1 (50.00%)       |\n",
    "| Backhand      | 5 (1.10%)        | 1 (0.72%)        | 2 (22.22%)       | 0 (0.00%)        |\n",
    "| Wrap-Around   | 6 (1.32%)        | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        |\n",
    "| Snap Shot     | 0  (0.00%)       | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        |\n",
    "| Deflected     | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        | 0 (0.00%)        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imp_sec_type(data):\n",
    "    \"\"\" This Function will looks to impute missing values in secondary type by using a classification model to guess the shot type\"\"\"\n",
    "\n",
    "    data = data.with_columns(pl.when(pl.col('secondary_type').is_in([\"Poked\", \"Batted\", \"Between Legs\"])).then(pl.lit(None)).otherwise(pl.col('secondary_type')).alias(\"secondary_type\"))\n",
    "\n",
    "    train = data.filter(~pl.col('secondary_type').is_null())\n",
    "    test = data.filter(pl.col('secondary_type').is_null())\n",
    "\n",
    "    exclude_cols = ['game_id', 'event_idx']\n",
    "    features = [t_col for t_col in train.columns if t_col not in exclude_cols and t_col != \"secondary_type\"]\n",
    "\n",
    "    train_features = train.select(features)\n",
    "    impute_features = test.select(features)\n",
    "\n",
    "\n",
    "    # Label encode the target variable\n",
    "    le = LabelEncoder()\n",
    "    train_target = le.fit_transform(\n",
    "        train.select('secondary_type')['secondary_type']\n",
    "    )\n",
    "    \n",
    "    # Train a classifier\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(train_features, train_target)\n",
    "\n",
    "    # Predict missing values\n",
    "    predicted_values = classifier.predict(impute_features)\n",
    "\n",
    "    # Decode predicted values\n",
    "    imputed_labels = le.inverse_transform(predicted_values)\n",
    "\n",
    "    # Use map_elements method to replace missing values\n",
    "    test = test.with_columns(pl.lit(imputed_labels).alias(\"event_detail\"))\n",
    "    train = train.with_columns(pl.col('secondary_type').alias(\"event_detail\"))\n",
    "    final_df = train.vstack(test)\n",
    "    final_df = (\n",
    "        final_df\n",
    "        .sort('season', 'game_id', 'event_idx')\n",
    "        .with_columns(\n",
    "        (pl.when(pl.col('event_detail') == \"Wrist\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('wrist_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Deflected\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('deflected_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Tip-In\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('tip_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Slap\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('slap_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Backhand\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('backhand_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Snap\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('snap_shot'),\n",
    "        (pl.when(pl.col('event_detail') == \"Wrap-Around\").then(pl.lit(1)).otherwise(pl.lit(0))).alias('wrap_shot')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Calculate Differences In New Shot Types\n",
    "    null_df = final_df.filter(pl.col('secondary_type').is_null())\n",
    "    rws = null_df.height\n",
    "    val_cts = null_df['event_detail'].value_counts()\n",
    "    val_cts = val_cts.with_columns(((pl.col('count')*100 / rws).round(2)).alias('Percent'))\n",
    "    val_cts = val_cts.with_columns(((val_cts['count'].map_elements(lambda x: f\"{x:,.0f}\")) + ' ' + (val_cts['Percent'].map_elements(lambda x: f\"({x:.2f}%)\"))).alias('Label')).sort(\"count\", descending=True).drop('count', 'Percent')\n",
    "    print(\"Rows Imputated Using XGB MultiClassifier of Null Shot Types (Blocked And Missed Shots): \"+ str(rws))\n",
    "    print(val_cts)\n",
    "    \n",
    "    return final_df.drop('secondary_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *g) Load Necessary Columns*\n",
    "\n",
    "The season loaded here has the correct column values that I want to keep for all data. This load simply initalizes a list of columns to keep for every load in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *h) Load Play-By-Play Data From NHL API via SDV Function*\n",
    "\n",
    "This cell will load each season of data, apply our cleaning and splitting functions, and then append all seasons of data to build our 4 dataframes for training and testing a model.\n",
    "\n",
    "Data from 2012 to 2022 will be used as the training data while data from the 2022-2023 & 2023-2024 seasons will be used primarily to test our models.\n",
    "\n",
    "*Note: I have mostly followed the same methodology as Evolving Wild up to this point. However I wanted to test the difference in their assumption of using only 7 years of PBP data for EV and PP models. Since Polars can be more efficient with large datasets like this, there was not much difference in performace of loading and training models on 10 years of data compared to 7.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Begin Loading + Cleaning Individual Seasons ==================\n",
      " \n",
      "Now Loading Play by Play Data From 2010-2011 NHL Season\n",
      "Now Loading Play by Play Data From 2011-2012 NHL Season\n",
      "Now Loading Play by Play Data From 2012-2013 NHL Season\n",
      "Now Loading Play by Play Data From 2013-2014 NHL Season\n",
      "Now Loading Play by Play Data From 2014-2015 NHL Season\n",
      "Now Loading Play by Play Data From 2015-2016 NHL Season\n",
      "Now Loading Play by Play Data From 2016-2017 NHL Season\n",
      "Now Loading Play by Play Data From 2017-2018 NHL Season\n",
      "Now Loading Play by Play Data From 2018-2019 NHL Season\n",
      "Now Loading Play by Play Data From 2019-2020 NHL Season\n",
      "Now Loading Play by Play Data From 2020-2021 NHL Season\n",
      "Now Loading Play by Play Data From 2021-2022 NHL Season\n",
      "Now Loading Play by Play Data From 2022-2023 NHL Season\n",
      "Now Loading Play by Play Data From 2023-2024 NHL Season\n",
      " \n",
      "================== Begin Appending DataFrames Together ==================\n",
      " \n",
      "857841 Total Shots in Even Strength DF\n",
      "215998 Total Shots in Power Play DF\n",
      "35805 Total Shots in Short Handed (Offense) DF\n",
      "7599 Total Shots in Empty Net DF\n",
      " \n",
      "================== Begin Imputing Null Shot Type Values ==================\n",
      " \n",
      "Rows Imputated Using XGB MultiClassifier of Null Shot Types (Blocked And Missed Shots): 1171\n",
      "shape: (6, 2)\n",
      "┌──────────────┬──────────────┐\n",
      "│ event_detail ┆ Label        │\n",
      "│ ---          ┆ ---          │\n",
      "│ str          ┆ str          │\n",
      "╞══════════════╪══════════════╡\n",
      "│ Wrist        ┆ 939 (80.19%) │\n",
      "│ Tip-In       ┆ 159 (13.58%) │\n",
      "│ Backhand     ┆ 39 (3.33%)   │\n",
      "│ Wrap-Around  ┆ 23 (1.96%)   │\n",
      "│ Slap         ┆ 8 (0.68%)    │\n",
      "│ Snap         ┆ 3 (0.26%)    │\n",
      "└──────────────┴──────────────┘\n",
      "Rows Imputated Using XGB MultiClassifier of Null Shot Types (Blocked And Missed Shots): 263\n",
      "shape: (4, 2)\n",
      "┌──────────────┬──────────────┐\n",
      "│ event_detail ┆ Label        │\n",
      "│ ---          ┆ ---          │\n",
      "│ str          ┆ str          │\n",
      "╞══════════════╪══════════════╡\n",
      "│ Wrist        ┆ 200 (76.05%) │\n",
      "│ Tip-In       ┆ 56 (21.29%)  │\n",
      "│ Slap         ┆ 6 (2.28%)    │\n",
      "│ Backhand     ┆ 1 (0.38%)    │\n",
      "└──────────────┴──────────────┘\n",
      "Rows Imputated Using XGB MultiClassifier of Null Shot Types (Blocked And Missed Shots): 44\n",
      "shape: (4, 2)\n",
      "┌──────────────┬─────────────┐\n",
      "│ event_detail ┆ Label       │\n",
      "│ ---          ┆ ---         │\n",
      "│ str          ┆ str         │\n",
      "╞══════════════╪═════════════╡\n",
      "│ Wrist        ┆ 33 (75.00%) │\n",
      "│ Backhand     ┆ 9 (20.45%)  │\n",
      "│ Wrap-Around  ┆ 1 (2.27%)   │\n",
      "│ Slap         ┆ 1 (2.27%)   │\n",
      "└──────────────┴─────────────┘\n",
      "Rows Imputated Using XGB MultiClassifier of Null Shot Types (Blocked And Missed Shots): 36\n",
      "shape: (1, 2)\n",
      "┌──────────────┬──────────────┐\n",
      "│ event_detail ┆ Label        │\n",
      "│ ---          ┆ ---          │\n",
      "│ str          ┆ str          │\n",
      "╞══════════════╪══════════════╡\n",
      "│ Wrist        ┆ 36 (100.00%) │\n",
      "└──────────────┴──────────────┘\n",
      "================== End Loading Data From the 20102011 Season to the 20232024 Season ==================\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the dataframes\n",
    "ev_dfs = []\n",
    "pp_dfs = []\n",
    "sh_dfs = []\n",
    "en_dfs = []\n",
    "\n",
    "print(\"================== Begin Loading + Cleaning Individual Seasons ==================\")\n",
    "print(\" \")\n",
    "\n",
    "for i in range(2010,2024):\n",
    "\n",
    "    # Begin Load\n",
    "    print(f\"Now Loading Play by Play Data From {i}-{i+1} NHL Season\")\n",
    "    \n",
    "    # Basic Clean/Manipulation\n",
    "    df = clean_pbp_data(pl.read_parquet(f'https://raw.githubusercontent.com/twinfield10/NHL-Data/main/PBP/parquet/API_RAW_PBP_Data_{i}{i+1}.parquet'))\n",
    "\n",
    "    # Create Indexes\n",
    "    df = index_input_data(df)\n",
    "\n",
    "    if i == 2023:\n",
    "        CURRENT_DF = df\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    # Split by Strength\n",
    "    ev, pp, sh, en = split_by_strength(df)\n",
    "\n",
    "    # Prep For Model (OHE + Other Features)\n",
    "    ev = model_prep(ev, \"EV\")\n",
    "    pp = model_prep(pp, \"PP\")\n",
    "    sh = model_prep(sh, \"SH\")\n",
    "    en = model_prep(en, \"EN\")\n",
    "\n",
    "    # Append the modified dataframe to the list\n",
    "    ev_dfs.append(ev)\n",
    "    pp_dfs.append(pp)\n",
    "    sh_dfs.append(sh)\n",
    "    en_dfs.append(en)\n",
    "\n",
    "    # Create the PBP DataFrames\n",
    "print(\" \")\n",
    "print(\"================== Begin Appending DataFrames Together ==================\")\n",
    "print(\" \")\n",
    "\n",
    "# EV\n",
    "EV_PBP = ev_dfs[4]\n",
    "for df in ev_dfs[5:]:\n",
    "    EV_PBP = EV_PBP.extend(df)\n",
    "print(str(EV_PBP.height) + \" Total Shots in Even Strength DF\")\n",
    "\n",
    "# PP\n",
    "PP_PBP = pp_dfs[0]\n",
    "for df in pp_dfs[1:]:\n",
    "    PP_PBP = PP_PBP.extend(df)\n",
    "print(str(PP_PBP.height) + \" Total Shots in Power Play DF\")\n",
    "\n",
    "# SH\n",
    "SH_PBP = sh_dfs[0]\n",
    "for df in sh_dfs[1:]:\n",
    "    SH_PBP = SH_PBP.extend(df)\n",
    "print(str(SH_PBP.height) + \" Total Shots in Short Handed (Offense) DF\")\n",
    "\n",
    "# EN\n",
    "EN_PBP = en_dfs[0]\n",
    "for df in en_dfs[1:]:\n",
    "    EN_PBP = EN_PBP.extend(df)\n",
    "print(str(EN_PBP.height) + \" Total Shots in Empty Net DF\")\n",
    "\n",
    "# Imputate + Clean Null Values of Shot Type\n",
    "print(\" \")\n",
    "print(\"================== Begin Imputing Null Shot Type Values ==================\")\n",
    "print(\" \")\n",
    "\n",
    "EV_PBP = imp_sec_type(EV_PBP).drop('event_detail', 'event_team_toi', 'def_team_toi')\n",
    "PP_PBP = imp_sec_type(PP_PBP).drop('event_detail', 'event_team_toi', 'def_team_toi')\n",
    "SH_PBP = imp_sec_type(SH_PBP).drop('event_detail', 'event_team_toi', 'def_team_toi')\n",
    "EN_PBP = imp_sec_type(EN_PBP).drop('event_detail', 'event_team_toi', 'def_team_toi')\n",
    "\n",
    "print(\"================== End Loading Data From the \" + str(EN_PBP['season'].min()) + \" Season to the \" + str(EN_PBP['season'].max())  + \" Season ==================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Convert To Pandas For Model + Check Nulls & Constant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PD = EV_PBP.to_pandas()\n",
    "PP_PD = PP_PBP.to_pandas()\n",
    "SH_PD = SH_PBP.to_pandas()\n",
    "EN_PD = EN_PBP.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "for df in [EV_PD, PP_PD, SH_PD, EN_PD]:\n",
    "    # Get the count of null values in each column\n",
    "    null_counts = df.filter(df['season'] != 20232024).isnull().sum()\n",
    "    # Filter columns with count > 0\n",
    "    filtered_columns = null_counts[null_counts > 0]\n",
    "    # Show the filtered DataFrame\n",
    "    print(filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PD.dropna(how = 'any', inplace = True)\n",
    "PP_PD.dropna(how = 'any', inplace = True)\n",
    "SH_PD.dropna(how = 'any', inplace = True)\n",
    "EN_PD.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV Constant Columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "PP Constant Columns\n",
      "Index(['state_6v5', 'state_6v4'], dtype='object')\n",
      "SH Constant Columns\n",
      "Index([], dtype='object')\n",
      "EN Constant Columns\n",
      "Index(['score_down_4', 'score_down_3', 'score_down_2', 'score_down_1',\n",
      "       'is_set_play'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check Constants\n",
    "print(\"EV Constant Columns\")\n",
    "print(EV_PD.columns[EV_PD.std() == 0])\n",
    "print(\"PP Constant Columns\")\n",
    "print(PP_PD.columns[PP_PD.std() == 0])\n",
    "print(\"SH Constant Columns\")\n",
    "print(SH_PD.columns[SH_PD.std() == 0])\n",
    "print(\"EN Constant Columns\")\n",
    "print(EN_PD.columns[EN_PD.std() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PD = EV_PD.drop(EV_PD.columns[EV_PD.std() == 0], axis = 1)\n",
    "PP_PD = PP_PD.drop(PP_PD.columns[PP_PD.std() == 0], axis = 1)\n",
    "SH_PD = SH_PD.drop(SH_PD.columns[SH_PD.std() == 0], axis = 1)\n",
    "EN_PD = EN_PD.drop(EN_PD.columns[EN_PD.std() == 0], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Build xGBoost Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Step 1: Create Matricies and Splits For Model Training/Validation/Testing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matricies(data):\n",
    "    # Initialize Data\n",
    "    df = data[data['season'] != 20232024]\n",
    "    current_df = data[data['season'] == 20232024]\n",
    "\n",
    "    # Initalize Features + Target\n",
    "    target = \"is_goal\"\n",
    "    features = [col for col in df.columns.tolist() if col not in ['season', 'game_id', 'event_idx'] + [target]]\n",
    "        \n",
    "    # Create Train, Valid, Test, TrainValid (For Final Model) DataFrames\n",
    "    trainvalid_df = df.sample(frac=0.8, random_state=66)\n",
    "    test_df = df.drop(trainvalid_df.index)\n",
    "    train_df = trainvalid_df.sample(frac=0.8, random_state=66)\n",
    "    valid_df = trainvalid_df.drop(train_df.index)\n",
    "\n",
    "    # Matricies\n",
    "    dtrain = xgb.DMatrix(data=train_df[features], label=train_df[target])\n",
    "    dvalid = xgb.DMatrix(data=valid_df[features], label=valid_df[target])\n",
    "    dtest = xgb.DMatrix(data=test_df[features], label=test_df[target])\n",
    "    dtrainvalid = xgb.DMatrix(data=pd.concat([train_df, valid_df])[features], label=pd.concat([train_df, valid_df])[target])\n",
    "    dcurrent = xgb.DMatrix(data=current_df[features], label=current_df[target])\n",
    "    dtestall = xgb.DMatrix(data=pd.concat([test_df, current_df])[features], label=pd.concat([test_df, current_df])[target])\n",
    "\n",
    "    return dtrain, dvalid, dtest, dtrainvalid, dcurrent, dtestall, current_df\n",
    "\n",
    "# Return Results by Strength #\n",
    "ev_dtrain, ev_dvalid, ev_dtest, ev_dtrainvalid, ev_dcurrent, ev_dtestall, ev_df = create_matricies(EV_PD)\n",
    "pp_dtrain, pp_dvalid, pp_dtest, pp_dtrainvalid, pp_dcurrent, pp_dtestall, pp_df = create_matricies(PP_PD)\n",
    "sh_dtrain, sh_dvalid, sh_dtest, sh_dtrainvalid, sh_dcurrent, sh_dtestall, sh_df = create_matricies(SH_PD)\n",
    "en_dtrain, en_dvalid, en_dtest, en_dtrainvalid, en_dcurrent, en_dtestall, en_df = create_matricies(EN_PD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Hypertune Paramaters:\n",
    "\n",
    "Firstly, I want to use the Optuna package to help me run trials for hypertuning my models. This package lets me quickly run through many options for hypertuning and producing the most predictive model.\n",
    "\n",
    "- **Primary Option: Find Best Tree Parameters, Then Find Best Boosting Parameters**\n",
    "    - The goal of this is to quickly be able to tune parameters.\n",
    "    - First, we find a learning rate that will allow us to check tree parameters at a super fast rate.\n",
    "        - eta will be set at a fixed rate and we will find the best *max_depth*, *min_child_weight*, etc.\n",
    "    - Once optimal tree-based parameters are settled on, we will slow (or optimize?) learning rate.\n",
    "        - This allows the model to learn slowly and recognize patterns.\n",
    "\n",
    "- **Secondary Option: Run all Parameters Through Optuna Trials**\n",
    "    - This method is more straightforward but will take longer.\n",
    "    - This may, however, produce a better model than Option 1.\n",
    "\n",
    "In both hypertuning options, I want to be able to evaluate each trial using two error metrics, logloss and auc. I am continuing my research to determine which error metric is better for this type of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Option: Find Best Tree Parameters First, Then Optimize Boosting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline Functions And Variables\n",
    "\n",
    "# Variables:\n",
    "\n",
    "## Evaluation Metric:\n",
    "e_m = 'auc'\n",
    "\n",
    "# Functions:\n",
    "def score_model(model: xgb.core.Booster, dmat: xgb.core.DMatrix) -> float:\n",
    "    y_true = dmat.get_label() \n",
    "    y_pred = model.predict(dmat)\n",
    "\n",
    "    # AUC\n",
    "    auc_roc = roc_auc_score(y_true, y_pred)\n",
    "    # LogLoss\n",
    "    logloss_score = log_loss(y_true, y_pred)\n",
    "\n",
    "    return auc_roc, logloss_score\n",
    "\n",
    "def get_fast_eta(dtrain, dvalid, range_vec, eval_met = e_m):\n",
    "    \"\"\" INPUTS:\n",
    "    Data = Set Of Train/Valid/Test Data (Will be split .4/.4/.2)\n",
    "    start_lr = Fixed Learning Rate To Test With Data\n",
    "    \"\"\"\n",
    "\n",
    "    base_params = {\n",
    "    'objective': 'binary:logistic'\n",
    "    }\n",
    "\n",
    "    eta_list = []\n",
    "    time_list = []\n",
    "\n",
    "    for i in range_vec:\n",
    "        params = {\n",
    "            'tree_method': 'approx',\n",
    "            'eval_metric': eval_met,\n",
    "            'learning_rate': i,\n",
    "\n",
    "        }\n",
    "\n",
    "        params.update(base_params)\n",
    "\n",
    "        # Test Model Time\n",
    "        tic = time.time()\n",
    "        model = xgb.train(params=params, dtrain=dtrain,\n",
    "                        evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                        num_boost_round=10000,\n",
    "                        early_stopping_rounds=50,\n",
    "                        verbose_eval=0)\n",
    "        toc = time.time()\n",
    "        auc_score, ll_score = score_model(model, dvalid)\n",
    "        print(f'ETA: {i} | {toc - tic:.1f} seconds | LogLoss: {ll_score:.4f} | AUC: {auc_score:.4f}')\n",
    "                \n",
    "        eta_list.append(i)\n",
    "        time_list.append(round(toc-tic, 2))\n",
    "\n",
    "    # Create DataFrame\n",
    "    data = {'eta': eta_list, 'time': time_list}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Plotting\n",
    "    plt.plot(df['eta'], df['time'], marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('eta')\n",
    "    plt.ylabel('time')\n",
    "    plt.title('Plot of eta vs. time')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Even Strength ==================================================\n",
      "================================================== Man-Advantage ==================================================\n",
      "================================================== Short-Handed ==================================================\n",
      "ETA: 0.005 | 1.7 seconds | LogLoss: 0.2519 | AUC: 0.7998\n",
      "ETA: 0.01 | 4.7 seconds | LogLoss: 0.2260 | AUC: 0.8045\n",
      "ETA: 0.0125 | 3.8 seconds | LogLoss: 0.2261 | AUC: 0.8044\n",
      "ETA: 0.015 | 3.0 seconds | LogLoss: 0.2260 | AUC: 0.8045\n",
      "ETA: 0.0175 | 1.9 seconds | LogLoss: 0.2266 | AUC: 0.8037\n",
      "ETA: 0.02 | 2.7 seconds | LogLoss: 0.2261 | AUC: 0.8047\n",
      "ETA: 0.0225 | 2.0 seconds | LogLoss: 0.2259 | AUC: 0.8048\n",
      "ETA: 0.025 | 2.8 seconds | LogLoss: 0.2261 | AUC: 0.8046\n",
      "ETA: 0.0275 | 1.8 seconds | LogLoss: 0.2259 | AUC: 0.8050\n",
      "ETA: 0.03 | 2.0 seconds | LogLoss: 0.2264 | AUC: 0.8040\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Empty Net ==================================================\n",
      "ETA: 0.005 | 0.4 seconds | LogLoss: 0.6224 | AUC: 0.6989\n",
      "ETA: 0.01 | 0.3 seconds | LogLoss: 0.6088 | AUC: 0.6951\n",
      "ETA: 0.015 | 0.3 seconds | LogLoss: 0.6025 | AUC: 0.6955\n",
      "ETA: 0.02 | 0.3 seconds | LogLoss: 0.5984 | AUC: 0.6930\n",
      "ETA: 0.0225 | 0.3 seconds | LogLoss: 0.5982 | AUC: 0.6947\n",
      "ETA: 0.025 | 0.4 seconds | LogLoss: 0.5905 | AUC: 0.6935\n",
      "ETA: 0.0275 | 0.3 seconds | LogLoss: 0.5945 | AUC: 0.6953\n",
      "ETA: 0.03 | 0.2 seconds | LogLoss: 0.5933 | AUC: 0.6951\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Determing Quickest Learning Rates ##\n",
    "\n",
    "# Get Learning Rate For Each Strength State #\n",
    "ev_vec = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1] #[0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.085, 0.1]\n",
    "pp_vec = [0.05, 0.075, 0.1, 0.15, 0.2, 0.3, 0.5, 0.75, 1] #[0.01, 0.02, 0.03, 0.04 , 0.05, 0.075, 0.1, 0.125, 0.15, 0.2]\n",
    "sh_vec = [0.005, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.0225, 0.025, 0.0275, 0.03] #[0.005, 0.075, 0.01, 0.0125, 0.015, 0.0175, 0.02, 0.03, 0.04]\n",
    "en_vec = [0.005, 0.01, 0.015, 0.02, 0.0225, 0.025, 0.0275, 0.03] #[0.02, 0.0225, 0.025, 0.0275, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "\n",
    "# Run\n",
    "print('='*50, \"Even Strength\", \"=\"*50)\n",
    "get_fast_eta(dtrain = ev_dtrain, dvalid = ev_dvalid, eval_met = e_m, range_vec = ev_vec)\n",
    "print('='*50, \"Man-Advantage\", \"=\"*50)\n",
    "get_fast_eta(dtrain = pp_dtrain, dvalid = pp_dvalid, eval_met = e_m, range_vec = pp_vec)\n",
    "print('='*50, \"Short-Handed\", \"=\"*50)\n",
    "get_fast_eta(dtrain = sh_dtrain, dvalid = sh_dvalid, eval_met = e_m, range_vec = sh_vec)\n",
    "print('='*50, \"Empty Net\", \"=\"*50)\n",
    "get_fast_eta(dtrain = en_dtrain, dvalid = en_dvalid, eval_met = e_m, range_vec = en_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed Learning Rates (Time Optimized)\n",
    "EV_eta = 0.3 # (16.5 seconds | LogLoss: 0.1959 | AUC: 0.7730)\n",
    "PP_eta = 0.2 # (4.1 seconds | LogLoss: 0.2859 | AUC: 0.7062)\n",
    "SH_eta = 0.01 # (1.8 seconds | LogLoss: 0.2259 | AUC: 0.8050)\n",
    "EN_eta = 0.001 # (0.3 seconds | LogLoss: 0.6025 | AUC: 0.6955)\n",
    "\n",
    "# Fixed Learning Rates (AUC Optimized)\n",
    "#EV_eta = 0.04\n",
    "#PP_eta = 0.03\n",
    "#SH_eta = 0.02\n",
    "#EN_eta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, dtrain, dvalid, lr, eval_met = e_m):\n",
    "    \"\"\" Using Optuna, I will take the fixed learning rate from above and use it to hypertune parameters related to trees (not boosting)\"\"\"\n",
    "\n",
    "    base_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': eval_met,\n",
    "    'learning_rate': lr\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'tree_method': trial.suggest_categorical('tree_method', ['approx', 'hist']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 6),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'max_delta_step': trial.suggest_int('max_delta_step', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.9),\n",
    "        'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.001, 10, log=True)\n",
    "    }\n",
    "    num_boost_round = 10000\n",
    "    params.update(base_params)\n",
    "    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, f'valid-{eval_met}')\n",
    "    model = xgb.train(params=params, dtrain=dtrain, num_boost_round=num_boost_round,\n",
    "                      evals=[(dtrain, 'train'), (dvalid, 'valid')],\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=0,\n",
    "                      callbacks=[pruning_callback]\n",
    "                      )\n",
    "    trial.set_user_attr('best_iteration', model.best_iteration)\n",
    "    return model.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 13:12:10,163] A new study created in memory with name: no-name-2b2a7f0a-1dc4-44c3-ac61-2831f9d91c64\n",
      "[I 2024-02-05 13:12:18,633] Trial 0 finished with value: 0.7823238851418842 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 10, 'subsample': 0.8364932101915348, 'colsample_bynode': 0.8613021421899187, 'reg_alpha': 9.61121037604149}. Best is trial 0 with value: 0.7823238851418842.\n",
      "[I 2024-02-05 13:12:48,679] Trial 1 finished with value: 0.7820529000081571 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 2, 'subsample': 0.780027204616762, 'colsample_bynode': 0.5681319489631267, 'reg_alpha': 3.953807603593903}. Best is trial 0 with value: 0.7823238851418842.\n",
      "[I 2024-02-05 13:12:55,898] Trial 2 finished with value: 0.7813909455698679 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.7114885933939243, 'colsample_bynode': 0.7847035452441409, 'reg_alpha': 0.014133354078030192}. Best is trial 0 with value: 0.7823238851418842.\n",
      "[I 2024-02-05 13:13:12,652] Trial 3 finished with value: 0.7824533707902029 and parameters: {'tree_method': 'hist', 'max_depth': 3, 'min_child_weight': 4, 'max_delta_step': 4, 'subsample': 0.7881325935269794, 'colsample_bynode': 0.5377414858884355, 'reg_alpha': 0.00805544243490735}. Best is trial 3 with value: 0.7824533707902029.\n",
      "[I 2024-02-05 13:13:28,555] Trial 4 finished with value: 0.7804769246934989 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 3, 'max_delta_step': 3, 'subsample': 0.6554746583261235, 'colsample_bynode': 0.5686084314371924, 'reg_alpha': 0.08558113664471088}. Best is trial 3 with value: 0.7824533707902029.\n",
      "[I 2024-02-05 13:13:28,929] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:13:29,111] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:13:29,479] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:13:36,886] Trial 8 pruned. Trial was pruned at iteration 87.\n",
      "[I 2024-02-05 13:18:03,456] Trial 9 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:18:04,058] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,123] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,228] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,310] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,379] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,457] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,528] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,630] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:04,988] Trial 18 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:18:05,369] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:05,557] Trial 20 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:18:05,716] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:05,872] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:06,040] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:06,193] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:06,361] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:06,705] Trial 26 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:18:07,088] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:07,250] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:18:09,787] Trial 29 pruned. Trial was pruned at iteration 28.\n",
      "[I 2024-02-05 13:18:09,839] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:27:07,530] Trial 31 finished with value: 0.7810032265823587 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 6, 'max_delta_step': 3, 'subsample': 0.7271927634673244, 'colsample_bynode': 0.8908007446199415, 'reg_alpha': 0.014519073098759314}. Best is trial 3 with value: 0.7824533707902029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate ==================================================\n",
      "========================= HyperTuning Results For Fixed Learning Rate = 0.3\n",
      "Best auc Score = 0.7824533707902029\n",
      "Best Boosting Round: 179\n",
      "========== Best Tree Params ==========\n",
      "tree_method : hist\n",
      "max_depth : 3\n",
      "min_child_weight : 4\n",
      "max_delta_step : 4\n",
      "subsample : 0.7881325935269794\n",
      "colsample_bynode : 0.5377414858884355\n",
      "reg_alpha : 0.00805544243490735\n",
      " \n",
      "================================================== Stage 2 - Boosting Parameters ==================================================\n",
      "best scores (AUC , LOGLOSS) = (0.7814432601442669, 0.19416716655973218)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.005\n",
      "best boosting round: 9999\n",
      "best scores (AUC , LOGLOSS) = (0.7815573004533684, 0.19412409277422202)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.01\n",
      "best boosting round: 7096\n",
      "best scores (AUC , LOGLOSS) = (0.7816555446181082, 0.19404526529930377)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.025\n",
      "best boosting round: 2578\n",
      "best scores (AUC , LOGLOSS) = (0.7812926936951247, 0.19432933778629508)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.05\n",
      "best boosting round: 1431\n",
      "best scores (AUC , LOGLOSS) = (0.7807220449694328, 0.19472535487596976)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.075\n",
      "best boosting round: 791\n",
      "best scores (AUC , LOGLOSS) = (0.7804206548874715, 0.19510711772374834)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.1\n",
      "best boosting round: 584\n",
      "     eta       auc   logloss   itr\n",
      "0  0.005  0.781443  0.194167  9999\n",
      "1  0.010  0.781557  0.194124  7096\n",
      "2  0.025  0.781656  0.194045  2578\n",
      "3  0.050  0.781293  0.194329  1431\n",
      "4  0.075  0.780722  0.194725   791\n",
      "5  0.100  0.780421  0.195107   584\n",
      "Final Even Strength Model ==========================\n",
      "test score against old data (AUC, LOGLOSS) = (0.774743159252879, 0.19768627538949593)\n",
      "test score against current data (AUC, LOGLOSS) = (0.7653724810299594, 0.20533079272432903)\n",
      "test score against all test data (AUC, LOGLOSS) = (0.7724603296178907, 0.19960846931079412)\n",
      "parameters ---------------------------\n",
      "tree_method : hist\n",
      "max_depth : 3\n",
      "min_child_weight : 4\n",
      "max_delta_step : 4\n",
      "subsample : 0.7881325935269794\n",
      "colsample_bynode : 0.5377414858884355\n",
      "reg_alpha : 0.00805544243490735\n",
      "learning_rate : 0.025\n",
      "num_boost_round: 2578\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=71)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "tic = time.time()\n",
    "while time.time() - tic < 600:\n",
    "    study.optimize(lambda trial: objective(trial, dtrain = ev_dtrain, dvalid = ev_dvalid, lr = EV_eta), n_trials=1)\n",
    "\n",
    "print('='*50,'Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate', '='*50)\n",
    "print('='*25, f'HyperTuning Results For Fixed Learning Rate = {EV_eta}')\n",
    "print(f'Best {e_m} Score = {study.best_trial.value}')\n",
    "print(f'Best Boosting Round: {study.best_trial.user_attrs[\"best_iteration\"]}')\n",
    "print(\"=\"*10,'Best Tree Params',\"=\"*10)\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(k, ':', v)\n",
    "\n",
    "#### STAGE 2 ####\n",
    "print(\" \")\n",
    "print('='*50, 'Stage 2 - Boosting Parameters', '='*50)\n",
    "lr_list = []\n",
    "auc_score_list = []\n",
    "logloss_list = []\n",
    "iterations_list = []\n",
    "for i in [0.005, 0.01, 0.025, 0.05, 0.075, 0.1]:\n",
    "    low_learning_rate = i\n",
    "    params = {}\n",
    "    params.update(study.best_trial.params)\n",
    "    params['learning_rate'] = i\n",
    "    model_stage2 = xgb.train(params=params, dtrain=ev_dtrain, \n",
    "                             num_boost_round=10000,\n",
    "                             evals=[(ev_dtrain, 'train'), (ev_dvalid, 'valid')],\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=0)\n",
    "    \n",
    "    print(f'best scores (AUC , LOGLOSS) = {score_model(model_stage2, ev_dvalid)}')\n",
    "    print('boosting params ---------------------------')\n",
    "    print(f'learning rate: {params[\"learning_rate\"]}')\n",
    "    print(f'best boosting round: {model_stage2.best_iteration}')\n",
    "    auc_score, ll_score = score_model(model_stage2, ev_dvalid)\n",
    "\n",
    "    lr_list.append(i)\n",
    "    auc_score_list.append(auc_score)\n",
    "    logloss_list.append(ll_score)\n",
    "    iterations_list.append(model_stage2.best_iteration)\n",
    "\n",
    "lr_df = pd.DataFrame({\n",
    "    'eta': lr_list,\n",
    "    'auc': auc_score_list,\n",
    "    'logloss': logloss_list,\n",
    "    'itr': iterations_list\n",
    "})\n",
    "print(lr_df)\n",
    "\n",
    "best_lr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['eta'].iloc[0] \n",
    "best_itr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['itr'].iloc[0] \n",
    "\n",
    "params['learning_rate'] = best_lr\n",
    "ev_model_final = xgb.train(params=params, dtrain=ev_dtrainvalid, \n",
    "                        num_boost_round=best_itr,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "print('Final Even Strength Model ==========================')\n",
    "print(f'test score against old data (AUC, LOGLOSS) = {score_model(ev_model_final, ev_dtest)}')\n",
    "print(f'test score against current data (AUC, LOGLOSS) = {score_model(ev_model_final, ev_dcurrent)}')\n",
    "print(f'test score against all test data (AUC, LOGLOSS) = {score_model(ev_model_final, ev_dtestall)}')\n",
    "print('parameters ---------------------------')\n",
    "for k, v in params.items():\n",
    "    print(k, ':', v)\n",
    "print(f'num_boost_round: {best_itr}')\n",
    "best_ev_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 13:48:24,560] A new study created in memory with name: no-name-ba6f43ed-929f-42d2-a464-b93accc38444\n",
      "[I 2024-02-05 13:48:27,256] Trial 0 finished with value: 0.7152591307201506 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 10, 'subsample': 0.8364932101915348, 'colsample_bynode': 0.8613021421899187, 'reg_alpha': 9.61121037604149}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:34,163] Trial 1 finished with value: 0.7138666954583388 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 2, 'subsample': 0.780027204616762, 'colsample_bynode': 0.5681319489631267, 'reg_alpha': 3.953807603593903}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:35,982] Trial 2 finished with value: 0.7121643698412707 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.7114885933939243, 'colsample_bynode': 0.7847035452441409, 'reg_alpha': 0.014133354078030192}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:38,164] Trial 3 finished with value: 0.7137980847884857 and parameters: {'tree_method': 'hist', 'max_depth': 3, 'min_child_weight': 4, 'max_delta_step': 4, 'subsample': 0.7881325935269794, 'colsample_bynode': 0.5377414858884355, 'reg_alpha': 0.00805544243490735}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:41,796] Trial 4 finished with value: 0.7110975746562999 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 3, 'max_delta_step': 3, 'subsample': 0.6554746583261235, 'colsample_bynode': 0.5686084314371924, 'reg_alpha': 0.08558113664471088}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:41,887] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:41,931] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,029] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,065] Trial 8 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:42,157] Trial 9 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:42,263] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,314] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,368] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,467] Trial 13 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:42,568] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,670] Trial 15 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:42,770] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:42,912] Trial 17 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:42,968] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,067] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,763] Trial 20 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:48:43,869] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,894] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,920] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,945] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:43,972] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:44,029] Trial 26 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:44,055] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:44,114] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:44,547] Trial 29 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-02-05 13:48:44,572] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:44,600] Trial 31 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:44,943] Trial 32 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-02-05 13:48:45,001] Trial 33 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:45,027] Trial 34 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:45,686] Trial 35 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:48:45,793] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:45,964] Trial 37 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:48:48,742] Trial 38 pruned. Trial was pruned at iteration 54.\n",
      "[I 2024-02-05 13:48:48,844] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:48,992] Trial 40 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:49,100] Trial 41 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:49,160] Trial 42 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:49,268] Trial 43 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:49,327] Trial 44 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:49,430] Trial 45 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:49,570] Trial 46 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:49,672] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:49,823] Trial 48 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:49,933] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:49,989] Trial 50 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:50,136] Trial 51 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:50,240] Trial 52 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:50,350] Trial 53 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:50,455] Trial 54 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:50,509] Trial 55 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:50,629] Trial 56 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:48:54,782] Trial 57 finished with value: 0.7148529056480953 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 8, 'max_delta_step': 9, 'subsample': 0.8358321448417042, 'colsample_bynode': 0.850442774389779, 'reg_alpha': 0.2687105563251391}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:55,933] Trial 58 pruned. Trial was pruned at iteration 49.\n",
      "[I 2024-02-05 13:48:55,960] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:56,018] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:56,077] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:56,136] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:56,849] Trial 63 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:48:57,005] Trial 64 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:48:57,107] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:57,164] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,126] Trial 67 finished with value: 0.7147679241256623 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 4, 'max_delta_step': 5, 'subsample': 0.8713264211284975, 'colsample_bynode': 0.7378855638629183, 'reg_alpha': 0.060151283380114294}. Best is trial 0 with value: 0.7152591307201506.\n",
      "[I 2024-02-05 13:48:59,152] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,182] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,211] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,242] Trial 71 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,273] Trial 72 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,303] Trial 73 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,364] Trial 74 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,468] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,527] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,634] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,834] Trial 78 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:48:59,936] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:48:59,965] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,011] Trial 81 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:00,041] Trial 82 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,072] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,119] Trial 84 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:00,151] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,211] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,525] Trial 87 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:49:00,581] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,691] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,753] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,856] Trial 91 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,887] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,915] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,946] Trial 94 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:00,977] Trial 95 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,324] Trial 96 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:01,431] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,488] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,588] Trial 99 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,647] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,755] Trial 101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,786] Trial 102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,833] Trial 103 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:01,864] Trial 104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,891] Trial 105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:01,949] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:02,060] Trial 107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:02,092] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:02,151] Trial 109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:02,294] Trial 110 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:02,361] Trial 111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:02,801] Trial 112 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:49:03,393] Trial 113 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:49:03,453] Trial 114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:03,808] Trial 115 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:04,203] Trial 116 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:49:04,312] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:04,417] Trial 118 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:04,520] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:04,582] Trial 120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:04,642] Trial 121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:04,749] Trial 122 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:05,644] Trial 123 pruned. Trial was pruned at iteration 17.\n",
      "[I 2024-02-05 13:49:05,799] Trial 124 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:05,862] Trial 125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:05,970] Trial 126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:06,029] Trial 127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:06,138] Trial 128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:06,250] Trial 129 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:06,358] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:06,512] Trial 131 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:06,718] Trial 132 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:06,780] Trial 133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:06,892] Trial 134 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:06,999] Trial 135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:07,504] Trial 136 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:49:07,630] Trial 137 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:07,692] Trial 138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:07,851] Trial 139 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:12,714] Trial 140 finished with value: 0.716594038449521 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 3, 'subsample': 0.8332146323796362, 'colsample_bynode': 0.8601547071390518, 'reg_alpha': 3.3305338985015873}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:49:13,364] Trial 141 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:49:13,675] Trial 142 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:49:13,771] Trial 143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:14,123] Trial 144 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:14,627] Trial 145 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:49:14,740] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:14,802] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:14,905] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:14,969] Trial 149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:15,076] Trial 150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:15,512] Trial 151 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:49:15,578] Trial 152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:20,376] Trial 153 finished with value: 0.7159748248586131 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 3, 'subsample': 0.8712418644356694, 'colsample_bynode': 0.8195408580402748, 'reg_alpha': 2.6716812583521445}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:49:20,631] Trial 154 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:21,310] Trial 155 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:49:21,372] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:21,603] Trial 157 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:49:21,765] Trial 158 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:21,874] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:21,937] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:22,002] Trial 161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:22,204] Trial 162 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:22,555] Trial 163 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:22,754] Trial 164 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:23,098] Trial 165 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:23,205] Trial 166 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:23,313] Trial 167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:23,373] Trial 168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:23,482] Trial 169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:23,540] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:23,696] Trial 171 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:23,758] Trial 172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:24,108] Trial 173 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:24,171] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:24,420] Trial 175 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:24,545] Trial 176 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:24,608] Trial 177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:24,715] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:24,968] Trial 179 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:25,119] Trial 180 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:25,183] Trial 181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,249] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,313] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,425] Trial 184 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:25,537] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,603] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,712] Trial 187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,778] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:25,980] Trial 189 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:26,087] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,350] Trial 191 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:49:26,454] Trial 192 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:26,523] Trial 193 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:26,561] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,593] Trial 195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,627] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,695] Trial 197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,761] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,868] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:26,977] Trial 200 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:27,153] Trial 201 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:27,236] Trial 202 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:27,301] Trial 203 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:27,444] Trial 204 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:27,477] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:27,510] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:27,574] Trial 207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:27,632] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:27,813] Trial 209 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:27,969] Trial 210 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:28,587] Trial 211 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:49:28,650] Trial 212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:28,713] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:28,777] Trial 214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:28,890] Trial 215 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:29,241] Trial 216 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:29,353] Trial 217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:29,417] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:29,669] Trial 219 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:29,780] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:34,118] Trial 221 finished with value: 0.7153453004931835 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 2, 'subsample': 0.8370959132068995, 'colsample_bynode': 0.9533479510898352, 'reg_alpha': 0.0019159646285617992}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:49:34,181] Trial 222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:34,249] Trial 223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:34,360] Trial 224 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:34,571] Trial 225 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:34,633] Trial 226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:34,744] Trial 227 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:34,947] Trial 228 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:49:35,016] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:35,123] Trial 230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:36,079] Trial 231 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:49:36,342] Trial 232 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:36,893] Trial 233 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:49:36,958] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,024] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,086] Trial 236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,150] Trial 237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,585] Trial 238 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-02-05 13:49:37,657] Trial 239 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:37,720] Trial 240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,829] Trial 241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:37,912] Trial 242 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:37,994] Trial 243 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:38,027] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:38,064] Trial 245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:38,130] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:38,275] Trial 247 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:38,336] Trial 248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:38,448] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:38,563] Trial 250 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:38,866] Trial 251 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:49:38,976] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:39,254] Trial 253 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:39,367] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:39,719] Trial 255 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:39,828] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:39,893] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:39,957] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,065] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,136] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,249] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,312] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,423] Trial 263 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:40,532] Trial 264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,597] Trial 265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,706] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,775] Trial 267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:40,841] Trial 268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:41,316] Trial 269 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:49:41,351] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:41,462] Trial 271 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:41,525] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:41,684] Trial 273 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:41,945] Trial 274 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:42,055] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:42,120] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:42,275] Trial 277 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:42,387] Trial 278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:42,503] Trial 279 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:42,749] Trial 280 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:49:42,816] Trial 281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:42,884] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:42,998] Trial 283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,067] Trial 284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,198] Trial 285 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:43,266] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,379] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,446] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,511] Trial 289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,625] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,689] Trial 291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:43,802] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:44,156] Trial 293 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:44,707] Trial 294 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:49:44,815] Trial 295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:44,876] Trial 296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:44,985] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:45,052] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:45,208] Trial 299 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:45,445] Trial 300 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:49:45,512] Trial 301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:45,715] Trial 302 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:49:45,784] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:45,896] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:45,962] Trial 305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,027] Trial 306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,141] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,206] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,319] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,386] Trial 310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,495] Trial 311 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:46,610] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,677] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,788] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:46,857] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,110] Trial 316 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:47,224] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,290] Trial 318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,436] Trial 319 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:47,503] Trial 320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,618] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,682] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,748] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:47,858] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,016] Trial 325 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:48,127] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,191] Trial 327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,397] Trial 328 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:48,509] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,583] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,696] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,765] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,829] Trial 333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:48,941] Trial 334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:49,002] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:49,113] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:49,183] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:49,434] Trial 338 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:49,582] Trial 339 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:49,647] Trial 340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:49,757] Trial 341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:50,161] Trial 342 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:49:50,276] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:50,818] Trial 344 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:49:50,883] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:50,995] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:51,351] Trial 347 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:51,464] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:51,574] Trial 349 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:51,641] Trial 350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:51,768] Trial 351 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:51,835] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:51,950] Trial 353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:52,014] Trial 354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:52,082] Trial 355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:52,232] Trial 356 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:52,787] Trial 357 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:49:53,008] Trial 358 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:53,070] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,180] Trial 360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,248] Trial 361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,317] Trial 362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,438] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,504] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,621] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:53,827] Trial 366 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:55,495] Trial 367 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:49:55,614] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:55,838] Trial 369 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:49:56,210] Trial 370 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:49:56,405] Trial 371 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:56,477] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:56,589] Trial 373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:56,908] Trial 374 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:57,027] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:57,098] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:57,170] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:57,320] Trial 378 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:49:57,595] Trial 379 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:49:57,710] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:57,777] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:57,949] Trial 382 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:58,067] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,142] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,254] Trial 385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,324] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,487] Trial 387 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:58,606] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,675] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,795] Trial 390 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:58,865] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:59,473] Trial 392 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:49:59,600] Trial 393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:59,763] Trial 394 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:49:59,874] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:49:59,942] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,056] Trial 397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,124] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,193] Trial 399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,308] Trial 400 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,379] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,494] Trial 402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:00,845] Trial 403 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:00,912] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:01,082] Trial 405 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:01,153] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:01,323] Trial 407 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:01,438] Trial 408 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:01,507] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:01,658] Trial 410 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:01,770] Trial 411 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:01,885] Trial 412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:02,102] Trial 413 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:02,219] Trial 414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:02,476] Trial 415 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:02,547] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:02,661] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:02,875] Trial 418 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:02,992] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,057] Trial 420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,128] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,243] Trial 422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,314] Trial 423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,435] Trial 424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,505] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,720] Trial 426 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:03,839] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:03,911] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,046] Trial 429 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:04,115] Trial 430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,277] Trial 431 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:04,390] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,458] Trial 433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,574] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,644] Trial 435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,757] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,825] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:04,939] Trial 438 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:05,063] Trial 439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:05,316] Trial 440 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:05,448] Trial 441 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:05,518] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:05,585] Trial 443 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:05,705] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:05,778] Trial 445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:06,059] Trial 446 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:50:06,622] Trial 447 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:06,835] Trial 448 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:06,948] Trial 449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:07,017] Trial 450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:07,188] Trial 451 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:07,393] Trial 452 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:07,512] Trial 453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:07,582] Trial 454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:07,793] Trial 455 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:07,907] Trial 456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:08,027] Trial 457 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:08,147] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:08,218] Trial 459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:08,473] Trial 460 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:08,591] Trial 461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:08,759] Trial 462 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:08,874] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:09,139] Trial 464 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:09,512] Trial 465 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:09,629] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:09,794] Trial 467 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:09,908] Trial 468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:09,977] Trial 469 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:10,188] Trial 470 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:10,317] Trial 471 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:10,995] Trial 472 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:11,064] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,184] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,255] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,369] Trial 476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,488] Trial 477 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:11,559] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,674] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,742] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:11,859] Trial 481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:12,071] Trial 482 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:12,141] Trial 483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:12,261] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:12,329] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:12,480] Trial 486 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:12,742] Trial 487 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:12,859] Trial 488 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:13,086] Trial 489 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:13,301] Trial 490 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:13,609] Trial 491 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:13,825] Trial 492 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:13,941] Trial 493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,011] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,084] Trial 495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,196] Trial 496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,315] Trial 497 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:14,434] Trial 498 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,505] Trial 499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,572] Trial 500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,694] Trial 501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:14,955] Trial 502 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:16,975] Trial 503 finished with value: 0.7160997964148643 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 2, 'subsample': 0.8653763177380702, 'colsample_bynode': 0.8526524654782168, 'reg_alpha': 1.4869949310374189}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:50:17,067] Trial 504 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:17,108] Trial 505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:17,287] Trial 506 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:17,690] Trial 507 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:50:17,731] Trial 508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:17,806] Trial 509 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:17,895] Trial 510 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:18,005] Trial 511 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:18,078] Trial 512 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:18,121] Trial 513 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,164] Trial 514 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,205] Trial 515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,281] Trial 516 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:18,323] Trial 517 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,366] Trial 518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,411] Trial 519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,453] Trial 520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,682] Trial 521 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:18,725] Trial 522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:18,820] Trial 523 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:18,862] Trial 524 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,329] Trial 525 pruned. Trial was pruned at iteration 21.\n",
      "[I 2024-02-05 13:50:19,369] Trial 526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,410] Trial 527 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,454] Trial 528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,496] Trial 529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,572] Trial 530 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:19,615] Trial 531 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,656] Trial 532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:19,861] Trial 533 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:50:19,904] Trial 534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:20,174] Trial 535 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:20,215] Trial 536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:20,310] Trial 537 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:20,352] Trial 538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:20,395] Trial 539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:20,517] Trial 540 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:20,635] Trial 541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:20,761] Trial 542 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:20,880] Trial 543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,098] Trial 544 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:21,170] Trial 545 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,319] Trial 546 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:21,490] Trial 547 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:21,612] Trial 548 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,684] Trial 549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,803] Trial 550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,874] Trial 551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:21,994] Trial 552 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,064] Trial 553 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,198] Trial 554 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:22,274] Trial 555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,389] Trial 556 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,460] Trial 557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,579] Trial 558 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:22,799] Trial 559 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:23,012] Trial 560 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:23,133] Trial 561 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:23,207] Trial 562 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:23,327] Trial 563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:23,402] Trial 564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:23,519] Trial 565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:23,684] Trial 566 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:23,824] Trial 567 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:23,942] Trial 568 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:24,068] Trial 569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,143] Trial 570 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,259] Trial 571 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,371] Trial 572 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:24,487] Trial 573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,563] Trial 574 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,686] Trial 575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:24,807] Trial 576 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:24,934] Trial 577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,006] Trial 578 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,127] Trial 579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,203] Trial 580 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,321] Trial 581 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,398] Trial 582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,517] Trial 583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,594] Trial 584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,713] Trial 585 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:25,788] Trial 586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:26,000] Trial 587 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:26,191] Trial 588 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:26,312] Trial 589 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:26,441] Trial 590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:26,516] Trial 591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:26,633] Trial 592 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:26,756] Trial 593 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:26,873] Trial 594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:26,992] Trial 595 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:27,114] Trial 596 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:27,184] Trial 597 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:27,532] Trial 598 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:27,600] Trial 599 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:27,739] Trial 600 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:27,905] Trial 601 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:28,147] Trial 602 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:28,919] Trial 603 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:50:29,085] Trial 604 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:29,164] Trial 605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:29,471] Trial 606 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:29,686] Trial 607 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:29,840] Trial 608 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:30,440] Trial 609 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:50:30,807] Trial 610 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:30,943] Trial 611 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:31,203] Trial 612 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:31,319] Trial 613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:31,393] Trial 614 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:31,707] Trial 615 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:31,779] Trial 616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:31,973] Trial 617 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:32,051] Trial 618 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,173] Trial 619 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,244] Trial 620 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,367] Trial 621 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,441] Trial 622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,563] Trial 623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,640] Trial 624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,758] Trial 625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:32,877] Trial 626 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:33,016] Trial 627 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:33,229] Trial 628 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:33,350] Trial 629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,427] Trial 630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,549] Trial 631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,622] Trial 632 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,739] Trial 633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,817] Trial 634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:33,938] Trial 635 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,059] Trial 636 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:34,133] Trial 637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,286] Trial 638 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:34,363] Trial 639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,483] Trial 640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,558] Trial 641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,684] Trial 642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,763] Trial 643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:34,930] Trial 644 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:35,054] Trial 645 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:35,171] Trial 646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:35,289] Trial 647 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:35,408] Trial 648 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:35,484] Trial 649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:35,728] Trial 650 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:35,806] Trial 651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:35,956] Trial 652 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:36,031] Trial 653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,150] Trial 654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,225] Trial 655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,534] Trial 656 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:36,607] Trial 657 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,729] Trial 658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,804] Trial 659 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:36,961] Trial 660 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:37,037] Trial 661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,160] Trial 662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,232] Trial 663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,449] Trial 664 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:37,569] Trial 665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,645] Trial 666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,768] Trial 667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:37,893] Trial 668 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:38,011] Trial 669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:38,137] Trial 670 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:38,260] Trial 671 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:38,385] Trial 672 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:38,507] Trial 673 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:38,583] Trial 674 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:38,779] Trial 675 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:38,855] Trial 676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:38,976] Trial 677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:39,052] Trial 678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:39,178] Trial 679 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:39,443] Trial 680 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:39,561] Trial 681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:39,687] Trial 682 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:39,810] Trial 683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:39,886] Trial 684 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:40,010] Trial 685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:40,369] Trial 686 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:40,492] Trial 687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:40,707] Trial 688 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:40,874] Trial 689 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:40,949] Trial 690 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,088] Trial 691 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:41,163] Trial 692 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,241] Trial 693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,364] Trial 694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,442] Trial 695 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,565] Trial 696 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,639] Trial 697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,764] Trial 698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:41,984] Trial 699 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:42,141] Trial 700 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:50:42,213] Trial 701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:42,340] Trial 702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:42,418] Trial 703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:42,540] Trial 704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:42,618] Trial 705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:42,739] Trial 706 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:43,109] Trial 707 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:43,243] Trial 708 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:43,315] Trial 709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:43,436] Trial 710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:43,516] Trial 711 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:43,692] Trial 712 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:43,814] Trial 713 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:43,952] Trial 714 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:44,032] Trial 715 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,157] Trial 716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,229] Trial 717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,354] Trial 718 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,432] Trial 719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,706] Trial 720 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:44,831] Trial 721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:44,957] Trial 722 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:45,300] Trial 723 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:45,518] Trial 724 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:45,640] Trial 725 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:45,720] Trial 726 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:45,840] Trial 727 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:45,960] Trial 728 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:46,083] Trial 729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:46,305] Trial 730 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:46,476] Trial 731 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:46,553] Trial 732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:46,678] Trial 733 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:46,757] Trial 734 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:46,902] Trial 735 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:46,979] Trial 736 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,101] Trial 737 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,179] Trial 738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,299] Trial 739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,376] Trial 740 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,607] Trial 741 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:47,682] Trial 742 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,804] Trial 743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:47,938] Trial 744 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:48,073] Trial 745 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,145] Trial 746 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,271] Trial 747 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,347] Trial 748 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,426] Trial 749 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,549] Trial 750 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:48,766] Trial 751 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:49,129] Trial 752 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:50,096] Trial 753 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:50:50,505] Trial 754 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:50,624] Trial 755 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:51,400] Trial 756 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:50:51,525] Trial 757 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:51,665] Trial 758 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:52,330] Trial 759 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:50:52,562] Trial 760 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:52,827] Trial 761 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:53,001] Trial 762 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:53,567] Trial 763 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:50:53,795] Trial 764 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:50:54,304] Trial 765 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:50:54,483] Trial 766 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:54,566] Trial 767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:54,815] Trial 768 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:55,032] Trial 769 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:55,158] Trial 770 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:55,424] Trial 771 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:55,566] Trial 772 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:55,650] Trial 773 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:55,845] Trial 774 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:50:55,922] Trial 775 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,048] Trial 776 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,477] Trial 777 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:56,602] Trial 778 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,685] Trial 779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,811] Trial 780 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,890] Trial 781 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:56,969] Trial 782 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,108] Trial 783 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:57,191] Trial 784 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,316] Trial 785 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,400] Trial 786 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,528] Trial 787 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,605] Trial 788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:57,726] Trial 789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,142] Trial 790 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:50:58,268] Trial 791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,347] Trial 792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,472] Trial 793 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,553] Trial 794 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,694] Trial 795 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:50:58,775] Trial 796 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,901] Trial 797 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:58,981] Trial 798 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:59,108] Trial 799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:59,327] Trial 800 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:59,449] Trial 801 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:59,675] Trial 802 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:50:59,803] Trial 803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:50:59,885] Trial 804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:00,010] Trial 805 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:00,184] Trial 806 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:00,309] Trial 807 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:00,389] Trial 808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:00,661] Trial 809 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:51:00,736] Trial 810 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:02,188] Trial 811 pruned. Trial was pruned at iteration 28.\n",
      "[I 2024-02-05 13:51:02,668] Trial 812 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:51:02,721] Trial 813 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:02,836] Trial 814 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:03,072] Trial 815 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:03,120] Trial 816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:03,521] Trial 817 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:51:03,921] Trial 818 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:51:05,727] Trial 819 finished with value: 0.7158937915688542 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 3, 'subsample': 0.8849762408822007, 'colsample_bynode': 0.8842607152038536, 'reg_alpha': 1.2463136163744895}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:51:05,830] Trial 820 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:05,928] Trial 821 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:06,041] Trial 822 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:06,159] Trial 823 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:06,295] Trial 824 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:51:06,345] Trial 825 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:06,449] Trial 826 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:06,663] Trial 827 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:51:06,761] Trial 828 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:07,080] Trial 829 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:51:07,230] Trial 830 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:07,329] Trial 831 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:07,506] Trial 832 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:07,554] Trial 833 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:07,604] Trial 834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:07,660] Trial 835 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:07,762] Trial 836 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:07,811] Trial 837 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:08,447] Trial 838 pruned. Trial was pruned at iteration 29.\n",
      "[I 2024-02-05 13:51:08,568] Trial 839 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:08,634] Trial 840 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:08,700] Trial 841 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:08,857] Trial 842 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:51:09,140] Trial 843 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:51:09,195] Trial 844 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:09,452] Trial 845 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:09,552] Trial 846 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:09,937] Trial 847 pruned. Trial was pruned at iteration 17.\n",
      "[I 2024-02-05 13:51:10,340] Trial 848 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:51:10,392] Trial 849 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:10,513] Trial 850 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:10,689] Trial 851 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:11,008] Trial 852 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:51:11,137] Trial 853 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:11,376] Trial 854 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:13,361] Trial 855 finished with value: 0.7149591136471499 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 3, 'subsample': 0.8771791601999795, 'colsample_bynode': 0.8695629239682285, 'reg_alpha': 1.26851040050807}. Best is trial 140 with value: 0.716594038449521.\n",
      "[I 2024-02-05 13:51:13,519] Trial 856 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:51:13,569] Trial 857 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:13,669] Trial 858 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:13,720] Trial 859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:13,768] Trial 860 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:13,817] Trial 861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:13,866] Trial 862 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:14,254] Trial 863 pruned. Trial was pruned at iteration 17.\n",
      "[I 2024-02-05 13:51:14,431] Trial 864 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:14,918] Trial 865 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:51:15,096] Trial 866 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:15,463] Trial 867 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-02-05 13:51:15,563] Trial 868 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:15,644] Trial 869 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:15,694] Trial 870 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:15,765] Trial 871 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:16,107] Trial 872 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:51:16,173] Trial 873 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:16,226] Trial 874 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:16,278] Trial 875 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:16,767] Trial 876 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:51:16,869] Trial 877 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:17,042] Trial 878 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:17,298] Trial 879 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:17,401] Trial 880 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:17,468] Trial 881 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:17,602] Trial 882 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:51:17,835] Trial 883 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:18,096] Trial 884 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:18,149] Trial 885 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:18,197] Trial 886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:18,265] Trial 887 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:18,367] Trial 888 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:18,417] Trial 889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:18,674] Trial 890 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:18,829] Trial 891 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:51:18,898] Trial 892 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:18,950] Trial 893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:19,073] Trial 894 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:19,123] Trial 895 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:19,674] Trial 896 pruned. Trial was pruned at iteration 24.\n",
      "[I 2024-02-05 13:51:19,916] Trial 897 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:20,035] Trial 898 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:20,089] Trial 899 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,141] Trial 900 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,189] Trial 901 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,241] Trial 902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,476] Trial 903 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:20,543] Trial 904 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:20,595] Trial 905 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,696] Trial 906 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:20,751] Trial 907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:20,990] Trial 908 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:21,043] Trial 909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:21,112] Trial 910 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:21,215] Trial 911 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:21,472] Trial 912 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:21,540] Trial 913 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:21,594] Trial 914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:21,649] Trial 915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:22,311] Trial 916 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:51:22,367] Trial 917 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:22,468] Trial 918 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:22,698] Trial 919 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:22,748] Trial 920 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:22,870] Trial 921 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:22,977] Trial 922 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:23,028] Trial 923 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,078] Trial 924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,182] Trial 925 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:23,234] Trial 926 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,337] Trial 927 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:23,461] Trial 928 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:23,513] Trial 929 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,566] Trial 930 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,620] Trial 931 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,743] Trial 932 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:23,796] Trial 933 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:23,937] Trial 934 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:51:23,991] Trial 935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,043] Trial 936 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,095] Trial 937 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,400] Trial 938 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:51:24,501] Trial 939 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:24,607] Trial 940 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:24,682] Trial 941 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:24,754] Trial 942 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:24,808] Trial 943 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,861] Trial 944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,913] Trial 945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:24,965] Trial 946 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:25,227] Trial 947 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:25,312] Trial 948 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:25,432] Trial 949 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:25,501] Trial 950 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:25,556] Trial 951 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:25,606] Trial 952 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:25,663] Trial 953 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:25,886] Trial 954 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:51:25,943] Trial 955 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,012] Trial 956 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:26,066] Trial 957 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,119] Trial 958 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,174] Trial 959 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,228] Trial 960 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,284] Trial 961 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,338] Trial 962 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,422] Trial 963 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,548] Trial 964 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,603] Trial 965 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,688] Trial 966 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,819] Trial 967 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:26,891] Trial 968 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:26,972] Trial 969 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:27,097] Trial 970 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:27,462] Trial 971 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:51:27,640] Trial 972 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:27,886] Trial 973 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:27,970] Trial 974 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:28,101] Trial 975 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:28,244] Trial 976 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:51:28,327] Trial 977 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:28,462] Trial 978 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:28,544] Trial 979 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:28,800] Trial 980 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:28,899] Trial 981 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:29,127] Trial 982 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:29,256] Trial 983 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:29,520] Trial 984 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:29,654] Trial 985 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:29,723] Trial 986 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:29,810] Trial 987 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:29,941] Trial 988 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:29,996] Trial 989 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:30,074] Trial 990 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:30,305] Trial 991 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:51:30,528] Trial 992 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:30,662] Trial 993 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:30,717] Trial 994 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:30,799] Trial 995 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:30,982] Trial 996 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:31,038] Trial 997 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:31,119] Trial 998 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:31,472] Trial 999 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:51:31,556] Trial 1000 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:31,736] Trial 1001 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:31,791] Trial 1002 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:31,874] Trial 1003 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,007] Trial 1004 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,060] Trial 1005 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,193] Trial 1006 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:32,320] Trial 1007 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,407] Trial 1008 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,565] Trial 1009 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:32,621] Trial 1010 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:33,191] Trial 1011 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:33,353] Trial 1012 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:33,410] Trial 1013 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:33,490] Trial 1014 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:33,623] Trial 1015 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:33,709] Trial 1016 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:34,007] Trial 1017 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:51:34,078] Trial 1018 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:34,163] Trial 1019 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:34,292] Trial 1020 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:34,347] Trial 1021 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:34,621] Trial 1022 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:34,749] Trial 1023 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:35,022] Trial 1024 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:35,189] Trial 1025 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:35,262] Trial 1026 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:35,349] Trial 1027 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:35,482] Trial 1028 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:35,538] Trial 1029 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:35,622] Trial 1030 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:35,820] Trial 1031 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:35,909] Trial 1032 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:36,055] Trial 1033 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:36,165] Trial 1034 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:36,295] Trial 1035 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:36,426] Trial 1036 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:36,479] Trial 1037 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:36,613] Trial 1038 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:36,781] Trial 1039 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:36,917] Trial 1040 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:37,215] Trial 1041 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:51:37,273] Trial 1042 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:37,361] Trial 1043 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:37,493] Trial 1044 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:37,548] Trial 1045 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:37,635] Trial 1046 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:37,800] Trial 1047 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:37,885] Trial 1048 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,037] Trial 1049 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:38,092] Trial 1050 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,175] Trial 1051 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,301] Trial 1052 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,358] Trial 1053 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,443] Trial 1054 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,575] Trial 1055 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,663] Trial 1056 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,812] Trial 1057 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:38,869] Trial 1058 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:38,955] Trial 1059 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:39,089] Trial 1060 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:39,152] Trial 1061 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:39,585] Trial 1062 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:39,717] Trial 1063 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:40,152] Trial 1064 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:40,283] Trial 1065 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:40,340] Trial 1066 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:40,425] Trial 1067 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:40,560] Trial 1068 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:40,618] Trial 1069 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:41,141] Trial 1070 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:51:41,267] Trial 1071 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:41,354] Trial 1072 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:41,487] Trial 1073 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:41,544] Trial 1074 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:41,777] Trial 1075 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:41,961] Trial 1076 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:42,042] Trial 1077 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:42,132] Trial 1078 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,261] Trial 1079 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,442] Trial 1080 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:42,573] Trial 1081 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,629] Trial 1082 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,718] Trial 1083 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,857] Trial 1084 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,912] Trial 1085 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:42,999] Trial 1086 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:43,132] Trial 1087 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:43,404] Trial 1088 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:43,540] Trial 1089 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:43,670] Trial 1090 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:43,758] Trial 1091 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,098] Trial 1092 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:44,156] Trial 1093 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,240] Trial 1094 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,374] Trial 1095 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,465] Trial 1096 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,596] Trial 1097 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:44,654] Trial 1098 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:45,381] Trial 1099 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:51:45,515] Trial 1100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:45,572] Trial 1101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:45,811] Trial 1102 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:46,072] Trial 1103 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:46,298] Trial 1104 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:46,430] Trial 1105 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:46,490] Trial 1106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:46,575] Trial 1107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:46,728] Trial 1108 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:46,786] Trial 1109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:46,875] Trial 1110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,025] Trial 1111 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:47,116] Trial 1112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,318] Trial 1113 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:47,377] Trial 1114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,463] Trial 1115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,600] Trial 1116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,657] Trial 1117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,743] Trial 1118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:47,877] Trial 1119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:48,205] Trial 1120 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:51:48,339] Trial 1121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:48,396] Trial 1122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:48,486] Trial 1123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:48,624] Trial 1124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:48,749] Trial 1125 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:49,181] Trial 1126 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:49,318] Trial 1127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:49,453] Trial 1128 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:49,607] Trial 1129 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:49,665] Trial 1130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:49,751] Trial 1131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:49,885] Trial 1132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:49,943] Trial 1133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,033] Trial 1134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,165] Trial 1135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,260] Trial 1136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,404] Trial 1137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,646] Trial 1138 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:51:50,738] Trial 1139 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:50,892] Trial 1140 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:50,952] Trial 1141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,041] Trial 1142 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,177] Trial 1143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,264] Trial 1144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,447] Trial 1145 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:51,536] Trial 1146 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:51:51,621] Trial 1147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,756] Trial 1148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,816] Trial 1149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:51,950] Trial 1150 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:52,083] Trial 1151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:52,512] Trial 1152 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:52,642] Trial 1153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:52,700] Trial 1154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:52,791] Trial 1155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:52,990] Trial 1156 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:53,048] Trial 1157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:53,275] Trial 1158 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:53,461] Trial 1159 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:53,551] Trial 1160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:53,682] Trial 1161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:53,758] Trial 1162 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:53,846] Trial 1163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:53,979] Trial 1164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:54,165] Trial 1165 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:54,254] Trial 1166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:54,598] Trial 1167 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:54,691] Trial 1168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:54,825] Trial 1169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:54,884] Trial 1170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:54,970] Trial 1171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:55,110] Trial 1172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:55,171] Trial 1173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:55,255] Trial 1174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:55,408] Trial 1175 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:55,485] Trial 1176 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:55,578] Trial 1177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:55,932] Trial 1178 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:51:56,025] Trial 1179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:56,163] Trial 1180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:56,239] Trial 1181 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:51:56,334] Trial 1182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:56,473] Trial 1183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:56,604] Trial 1184 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:56,707] Trial 1185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:56,843] Trial 1186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:57,296] Trial 1187 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:57,567] Trial 1188 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:51:57,628] Trial 1189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:57,719] Trial 1190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:57,855] Trial 1191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:57,914] Trial 1192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:58,146] Trial 1193 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:58,288] Trial 1194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:58,521] Trial 1195 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:51:58,766] Trial 1196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:58,827] Trial 1197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:59,511] Trial 1198 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:51:59,716] Trial 1199 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:51:59,775] Trial 1200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:59,863] Trial 1201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:51:59,993] Trial 1202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:00,082] Trial 1203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:00,217] Trial 1204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:00,293] Trial 1205 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:00,533] Trial 1206 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:00,671] Trial 1207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:00,730] Trial 1208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:00,872] Trial 1209 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:01,011] Trial 1210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,240] Trial 1211 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:01,375] Trial 1212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,437] Trial 1213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,525] Trial 1214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,660] Trial 1215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,725] Trial 1216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:01,860] Trial 1217 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:01,998] Trial 1218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:02,088] Trial 1219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:02,298] Trial 1220 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:52:02,447] Trial 1221 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:52:02,632] Trial 1222 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:02,769] Trial 1223 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:02,828] Trial 1224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:02,920] Trial 1225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,055] Trial 1226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,147] Trial 1227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,284] Trial 1228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,391] Trial 1229 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:03,484] Trial 1230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,634] Trial 1231 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:03,695] Trial 1232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,782] Trial 1233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:03,938] Trial 1234 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:04,123] Trial 1235 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:04,268] Trial 1236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:04,328] Trial 1237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:04,421] Trial 1238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:04,979] Trial 1239 pruned. Trial was pruned at iteration 21.\n",
      "[I 2024-02-05 13:52:05,041] Trial 1240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:05,176] Trial 1241 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:05,313] Trial 1242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:05,394] Trial 1243 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:05,623] Trial 1244 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:05,757] Trial 1245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:05,850] Trial 1246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:06,415] Trial 1247 pruned. Trial was pruned at iteration 21.\n",
      "[I 2024-02-05 13:52:06,679] Trial 1248 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:52:06,812] Trial 1249 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:06,948] Trial 1250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:07,009] Trial 1251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:07,631] Trial 1252 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:52:07,821] Trial 1253 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:07,917] Trial 1254 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:08,442] Trial 1255 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:52:09,098] Trial 1256 pruned. Trial was pruned at iteration 26.\n",
      "[I 2024-02-05 13:52:09,207] Trial 1257 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:09,346] Trial 1258 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:09,485] Trial 1259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:09,574] Trial 1260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:09,714] Trial 1261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:09,777] Trial 1262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:10,008] Trial 1263 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:10,142] Trial 1264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:10,206] Trial 1265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:10,342] Trial 1266 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:10,500] Trial 1267 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:10,563] Trial 1268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:10,657] Trial 1269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:10,824] Trial 1270 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:10,917] Trial 1271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,054] Trial 1272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,152] Trial 1273 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:11,244] Trial 1274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,378] Trial 1275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,472] Trial 1276 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:11,575] Trial 1277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,714] Trial 1278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,806] Trial 1279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:11,980] Trial 1280 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:52:12,058] Trial 1281 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:12,150] Trial 1282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:12,491] Trial 1283 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:52:12,553] Trial 1284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:12,643] Trial 1285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:12,798] Trial 1286 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:12,888] Trial 1287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:13,023] Trial 1288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:13,086] Trial 1289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:13,176] Trial 1290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:13,501] Trial 1291 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:52:13,734] Trial 1292 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:52:13,826] Trial 1293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:13,970] Trial 1294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,062] Trial 1295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,200] Trial 1296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,259] Trial 1297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,349] Trial 1298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,489] Trial 1299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,555] Trial 1300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,661] Trial 1301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:14,937] Trial 1302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:15,067] Trial 1303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:15,243] Trial 1304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:15,317] Trial 1305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:15,950] Trial 1306 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:52:16,094] Trial 1307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:16,161] Trial 1308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:16,444] Trial 1309 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:52:16,812] Trial 1310 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:52:16,962] Trial 1311 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:52:17,104] Trial 1312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,166] Trial 1313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,257] Trial 1314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,401] Trial 1315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,462] Trial 1316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,557] Trial 1317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:17,746] Trial 1318 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:18,276] Trial 1319 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:52:18,466] Trial 1320 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:18,532] Trial 1321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:18,619] Trial 1322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:18,762] Trial 1323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:18,826] Trial 1324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:18,919] Trial 1325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,058] Trial 1326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,299] Trial 1327 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:52:19,438] Trial 1328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,502] Trial 1329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,597] Trial 1330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,734] Trial 1331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,799] Trial 1332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:19,929] Trial 1333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:20,071] Trial 1334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:20,167] Trial 1335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:20,303] Trial 1336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:20,366] Trial 1337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:20,797] Trial 1338 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:52:21,064] Trial 1339 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:52:21,257] Trial 1340 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:52:21,352] Trial 1341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:52:21,494] Trial 1342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:02,054] Trial 1343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:02,508] Trial 1344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:02,606] Trial 1345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:02,731] Trial 1346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:02,942] Trial 1347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:03,071] Trial 1348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:03,228] Trial 1349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:03,373] Trial 1350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:03,561] Trial 1351 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:03,723] Trial 1352 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:05,126] Trial 1353 pruned. Trial was pruned at iteration 16.\n",
      "[I 2024-02-05 13:53:05,841] Trial 1354 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:53:06,097] Trial 1355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:06,182] Trial 1356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:06,377] Trial 1357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:06,888] Trial 1358 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:53:07,008] Trial 1359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:07,189] Trial 1360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:07,264] Trial 1361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:07,603] Trial 1362 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:53:07,768] Trial 1363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:07,847] Trial 1364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:08,016] Trial 1365 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:08,164] Trial 1366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:08,272] Trial 1367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:08,451] Trial 1368 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:08,535] Trial 1369 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:08,636] Trial 1370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:08,802] Trial 1371 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:08,872] Trial 1372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:08,970] Trial 1373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:09,375] Trial 1374 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:53:09,492] Trial 1375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:09,681] Trial 1376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:09,802] Trial 1377 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:53:09,920] Trial 1378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:10,084] Trial 1379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:10,702] Trial 1380 pruned. Trial was pruned at iteration 26.\n",
      "[I 2024-02-05 13:53:10,800] Trial 1381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:10,960] Trial 1382 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:11,059] Trial 1383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:11,820] Trial 1384 pruned. Trial was pruned at iteration 29.\n",
      "[I 2024-02-05 13:53:11,953] Trial 1385 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:53:12,048] Trial 1386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:12,193] Trial 1387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:12,259] Trial 1388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:12,407] Trial 1389 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:12,787] Trial 1390 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:53:12,885] Trial 1391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:13,629] Trial 1392 pruned. Trial was pruned at iteration 29.\n",
      "[I 2024-02-05 13:53:13,722] Trial 1393 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:13,819] Trial 1394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:13,962] Trial 1395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:14,032] Trial 1396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:14,127] Trial 1397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:14,280] Trial 1398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:14,348] Trial 1399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:14,492] Trial 1400 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:14,642] Trial 1401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:15,289] Trial 1402 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:53:15,668] Trial 1403 pruned. Trial was pruned at iteration 12.\n",
      "[I 2024-02-05 13:53:15,738] Trial 1404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:15,833] Trial 1405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:16,032] Trial 1406 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:53:16,100] Trial 1407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:16,197] Trial 1408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:16,412] Trial 1409 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:53:16,558] Trial 1410 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:16,735] Trial 1411 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:53:16,804] Trial 1412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:16,899] Trial 1413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:17,042] Trial 1414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:17,107] Trial 1415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:17,254] Trial 1416 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:17,415] Trial 1417 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:17,562] Trial 1418 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:17,725] Trial 1419 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:18,320] Trial 1420 pruned. Trial was pruned at iteration 26.\n",
      "[I 2024-02-05 13:53:19,070] Trial 1421 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:53:19,214] Trial 1422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:19,428] Trial 1423 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:53:19,528] Trial 1424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:19,676] Trial 1425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:19,745] Trial 1426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:19,981] Trial 1427 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:53:20,125] Trial 1428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:20,224] Trial 1429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:20,547] Trial 1430 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:53:20,614] Trial 1431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:20,710] Trial 1432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:20,855] Trial 1433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:20,924] Trial 1434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,027] Trial 1435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,168] Trial 1436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,316] Trial 1437 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:21,457] Trial 1438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,526] Trial 1439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,674] Trial 1440 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:21,822] Trial 1441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:21,889] Trial 1442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:22,034] Trial 1443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:22,211] Trial 1444 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:53:22,495] Trial 1445 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:53:22,642] Trial 1446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:22,710] Trial 1447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:22,809] Trial 1448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:22,956] Trial 1449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:23,238] Trial 1450 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:53:23,336] Trial 1451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:23,495] Trial 1452 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:53:23,591] Trial 1453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:23,736] Trial 1454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:23,876] Trial 1455 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:53:23,977] Trial 1456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:24,123] Trial 1457 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:24,192] Trial 1458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:24,293] Trial 1459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:53:24,492] Trial 1460 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:53:24,588] Trial 1461 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate ==================================================\n",
      "========================= HyperTuning Results For Fixed Learning Rate = 0.2\n",
      "Best auc Score = 0.716594038449521\n",
      "Best Boosting Round: 45\n",
      "========== Best Tree Params ==========\n",
      "tree_method : approx\n",
      "max_depth : 6\n",
      "min_child_weight : 2\n",
      "max_delta_step : 3\n",
      "subsample : 0.8332146323796362\n",
      "colsample_bynode : 0.8601547071390518\n",
      "reg_alpha : 3.3305338985015873\n",
      " \n",
      "================================================== Stage 2 - Boosting Parameters ==================================================\n",
      "best scores (AUC , LOGLOSS) = (0.7153091722738142, 0.2856063340597667)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.005\n",
      "best boosting round: 1998\n",
      "best scores (AUC , LOGLOSS) = (0.7152646128763264, 0.28563601225505936)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.01\n",
      "best boosting round: 963\n",
      "best scores (AUC , LOGLOSS) = (0.7127924683059809, 0.2878597387681658)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.1\n",
      "best boosting round: 113\n",
      "     eta       auc   logloss   itr\n",
      "0  0.005  0.715309  0.285606  1998\n",
      "1  0.010  0.715265  0.285636   963\n",
      "2  0.100  0.712792  0.287860   113\n",
      "Final Even Strength Model ==========================\n",
      "test score against old data (AUC, LOGLOSS) = (0.7204928444136771, 0.281197251032698)\n",
      "test score against current data (AUC, LOGLOSS) = (0.6660714941591911, 0.30030403427979496)\n",
      "test score against all test data (AUC, LOGLOSS) = (0.7097616243109578, 0.2850385024619617)\n",
      "parameters ---------------------------\n",
      "tree_method : approx\n",
      "max_depth : 6\n",
      "min_child_weight : 2\n",
      "max_delta_step : 3\n",
      "subsample : 0.8332146323796362\n",
      "colsample_bynode : 0.8601547071390518\n",
      "reg_alpha : 3.3305338985015873\n",
      "learning_rate : 0.005\n",
      "num_boost_round: 1998\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=71)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "tic = time.time()\n",
    "while time.time() - tic < 300:\n",
    "    study.optimize(lambda trial: objective(trial, dtrain = pp_dtrain, dvalid = pp_dvalid, lr = PP_eta), n_trials=1)\n",
    "\n",
    "print('='*50,'Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate', '='*50)\n",
    "print('='*25, f'HyperTuning Results For Fixed Learning Rate = {PP_eta}')\n",
    "print(f'Best {e_m} Score = {study.best_trial.value}')\n",
    "print(f'Best Boosting Round: {study.best_trial.user_attrs[\"best_iteration\"]}')\n",
    "print(\"=\"*10,'Best Tree Params',\"=\"*10)\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(k, ':', v)\n",
    "\n",
    "#### STAGE 2 ####\n",
    "print(\" \")\n",
    "print('='*50, 'Stage 2 - Boosting Parameters', '='*50)\n",
    "lr_list = []\n",
    "auc_score_list = []\n",
    "logloss_list = []\n",
    "iterations_list = []\n",
    "for i in [0.005, 0.01, 0.1]:\n",
    "    low_learning_rate = i\n",
    "    params = {}\n",
    "    params.update(study.best_trial.params)\n",
    "    params['learning_rate'] = i\n",
    "    model_stage2 = xgb.train(params=params, dtrain=pp_dtrain, \n",
    "                             num_boost_round=10000,\n",
    "                             evals=[(pp_dtrain, 'train'), (pp_dvalid, 'valid')],\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=0)\n",
    "    \n",
    "    print(f'best scores (AUC , LOGLOSS) = {score_model(model_stage2, pp_dvalid)}')\n",
    "    print('boosting params ---------------------------')\n",
    "    print(f'learning rate: {params[\"learning_rate\"]}')\n",
    "    print(f'best boosting round: {model_stage2.best_iteration}')\n",
    "    auc_score, ll_score = score_model(model_stage2, pp_dvalid)\n",
    "\n",
    "    lr_list.append(i)\n",
    "    auc_score_list.append(auc_score)\n",
    "    logloss_list.append(ll_score)\n",
    "    iterations_list.append(model_stage2.best_iteration)\n",
    "\n",
    "lr_df = pd.DataFrame({\n",
    "    'eta': lr_list,\n",
    "    'auc': auc_score_list,\n",
    "    'logloss': logloss_list,\n",
    "    'itr': iterations_list\n",
    "})\n",
    "print(lr_df)\n",
    "\n",
    "best_lr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['eta'].iloc[0] \n",
    "best_itr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['itr'].iloc[0] \n",
    "\n",
    "params['learning_rate'] = best_lr\n",
    "pp_model_final = xgb.train(params=params, dtrain=pp_dtrainvalid, \n",
    "                        num_boost_round=best_itr,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "print('Final Even Strength Model ==========================')\n",
    "print(f'test score against old data (AUC, LOGLOSS) = {score_model(pp_model_final, pp_dtest)}')\n",
    "print(f'test score against current data (AUC, LOGLOSS) = {score_model(pp_model_final, pp_dcurrent)}')\n",
    "print(f'test score against all test data (AUC, LOGLOSS) = {score_model(pp_model_final, pp_dtestall)}')\n",
    "print('parameters ---------------------------')\n",
    "for k, v in params.items():\n",
    "    print(k, ':', v)\n",
    "print(f'num_boost_round: {best_itr}')\n",
    "best_pp_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 13:54:22,673] A new study created in memory with name: no-name-d75f296f-2925-4fea-b731-6e5ddc4c1921\n",
      "[I 2024-02-05 13:54:25,975] Trial 0 finished with value: 0.7934312741443007 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 10, 'subsample': 0.8364932101915348, 'colsample_bynode': 0.8613021421899187, 'reg_alpha': 9.61121037604149}. Best is trial 0 with value: 0.7934312741443007.\n",
      "[I 2024-02-05 13:54:33,075] Trial 1 finished with value: 0.7961562062450446 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 2, 'subsample': 0.780027204616762, 'colsample_bynode': 0.5681319489631267, 'reg_alpha': 3.953807603593903}. Best is trial 1 with value: 0.7961562062450446.\n",
      "[I 2024-02-05 13:54:35,046] Trial 2 finished with value: 0.7928179140167682 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.7114885933939243, 'colsample_bynode': 0.7847035452441409, 'reg_alpha': 0.014133354078030192}. Best is trial 1 with value: 0.7961562062450446.\n",
      "[I 2024-02-05 13:54:37,994] Trial 3 finished with value: 0.7968836982742624 and parameters: {'tree_method': 'hist', 'max_depth': 3, 'min_child_weight': 4, 'max_delta_step': 4, 'subsample': 0.7881325935269794, 'colsample_bynode': 0.5377414858884355, 'reg_alpha': 0.00805544243490735}. Best is trial 3 with value: 0.7968836982742624.\n",
      "[I 2024-02-05 13:54:40,545] Trial 4 finished with value: 0.7924122581352587 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 3, 'max_delta_step': 3, 'subsample': 0.6554746583261235, 'colsample_bynode': 0.5686084314371924, 'reg_alpha': 0.08558113664471088}. Best is trial 3 with value: 0.7968836982742624.\n",
      "[I 2024-02-05 13:54:40,848] Trial 5 finished with value: 0.7895365559473001 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 7, 'max_delta_step': 10, 'subsample': 0.7589296045513105, 'colsample_bynode': 0.709686942923833, 'reg_alpha': 0.18170661936576954}. Best is trial 3 with value: 0.7968836982742624.\n",
      "[I 2024-02-05 13:54:40,860] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:40,965] Trial 7 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:54:40,971] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:40,983] Trial 9 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:41,012] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:41,034] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:47,907] Trial 12 finished with value: 0.7975421312775182 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 6, 'subsample': 0.727343585571938, 'colsample_bynode': 0.6699391190927029, 'reg_alpha': 1.5556269062020258}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:47,929] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:47,964] Trial 14 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:47,984] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:48,283] Trial 16 finished with value: 0.7896791549283895 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 6, 'subsample': 0.7276455389995156, 'colsample_bynode': 0.5731547740599805, 'reg_alpha': 0.005400291317813906}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:48,315] Trial 17 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:48,336] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:48,412] Trial 19 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:54:48,432] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:48,454] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:48,561] Trial 22 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:54:52,011] Trial 23 pruned. Trial was pruned at iteration 327.\n",
      "[I 2024-02-05 13:54:52,051] Trial 24 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:54:52,073] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,103] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,153] Trial 27 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:54:52,182] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,198] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,220] Trial 30 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,320] Trial 31 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:54:52,340] Trial 32 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:52,358] Trial 33 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,895] Trial 34 finished with value: 0.7925738351692843 and parameters: {'tree_method': 'hist', 'max_depth': 5, 'min_child_weight': 4, 'max_delta_step': 3, 'subsample': 0.8163323920604957, 'colsample_bynode': 0.7011606616046833, 'reg_alpha': 2.6136882906279113}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:52,911] Trial 35 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,928] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,950] Trial 37 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:52,982] Trial 38 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:53,004] Trial 39 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,034] Trial 40 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,054] Trial 41 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,074] Trial 42 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,091] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,113] Trial 44 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:53,132] Trial 45 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,156] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,214] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,248] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,272] Trial 49 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:53,337] Trial 50 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:54:53,917] Trial 51 finished with value: 0.7927551810084515 and parameters: {'tree_method': 'hist', 'max_depth': 5, 'min_child_weight': 4, 'max_delta_step': 3, 'subsample': 0.8168762748652558, 'colsample_bynode': 0.7037024585270751, 'reg_alpha': 2.7769906827534565}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:53,940] Trial 52 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:53,964] Trial 53 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:54:56,608] Trial 54 finished with value: 0.7970529192462761 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 3, 'subsample': 0.8060554344770029, 'colsample_bynode': 0.7609499897201957, 'reg_alpha': 2.2747511010001}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:56,641] Trial 55 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:56,671] Trial 56 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:56,694] Trial 57 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:56,725] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:56,758] Trial 59 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:56,790] Trial 60 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:56,807] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:56,824] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,586] Trial 63 finished with value: 0.7922435643313821 and parameters: {'tree_method': 'hist', 'max_depth': 5, 'min_child_weight': 6, 'max_delta_step': 8, 'subsample': 0.8396994325721852, 'colsample_bynode': 0.7397710843351623, 'reg_alpha': 0.5392816375780468}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:54:57,603] Trial 64 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,620] Trial 65 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,640] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,867] Trial 67 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:54:57,908] Trial 68 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:54:57,932] Trial 69 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,965] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:57,988] Trial 71 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:58,011] Trial 72 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:58,108] Trial 73 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:54:58,125] Trial 74 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,154] Trial 75 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:54:58,174] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,213] Trial 77 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:58,447] Trial 78 pruned. Trial was pruned at iteration 50.\n",
      "[I 2024-02-05 13:54:58,467] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,490] Trial 80 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,514] Trial 81 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,539] Trial 82 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,574] Trial 83 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:54:58,599] Trial 84 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,623] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,656] Trial 86 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,706] Trial 87 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:54:58,731] Trial 88 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,763] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:54:58,788] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,463] Trial 91 pruned. Trial was pruned at iteration 370.\n",
      "[I 2024-02-05 13:55:00,482] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,502] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,525] Trial 94 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:00,547] Trial 95 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:00,570] Trial 96 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:00,589] Trial 97 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,607] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,640] Trial 99 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:00,674] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,694] Trial 101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:00,741] Trial 102 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:55:00,829] Trial 103 pruned. Trial was pruned at iteration 18.\n",
      "[I 2024-02-05 13:55:00,915] Trial 104 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:55:00,962] Trial 105 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:55:00,982] Trial 106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,018] Trial 107 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:01,050] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,075] Trial 109 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:01,110] Trial 110 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:01,142] Trial 111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,409] Trial 112 finished with value: 0.790868709829788 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 10, 'subsample': 0.7901798205073863, 'colsample_bynode': 0.7540340112309457, 'reg_alpha': 0.15239832771384565}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:01,449] Trial 113 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:01,469] Trial 114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,488] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,508] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,527] Trial 117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:01,563] Trial 118 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:03,247] Trial 119 pruned. Trial was pruned at iteration 410.\n",
      "[I 2024-02-05 13:55:03,739] Trial 120 pruned. Trial was pruned at iteration 109.\n",
      "[I 2024-02-05 13:55:03,758] Trial 121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:03,808] Trial 122 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:55:03,830] Trial 123 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:03,856] Trial 124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:03,889] Trial 125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:03,910] Trial 126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:03,956] Trial 127 pruned. Trial was pruned at iteration 8.\n",
      "[I 2024-02-05 13:55:03,983] Trial 128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:04,018] Trial 129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:04,040] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:04,290] Trial 131 finished with value: 0.7914617739840416 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.844786163115142, 'colsample_bynode': 0.7156836048497837, 'reg_alpha': 0.002996977774096022}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:04,312] Trial 132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:04,854] Trial 133 finished with value: 0.7927973544594207 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8131670967948832, 'colsample_bynode': 0.7408159104802035, 'reg_alpha': 0.0023005331817441193}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:05,389] Trial 134 finished with value: 0.7926874399028324 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8049225698963434, 'colsample_bynode': 0.7407195161801161, 'reg_alpha': 0.0020631939362556894}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:05,898] Trial 135 finished with value: 0.7925205911874357 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8109057010718231, 'colsample_bynode': 0.7408780476169579, 'reg_alpha': 0.002375719638558838}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:06,867] Trial 136 finished with value: 0.7933142428178613 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8140080636918806, 'colsample_bynode': 0.7285049349078215, 'reg_alpha': 0.0019368691322919893}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:07,385] Trial 137 finished with value: 0.7928350469812244 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8132334009865481, 'colsample_bynode': 0.7441587381140036, 'reg_alpha': 0.0013462854601172273}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:07,888] Trial 138 finished with value: 0.7929051603434606 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.813900142338859, 'colsample_bynode': 0.7314099769882492, 'reg_alpha': 0.0011672926919657385}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:08,188] Trial 139 pruned. Trial was pruned at iteration 70.\n",
      "[I 2024-02-05 13:55:08,209] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:08,733] Trial 141 finished with value: 0.7926555462305369 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8109195076486573, 'colsample_bynode': 0.7372045956424196, 'reg_alpha': 0.0013392337945045561}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:11,321] Trial 142 finished with value: 0.7972753842001383 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8103809972516044, 'colsample_bynode': 0.7389359678178776, 'reg_alpha': 0.0012661331433272604}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:11,341] Trial 143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:11,362] Trial 144 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:11,381] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:11,667] Trial 146 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:11,687] Trial 147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:11,706] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:11,729] Trial 149 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:11,749] Trial 150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:13,646] Trial 151 pruned. Trial was pruned at iteration 457.\n",
      "[I 2024-02-05 13:55:13,666] Trial 152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:13,953] Trial 153 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:13,974] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,024] Trial 155 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:55:14,046] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,329] Trial 157 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:14,594] Trial 158 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:14,613] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,633] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,728] Trial 161 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:14,753] Trial 162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,780] Trial 163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,818] Trial 164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,860] Trial 165 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:14,887] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,921] Trial 167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,941] Trial 168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,962] Trial 169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:14,990] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,031] Trial 171 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:15,052] Trial 172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,074] Trial 173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,096] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,117] Trial 175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,144] Trial 176 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:15,165] Trial 177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,215] Trial 178 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:15,235] Trial 179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,262] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,297] Trial 181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,317] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,339] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,363] Trial 184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,661] Trial 185 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:15,682] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,703] Trial 187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,724] Trial 188 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,746] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,774] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,813] Trial 191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,834] Trial 192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,856] Trial 193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:15,878] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,147] Trial 195 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:16,168] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,193] Trial 197 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:16,215] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,237] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,263] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,310] Trial 201 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:16,331] Trial 202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,354] Trial 203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,375] Trial 204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,397] Trial 205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,418] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,446] Trial 207 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:16,467] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,512] Trial 209 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:16,547] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,569] Trial 211 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,591] Trial 212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,617] Trial 213 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:16,640] Trial 214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,662] Trial 215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,687] Trial 216 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:16,708] Trial 217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,737] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,823] Trial 219 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:55:16,846] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,883] Trial 221 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:55:16,906] Trial 222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:16,931] Trial 223 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:16,952] Trial 224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,466] Trial 225 finished with value: 0.7927878654329527 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.813381517728686, 'colsample_bynode': 0.7325972759147608, 'reg_alpha': 0.0020670109663149332}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:17,489] Trial 226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,510] Trial 227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,549] Trial 228 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:17,585] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,608] Trial 230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,630] Trial 231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:17,892] Trial 232 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:18,140] Trial 233 pruned. Trial was pruned at iteration 60.\n",
      "[I 2024-02-05 13:55:18,161] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,187] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,209] Trial 236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,238] Trial 237 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:18,262] Trial 238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,292] Trial 239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,333] Trial 240 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:18,406] Trial 241 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:55:18,429] Trial 242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,451] Trial 243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,474] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,498] Trial 245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,778] Trial 246 pruned. Trial was pruned at iteration 63.\n",
      "[I 2024-02-05 13:55:18,803] Trial 247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,827] Trial 248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,850] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,878] Trial 250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,916] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,940] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,964] Trial 253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:18,987] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,010] Trial 255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,038] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,074] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,098] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,121] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,145] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,169] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,198] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,236] Trial 263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,262] Trial 264 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:19,294] Trial 265 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:19,317] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,344] Trial 267 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:19,378] Trial 268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,418] Trial 269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,444] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,468] Trial 271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,492] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,765] Trial 273 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:19,795] Trial 274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,831] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,870] Trial 276 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:19,893] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,922] Trial 278 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:19,947] Trial 279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:19,976] Trial 280 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:20,016] Trial 281 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:20,054] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,080] Trial 283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,103] Trial 284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,127] Trial 285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,150] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,179] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,224] Trial 288 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:20,271] Trial 289 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:20,295] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,320] Trial 291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,346] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,390] Trial 293 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:20,428] Trial 294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,459] Trial 295 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:20,503] Trial 296 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:20,527] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,550] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,576] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,606] Trial 300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,645] Trial 301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,670] Trial 302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,695] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,720] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,743] Trial 305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,776] Trial 306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,813] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,838] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,862] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,886] Trial 310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,916] Trial 311 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:20,946] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:20,984] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,007] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,033] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,059] Trial 316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,083] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,124] Trial 318 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:21,166] Trial 319 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:21,190] Trial 320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,475] Trial 321 pruned. Trial was pruned at iteration 67.\n",
      "[I 2024-02-05 13:55:21,501] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,527] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,551] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,582] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,621] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,697] Trial 327 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:55:21,722] Trial 328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,748] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,773] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,803] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,846] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,871] Trial 333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,895] Trial 334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,920] Trial 335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,946] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:21,985] Trial 337 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:22,024] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,165] Trial 339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,191] Trial 340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,222] Trial 341 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:22,247] Trial 342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,278] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,320] Trial 344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,345] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,373] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,433] Trial 347 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:55:22,459] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,525] Trial 349 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:22,584] Trial 350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,628] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,671] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,801] Trial 353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:22,837] Trial 354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,199] Trial 355 pruned. Trial was pruned at iteration 60.\n",
      "[I 2024-02-05 13:55:23,227] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,266] Trial 357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,315] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,343] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,374] Trial 360 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:23,450] Trial 361 pruned. Trial was pruned at iteration 10.\n",
      "[I 2024-02-05 13:55:23,494] Trial 362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,535] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,560] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,586] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,614] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,639] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,672] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,716] Trial 369 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:23,744] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,771] Trial 371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,800] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,827] Trial 373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,853] Trial 374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,888] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,928] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,955] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:23,985] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,013] Trial 379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,039] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,071] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,116] Trial 382 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:24,144] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,171] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,199] Trial 385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,227] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,262] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,333] Trial 388 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:55:24,360] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,701] Trial 390 pruned. Trial was pruned at iteration 67.\n",
      "[I 2024-02-05 13:55:24,729] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,756] Trial 392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:24,791] Trial 393 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:24,829] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,136] Trial 395 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:25,163] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,190] Trial 397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,218] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,246] Trial 399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,288] Trial 400 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:25,333] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,361] Trial 402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,391] Trial 403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,727] Trial 404 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:25,759] Trial 405 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:25,794] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,838] Trial 407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,866] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,894] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:25,927] Trial 410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,041] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,245] Trial 412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,296] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,332] Trial 414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,372] Trial 415 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:26,404] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,437] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,467] Trial 418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,511] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,554] Trial 420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,584] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,614] Trial 422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,644] Trial 423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,680] Trial 424 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:26,716] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,764] Trial 426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,792] Trial 427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:26,821] Trial 428 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,353] Trial 429 pruned. Trial was pruned at iteration 39.\n",
      "[I 2024-02-05 13:55:27,381] Trial 430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,416] Trial 431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,460] Trial 432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,492] Trial 433 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:27,522] Trial 434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,559] Trial 435 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:27,587] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,621] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,669] Trial 438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,710] Trial 439 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:27,739] Trial 440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,772] Trial 441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:27,806] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,339] Trial 443 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:29,380] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,430] Trial 445 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,476] Trial 446 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:29,508] Trial 447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,542] Trial 448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,591] Trial 449 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:29,640] Trial 450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:29,760] Trial 451 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:29,804] Trial 452 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:29,842] Trial 453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,090] Trial 454 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:55:30,132] Trial 455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,193] Trial 456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,248] Trial 457 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,296] Trial 458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,332] Trial 459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,369] Trial 460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,543] Trial 461 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:55:30,588] Trial 462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:30,636] Trial 463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,034] Trial 464 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:31,076] Trial 465 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:31,108] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,140] Trial 467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,174] Trial 468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,223] Trial 469 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:31,270] Trial 470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,302] Trial 471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,335] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,366] Trial 473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,397] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,434] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,480] Trial 476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,511] Trial 477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,543] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,583] Trial 479 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:31,614] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,661] Trial 481 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:31,708] Trial 482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:31,738] Trial 483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,025] Trial 484 pruned. Trial was pruned at iteration 60.\n",
      "[I 2024-02-05 13:55:32,055] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,087] Trial 486 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,175] Trial 487 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:32,221] Trial 488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,252] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,285] Trial 490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,318] Trial 491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,410] Trial 492 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:55:32,441] Trial 493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,480] Trial 494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,553] Trial 495 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:32,586] Trial 496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,618] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,658] Trial 498 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:32,688] Trial 499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,739] Trial 500 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:32,793] Trial 501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,826] Trial 502 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:32,971] Trial 503 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:55:33,002] Trial 504 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,036] Trial 505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,072] Trial 506 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,116] Trial 507 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,147] Trial 508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,183] Trial 509 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:33,214] Trial 510 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,248] Trial 511 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,285] Trial 512 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,334] Trial 513 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:33,369] Trial 514 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,405] Trial 515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,439] Trial 516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,473] Trial 517 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,505] Trial 518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,546] Trial 519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,598] Trial 520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,688] Trial 521 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:33,728] Trial 522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,760] Trial 523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,795] Trial 524 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,835] Trial 525 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,898] Trial 526 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:33,932] Trial 527 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:33,974] Trial 528 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:34,009] Trial 529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,043] Trial 530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,092] Trial 531 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:34,141] Trial 532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,175] Trial 533 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,503] Trial 534 pruned. Trial was pruned at iteration 68.\n",
      "[I 2024-02-05 13:55:34,535] Trial 535 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,569] Trial 536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,607] Trial 537 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,658] Trial 538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,692] Trial 539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,729] Trial 540 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,763] Trial 541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,798] Trial 542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,834] Trial 543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,876] Trial 544 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,926] Trial 545 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,960] Trial 546 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:34,992] Trial 547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,024] Trial 548 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,056] Trial 549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,096] Trial 550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,143] Trial 551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,187] Trial 552 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:35,221] Trial 553 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,255] Trial 554 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,288] Trial 555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,329] Trial 556 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,377] Trial 557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,413] Trial 558 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,448] Trial 559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,485] Trial 560 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:35,786] Trial 561 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:35,825] Trial 562 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,877] Trial 563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,911] Trial 564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,944] Trial 565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:35,976] Trial 566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,010] Trial 567 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,043] Trial 568 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,083] Trial 569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,143] Trial 570 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,193] Trial 571 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:36,230] Trial 572 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,272] Trial 573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,306] Trial 574 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,346] Trial 575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,396] Trial 576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,430] Trial 577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,465] Trial 578 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,501] Trial 579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,536] Trial 580 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:36,586] Trial 581 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:36,639] Trial 582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,009] Trial 583 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:37,044] Trial 584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,077] Trial 585 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,111] Trial 586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,153] Trial 587 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,201] Trial 588 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,236] Trial 589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,270] Trial 590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,306] Trial 591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,344] Trial 592 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:37,385] Trial 593 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:37,426] Trial 594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,475] Trial 595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,509] Trial 596 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,545] Trial 597 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,580] Trial 598 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,614] Trial 599 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:37,664] Trial 600 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:37,719] Trial 601 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:37,933] Trial 602 pruned. Trial was pruned at iteration 39.\n",
      "[I 2024-02-05 13:55:37,969] Trial 603 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,031] Trial 604 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:38,070] Trial 605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,121] Trial 606 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,173] Trial 607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,208] Trial 608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,252] Trial 609 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:38,286] Trial 610 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,321] Trial 611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,362] Trial 612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,410] Trial 613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,450] Trial 614 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:38,486] Trial 615 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,520] Trial 616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,556] Trial 617 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,591] Trial 618 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,634] Trial 619 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,683] Trial 620 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,718] Trial 621 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,754] Trial 622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,790] Trial 623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,826] Trial 624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,869] Trial 625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,920] Trial 626 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,955] Trial 627 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:38,991] Trial 628 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,025] Trial 629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,061] Trial 630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,111] Trial 631 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:39,163] Trial 632 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,198] Trial 633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,234] Trial 634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,268] Trial 635 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,302] Trial 636 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,345] Trial 637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,396] Trial 638 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,430] Trial 639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,470] Trial 640 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:39,505] Trial 641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,542] Trial 642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,578] Trial 643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,631] Trial 644 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:39,685] Trial 645 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,719] Trial 646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,755] Trial 647 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,799] Trial 648 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:39,835] Trial 649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:39,875] Trial 650 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,081] Trial 651 pruned. Trial was pruned at iteration 39.\n",
      "[I 2024-02-05 13:55:40,123] Trial 652 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:40,159] Trial 653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,195] Trial 654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,230] Trial 655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,271] Trial 656 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,325] Trial 657 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:40,360] Trial 658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,396] Trial 659 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,688] Trial 660 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:40,727] Trial 661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,767] Trial 662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,818] Trial 663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:40,980] Trial 664 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:55:41,018] Trial 665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:41,063] Trial 666 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:41,371] Trial 667 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:41,419] Trial 668 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:41,470] Trial 669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:41,527] Trial 670 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:41,585] Trial 671 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:55:41,622] Trial 672 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:41,667] Trial 673 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:41,706] Trial 674 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:41,760] Trial 675 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:41,820] Trial 676 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:41,857] Trial 677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:41,898] Trial 678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,222] Trial 679 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:42,258] Trial 680 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,302] Trial 681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,357] Trial 682 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,394] Trial 683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,433] Trial 684 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:42,472] Trial 685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,507] Trial 686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,696] Trial 687 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:55:42,751] Trial 688 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:42,787] Trial 689 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:42,836] Trial 690 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:42,943] Trial 691 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:55:42,979] Trial 692 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,031] Trial 693 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:43,081] Trial 694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,117] Trial 695 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,156] Trial 696 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,192] Trial 697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,229] Trial 698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,267] Trial 699 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,308] Trial 700 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,362] Trial 701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,399] Trial 702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,438] Trial 703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,474] Trial 704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,511] Trial 705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,555] Trial 706 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,606] Trial 707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,644] Trial 708 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,683] Trial 709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,720] Trial 710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,756] Trial 711 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,799] Trial 712 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,860] Trial 713 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:43,898] Trial 714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:43,946] Trial 715 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:43,984] Trial 716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,024] Trial 717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,080] Trial 718 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:44,133] Trial 719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,176] Trial 720 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:44,216] Trial 721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,500] Trial 722 pruned. Trial was pruned at iteration 59.\n",
      "[I 2024-02-05 13:55:44,538] Trial 723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,577] Trial 724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,620] Trial 725 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,678] Trial 726 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:44,715] Trial 727 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,752] Trial 728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,791] Trial 729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,830] Trial 730 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,875] Trial 731 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,929] Trial 732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:44,969] Trial 733 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,010] Trial 734 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,073] Trial 735 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:45,113] Trial 736 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:45,181] Trial 737 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,236] Trial 738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,274] Trial 739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,313] Trial 740 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,353] Trial 741 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,647] Trial 742 pruned. Trial was pruned at iteration 60.\n",
      "[I 2024-02-05 13:55:45,692] Trial 743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,745] Trial 744 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,785] Trial 745 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,825] Trial 746 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:45,865] Trial 747 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,178] Trial 748 pruned. Trial was pruned at iteration 68.\n",
      "[I 2024-02-05 13:55:46,216] Trial 749 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,264] Trial 750 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,320] Trial 751 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,368] Trial 752 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:46,413] Trial 753 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:46,451] Trial 754 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,492] Trial 755 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,539] Trial 756 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,593] Trial 757 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,630] Trial 758 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,668] Trial 759 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,706] Trial 760 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,745] Trial 761 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,793] Trial 762 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:46,837] Trial 763 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,889] Trial 764 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:46,927] Trial 765 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,021] Trial 766 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:55:47,061] Trial 767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,106] Trial 768 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,163] Trial 769 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:47,201] Trial 770 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,241] Trial 771 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,284] Trial 772 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,326] Trial 773 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,368] Trial 774 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,415] Trial 775 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,487] Trial 776 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:47,529] Trial 777 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,570] Trial 778 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,610] Trial 779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,652] Trial 780 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,701] Trial 781 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,759] Trial 782 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:47,819] Trial 783 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:55:47,883] Trial 784 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:55:47,932] Trial 785 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:47,975] Trial 786 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,035] Trial 787 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:48,089] Trial 788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,129] Trial 789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,168] Trial 790 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,208] Trial 791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,247] Trial 792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,293] Trial 793 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:48,373] Trial 794 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:48,664] Trial 795 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:48,729] Trial 796 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:48,770] Trial 797 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,085] Trial 798 pruned. Trial was pruned at iteration 69.\n",
      "[I 2024-02-05 13:55:49,124] Trial 799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,171] Trial 800 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,224] Trial 801 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,267] Trial 802 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,308] Trial 803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,348] Trial 804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,392] Trial 805 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,440] Trial 806 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,748] Trial 807 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:49,788] Trial 808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,829] Trial 809 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,870] Trial 810 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,911] Trial 811 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:49,967] Trial 812 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:50,022] Trial 813 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,330] Trial 814 pruned. Trial was pruned at iteration 67.\n",
      "[I 2024-02-05 13:55:50,371] Trial 815 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,412] Trial 816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,481] Trial 817 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:55:50,527] Trial 818 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,582] Trial 819 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,623] Trial 820 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,665] Trial 821 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,705] Trial 822 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,746] Trial 823 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,790] Trial 824 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:50,839] Trial 825 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,893] Trial 826 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,935] Trial 827 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:50,977] Trial 828 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,292] Trial 829 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:55:51,332] Trial 830 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,378] Trial 831 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,434] Trial 832 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,479] Trial 833 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:51,521] Trial 834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,562] Trial 835 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,603] Trial 836 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,651] Trial 837 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,714] Trial 838 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:51,756] Trial 839 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:51,806] Trial 840 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:51,851] Trial 841 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:52,128] Trial 842 pruned. Trial was pruned at iteration 61.\n",
      "[I 2024-02-05 13:55:52,175] Trial 843 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,231] Trial 844 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,274] Trial 845 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,315] Trial 846 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,355] Trial 847 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,396] Trial 848 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,442] Trial 849 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,502] Trial 850 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:52,545] Trial 851 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,588] Trial 852 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,637] Trial 853 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:52,681] Trial 854 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,726] Trial 855 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:52,774] Trial 856 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,835] Trial 857 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:52,879] Trial 858 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,920] Trial 859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:52,974] Trial 860 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:53,018] Trial 861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,073] Trial 862 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:53,130] Trial 863 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,173] Trial 864 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,467] Trial 865 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:53,531] Trial 866 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:53,578] Trial 867 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:53,628] Trial 868 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,684] Trial 869 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,725] Trial 870 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,768] Trial 871 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,812] Trial 872 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,853] Trial 873 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:53,910] Trial 874 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:53,969] Trial 875 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,011] Trial 876 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,052] Trial 877 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,096] Trial 878 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,137] Trial 879 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,178] Trial 880 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,228] Trial 881 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,286] Trial 882 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,334] Trial 883 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:54,376] Trial 884 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,420] Trial 885 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,461] Trial 886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,508] Trial 887 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,571] Trial 888 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:54,614] Trial 889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,656] Trial 890 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,704] Trial 891 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:54,746] Trial 892 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,795] Trial 893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,854] Trial 894 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:54,969] Trial 895 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:55:55,013] Trial 896 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,055] Trial 897 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,098] Trial 898 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,150] Trial 899 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,206] Trial 900 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,250] Trial 901 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,293] Trial 902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,335] Trial 903 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,622] Trial 904 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:55:55,665] Trial 905 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,713] Trial 906 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,771] Trial 907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,814] Trial 908 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,859] Trial 909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,908] Trial 910 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:55:55,949] Trial 911 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:55,998] Trial 912 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,054] Trial 913 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,097] Trial 914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,141] Trial 915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,183] Trial 916 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,226] Trial 917 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,286] Trial 918 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:56,401] Trial 919 pruned. Trial was pruned at iteration 15.\n",
      "[I 2024-02-05 13:55:56,520] Trial 920 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:55:56,562] Trial 921 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,605] Trial 922 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,649] Trial 923 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,700] Trial 924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,761] Trial 925 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,804] Trial 926 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,847] Trial 927 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,891] Trial 928 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:56,938] Trial 929 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:56,995] Trial 930 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:55:57,043] Trial 931 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,101] Trial 932 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,147] Trial 933 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,191] Trial 934 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,234] Trial 935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,277] Trial 936 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,335] Trial 937 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:57,392] Trial 938 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,435] Trial 939 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,479] Trial 940 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,523] Trial 941 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,568] Trial 942 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,626] Trial 943 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:57,683] Trial 944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,727] Trial 945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,770] Trial 946 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,818] Trial 947 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:57,862] Trial 948 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,911] Trial 949 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:57,969] Trial 950 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,013] Trial 951 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,058] Trial 952 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,103] Trial 953 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,147] Trial 954 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,194] Trial 955 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:58,246] Trial 956 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,319] Trial 957 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:55:58,362] Trial 958 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,406] Trial 959 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,450] Trial 960 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,495] Trial 961 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,545] Trial 962 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,607] Trial 963 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:58,650] Trial 964 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,221] Trial 965 finished with value: 0.7929773823782452 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8133289229810406, 'colsample_bynode': 0.7458030092525133, 'reg_alpha': 0.1496086066463806}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:55:59,265] Trial 966 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,314] Trial 967 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:59,357] Trial 968 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,417] Trial 969 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:55:59,478] Trial 970 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,524] Trial 971 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,593] Trial 972 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:55:59,638] Trial 973 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:55:59,958] Trial 974 pruned. Trial was pruned at iteration 68.\n",
      "[I 2024-02-05 13:56:00,011] Trial 975 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,069] Trial 976 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,115] Trial 977 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,162] Trial 978 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,207] Trial 979 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,251] Trial 980 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,337] Trial 981 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,676] Trial 982 pruned. Trial was pruned at iteration 68.\n",
      "[I 2024-02-05 13:56:00,739] Trial 983 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:56:00,786] Trial 984 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,835] Trial 985 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,882] Trial 986 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:00,927] Trial 987 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:00,976] Trial 988 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,038] Trial 989 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,084] Trial 990 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,130] Trial 991 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,176] Trial 992 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,226] Trial 993 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:01,287] Trial 994 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:01,353] Trial 995 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:01,399] Trial 996 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,444] Trial 997 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,490] Trial 998 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,536] Trial 999 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,582] Trial 1000 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,633] Trial 1001 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,694] Trial 1002 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,741] Trial 1003 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,788] Trial 1004 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,832] Trial 1005 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,884] Trial 1006 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,944] Trial 1007 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:01,994] Trial 1008 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:02,040] Trial 1009 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,085] Trial 1010 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,131] Trial 1011 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,183] Trial 1012 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,244] Trial 1013 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,291] Trial 1014 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,336] Trial 1015 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,382] Trial 1016 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,428] Trial 1017 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,475] Trial 1018 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,526] Trial 1019 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,590] Trial 1020 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,636] Trial 1021 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,680] Trial 1022 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,728] Trial 1023 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,774] Trial 1024 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,826] Trial 1025 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,886] Trial 1026 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,932] Trial 1027 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:02,979] Trial 1028 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,025] Trial 1029 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,071] Trial 1030 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,125] Trial 1031 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,196] Trial 1032 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:03,265] Trial 1033 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:03,312] Trial 1034 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,359] Trial 1035 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,405] Trial 1036 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,458] Trial 1037 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,518] Trial 1038 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:03,567] Trial 1039 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,120] Trial 1040 finished with value: 0.7928903996356214 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.8134678996429069, 'colsample_bynode': 0.7303550702571016, 'reg_alpha': 0.009234995367306055}. Best is trial 12 with value: 0.7975421312775182.\n",
      "[I 2024-02-05 13:56:04,406] Trial 1041 pruned. Trial was pruned at iteration 57.\n",
      "[I 2024-02-05 13:56:04,453] Trial 1042 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,500] Trial 1043 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,547] Trial 1044 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,602] Trial 1045 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,664] Trial 1046 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,712] Trial 1047 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,768] Trial 1048 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:04,816] Trial 1049 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,863] Trial 1050 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,914] Trial 1051 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:04,975] Trial 1052 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,024] Trial 1053 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,091] Trial 1054 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:05,137] Trial 1055 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,237] Trial 1056 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:56:05,319] Trial 1057 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:05,382] Trial 1058 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,429] Trial 1059 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,475] Trial 1060 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,592] Trial 1061 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:56:05,640] Trial 1062 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,692] Trial 1063 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,752] Trial 1064 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,801] Trial 1065 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,870] Trial 1066 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:05,919] Trial 1067 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:05,965] Trial 1068 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,018] Trial 1069 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,079] Trial 1070 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,128] Trial 1071 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,175] Trial 1072 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,224] Trial 1073 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,283] Trial 1074 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:06,330] Trial 1075 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,383] Trial 1076 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,467] Trial 1077 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:06,515] Trial 1078 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,562] Trial 1079 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,609] Trial 1080 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,656] Trial 1081 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,708] Trial 1082 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,769] Trial 1083 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,817] Trial 1084 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,865] Trial 1085 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:06,941] Trial 1086 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:56:06,988] Trial 1087 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,052] Trial 1088 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:07,114] Trial 1089 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,163] Trial 1090 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,213] Trial 1091 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,259] Trial 1092 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,308] Trial 1093 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,362] Trial 1094 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,424] Trial 1095 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,472] Trial 1096 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,541] Trial 1097 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:07,595] Trial 1098 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,646] Trial 1099 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:07,695] Trial 1100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,760] Trial 1101 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:07,823] Trial 1102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:07,871] Trial 1103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,036] Trial 1104 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:56:08,088] Trial 1105 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:08,136] Trial 1106 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,203] Trial 1107 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:08,265] Trial 1108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,312] Trial 1109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,362] Trial 1110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,604] Trial 1111 pruned. Trial was pruned at iteration 50.\n",
      "[I 2024-02-05 13:56:08,662] Trial 1112 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:08,717] Trial 1113 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,783] Trial 1114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,834] Trial 1115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,882] Trial 1116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:08,933] Trial 1117 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:09,036] Trial 1118 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:56:09,091] Trial 1119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,156] Trial 1120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,204] Trial 1121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,254] Trial 1122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,326] Trial 1123 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:09,374] Trial 1124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,430] Trial 1125 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:09,485] Trial 1126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,549] Trial 1127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,596] Trial 1128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,646] Trial 1129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,697] Trial 1130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,746] Trial 1131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,800] Trial 1132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,863] Trial 1133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:09,920] Trial 1134 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:09,969] Trial 1135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,018] Trial 1136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,070] Trial 1137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,126] Trial 1138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,197] Trial 1139 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:10,250] Trial 1140 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:10,299] Trial 1141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,352] Trial 1142 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:10,400] Trial 1143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,454] Trial 1144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,593] Trial 1145 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:56:10,644] Trial 1146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,694] Trial 1147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,750] Trial 1148 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:10,799] Trial 1149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,871] Trial 1150 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:10,927] Trial 1151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:10,989] Trial 1152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,041] Trial 1153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,091] Trial 1154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,141] Trial 1155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,191] Trial 1156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,260] Trial 1157 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:11,326] Trial 1158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,497] Trial 1159 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:56:11,546] Trial 1160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,599] Trial 1161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,648] Trial 1162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,705] Trial 1163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,771] Trial 1164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,821] Trial 1165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,872] Trial 1166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,922] Trial 1167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:11,976] Trial 1168 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:12,031] Trial 1169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,099] Trial 1170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,148] Trial 1171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,199] Trial 1172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,248] Trial 1173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,318] Trial 1174 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:56:12,375] Trial 1175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,563] Trial 1176 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:56:12,615] Trial 1177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,665] Trial 1178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,715] Trial 1179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,787] Trial 1180 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:12,838] Trial 1181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,896] Trial 1182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:12,963] Trial 1183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,020] Trial 1184 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:13,070] Trial 1185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,120] Trial 1186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,170] Trial 1187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,236] Trial 1188 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:13,303] Trial 1189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,359] Trial 1190 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:13,411] Trial 1191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,463] Trial 1192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,515] Trial 1193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,570] Trial 1194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,636] Trial 1195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,686] Trial 1196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,741] Trial 1197 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:13,790] Trial 1198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,843] Trial 1199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,899] Trial 1200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:13,966] Trial 1201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,019] Trial 1202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,069] Trial 1203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,121] Trial 1204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,172] Trial 1205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,224] Trial 1206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,275] Trial 1207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,335] Trial 1208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,425] Trial 1209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,478] Trial 1210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,535] Trial 1211 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:14,588] Trial 1212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,646] Trial 1213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,712] Trial 1214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,765] Trial 1215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,817] Trial 1216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,873] Trial 1217 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:14,926] Trial 1218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:14,983] Trial 1219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,050] Trial 1220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,102] Trial 1221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,160] Trial 1222 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:15,235] Trial 1223 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:15,287] Trial 1224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,344] Trial 1225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,411] Trial 1226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,463] Trial 1227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,516] Trial 1228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,568] Trial 1229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,620] Trial 1230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,674] Trial 1231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,732] Trial 1232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,798] Trial 1233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,851] Trial 1234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:15,910] Trial 1235 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:15,962] Trial 1236 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,014] Trial 1237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,073] Trial 1238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,389] Trial 1239 pruned. Trial was pruned at iteration 62.\n",
      "[I 2024-02-05 13:56:16,442] Trial 1240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,493] Trial 1241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,546] Trial 1242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,600] Trial 1243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,796] Trial 1244 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:56:16,868] Trial 1245 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:16,920] Trial 1246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:16,972] Trial 1247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,024] Trial 1248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,079] Trial 1249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,136] Trial 1250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,200] Trial 1251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,253] Trial 1252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,325] Trial 1253 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:17,381] Trial 1254 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:17,433] Trial 1255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,493] Trial 1256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,562] Trial 1257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,614] Trial 1258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,667] Trial 1259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,729] Trial 1260 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:17,782] Trial 1261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,838] Trial 1262 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:17,900] Trial 1263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:17,970] Trial 1264 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:18,024] Trial 1265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,076] Trial 1266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,157] Trial 1267 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:56:18,210] Trial 1268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,269] Trial 1269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,339] Trial 1270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,395] Trial 1271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,448] Trial 1272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,500] Trial 1273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,554] Trial 1274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,614] Trial 1275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,680] Trial 1276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,756] Trial 1277 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:18,811] Trial 1278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,864] Trial 1279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,919] Trial 1280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:18,989] Trial 1281 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:19,056] Trial 1282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,138] Trial 1283 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:56:19,193] Trial 1284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,245] Trial 1285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,299] Trial 1286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,358] Trial 1287 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:19,422] Trial 1288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,493] Trial 1289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,547] Trial 1290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,606] Trial 1291 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:19,660] Trial 1292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,715] Trial 1293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,776] Trial 1294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,846] Trial 1295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:19,925] Trial 1296 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:19,981] Trial 1297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,035] Trial 1298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,204] Trial 1299 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:56:20,262] Trial 1300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,330] Trial 1301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,383] Trial 1302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,458] Trial 1303 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:20,514] Trial 1304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,572] Trial 1305 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:20,641] Trial 1306 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:20,709] Trial 1307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,783] Trial 1308 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:20,836] Trial 1309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:20,911] Trial 1310 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:20,966] Trial 1311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,018] Trial 1312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,081] Trial 1313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,148] Trial 1314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,202] Trial 1315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,257] Trial 1316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,321] Trial 1317 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:21,377] Trial 1318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,438] Trial 1319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,507] Trial 1320 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,585] Trial 1321 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:21,639] Trial 1322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,693] Trial 1323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,768] Trial 1324 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:21,831] Trial 1325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:21,904] Trial 1326 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:21,957] Trial 1327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,014] Trial 1328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,069] Trial 1329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,123] Trial 1330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,186] Trial 1331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,265] Trial 1332 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:22,318] Trial 1333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,374] Trial 1334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,456] Trial 1335 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:56:22,512] Trial 1336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,567] Trial 1337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:22,636] Trial 1338 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:22,961] Trial 1339 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:56:23,016] Trial 1340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,072] Trial 1341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,127] Trial 1342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,187] Trial 1343 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:23,249] Trial 1344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,344] Trial 1345 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:23,400] Trial 1346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,455] Trial 1347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,511] Trial 1348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,566] Trial 1349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,627] Trial 1350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,697] Trial 1351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,752] Trial 1352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,809] Trial 1353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,864] Trial 1354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:23,928] Trial 1355 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:23,993] Trial 1356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,062] Trial 1357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,118] Trial 1358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,288] Trial 1359 pruned. Trial was pruned at iteration 30.\n",
      "[I 2024-02-05 13:56:24,345] Trial 1360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,401] Trial 1361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,464] Trial 1362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,544] Trial 1363 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:24,600] Trial 1364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,658] Trial 1365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,715] Trial 1366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,770] Trial 1367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,827] Trial 1368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,889] Trial 1369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:24,960] Trial 1370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,019] Trial 1371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,077] Trial 1372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,135] Trial 1373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,192] Trial 1374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,254] Trial 1375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,327] Trial 1376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,384] Trial 1377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,463] Trial 1378 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:25,519] Trial 1379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,837] Trial 1380 pruned. Trial was pruned at iteration 63.\n",
      "[I 2024-02-05 13:56:25,901] Trial 1381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:25,970] Trial 1382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,027] Trial 1383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,083] Trial 1384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,140] Trial 1385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,431] Trial 1386 pruned. Trial was pruned at iteration 57.\n",
      "[I 2024-02-05 13:56:26,494] Trial 1387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,566] Trial 1388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,623] Trial 1389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,684] Trial 1390 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:26,744] Trial 1391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,801] Trial 1392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,862] Trial 1393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:26,934] Trial 1394 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:27,006] Trial 1395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,074] Trial 1396 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:27,130] Trial 1397 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,189] Trial 1398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,253] Trial 1399 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:27,325] Trial 1400 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:27,419] Trial 1401 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:27,476] Trial 1402 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,533] Trial 1403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,589] Trial 1404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,647] Trial 1405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,711] Trial 1406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,786] Trial 1407 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:27,847] Trial 1408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,904] Trial 1409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:27,962] Trial 1410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,018] Trial 1411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,080] Trial 1412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,174] Trial 1413 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:28,231] Trial 1414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,288] Trial 1415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,346] Trial 1416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,404] Trial 1417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,461] Trial 1418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,526] Trial 1419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,598] Trial 1420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,678] Trial 1421 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:28,738] Trial 1422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,797] Trial 1423 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,854] Trial 1424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,920] Trial 1425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:28,995] Trial 1426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,053] Trial 1427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,371] Trial 1428 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:56:29,430] Trial 1429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,486] Trial 1430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,551] Trial 1431 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,626] Trial 1432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,685] Trial 1433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,743] Trial 1434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:29,807] Trial 1435 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:29,876] Trial 1436 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:29,941] Trial 1437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,012] Trial 1438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,093] Trial 1439 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:30,153] Trial 1440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,213] Trial 1441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,270] Trial 1442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,343] Trial 1443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:30,416] Trial 1444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,520] Trial 1445 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:30,580] Trial 1446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,644] Trial 1447 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:30,703] Trial 1448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,764] Trial 1449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,839] Trial 1450 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:30,911] Trial 1451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:30,970] Trial 1452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,030] Trial 1453 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,089] Trial 1454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,149] Trial 1455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,213] Trial 1456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,509] Trial 1457 pruned. Trial was pruned at iteration 57.\n",
      "[I 2024-02-05 13:56:31,568] Trial 1458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,630] Trial 1459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,689] Trial 1460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,749] Trial 1461 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,813] Trial 1462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,887] Trial 1463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:31,945] Trial 1464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,005] Trial 1465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,064] Trial 1466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,133] Trial 1467 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:32,201] Trial 1468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,278] Trial 1469 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,337] Trial 1470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,396] Trial 1471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,455] Trial 1472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,515] Trial 1473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,575] Trial 1474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,641] Trial 1475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,713] Trial 1476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,775] Trial 1477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,834] Trial 1478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:32,900] Trial 1479 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:32,959] Trial 1480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,027] Trial 1481 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,102] Trial 1482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,372] Trial 1483 pruned. Trial was pruned at iteration 53.\n",
      "[I 2024-02-05 13:56:33,431] Trial 1484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,491] Trial 1485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,551] Trial 1486 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,618] Trial 1487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,693] Trial 1488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,758] Trial 1489 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:33,818] Trial 1490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,879] Trial 1491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:33,937] Trial 1492 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,005] Trial 1493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,084] Trial 1494 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:34,146] Trial 1495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,206] Trial 1496 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,264] Trial 1497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,328] Trial 1498 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:34,388] Trial 1499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,455] Trial 1500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,532] Trial 1501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,594] Trial 1502 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,654] Trial 1503 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,720] Trial 1504 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:34,780] Trial 1505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:34,856] Trial 1506 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:34,941] Trial 1507 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:35,001] Trial 1508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,063] Trial 1509 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,123] Trial 1510 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,185] Trial 1511 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,251] Trial 1512 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,338] Trial 1513 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:35,398] Trial 1514 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,460] Trial 1515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,520] Trial 1516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,581] Trial 1517 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,647] Trial 1518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,746] Trial 1519 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:35,808] Trial 1520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,876] Trial 1521 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:35,937] Trial 1522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:35,999] Trial 1523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,065] Trial 1524 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,141] Trial 1525 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,203] Trial 1526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,264] Trial 1527 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,325] Trial 1528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,391] Trial 1529 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:36,452] Trial 1530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,521] Trial 1531 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,599] Trial 1532 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:36,661] Trial 1533 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,721] Trial 1534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,790] Trial 1535 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:36,853] Trial 1536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:36,934] Trial 1537 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,017] Trial 1538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,083] Trial 1539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,372] Trial 1540 pruned. Trial was pruned at iteration 50.\n",
      "[I 2024-02-05 13:56:37,434] Trial 1541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,500] Trial 1542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,572] Trial 1543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,651] Trial 1544 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,723] Trial 1545 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:37,792] Trial 1546 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,858] Trial 1547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,921] Trial 1548 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:37,991] Trial 1549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,068] Trial 1550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,184] Trial 1551 pruned. Trial was pruned at iteration 13.\n",
      "[I 2024-02-05 13:56:38,247] Trial 1552 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,310] Trial 1553 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,374] Trial 1554 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,437] Trial 1555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,511] Trial 1556 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,592] Trial 1557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,669] Trial 1558 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:38,736] Trial 1559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,800] Trial 1560 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,865] Trial 1561 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:38,943] Trial 1562 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:39,029] Trial 1563 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:39,098] Trial 1564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,167] Trial 1565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,233] Trial 1566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,388] Trial 1567 pruned. Trial was pruned at iteration 14.\n",
      "[I 2024-02-05 13:56:39,460] Trial 1568 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,537] Trial 1569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,600] Trial 1570 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,663] Trial 1571 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,729] Trial 1572 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,795] Trial 1573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:39,878] Trial 1574 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:39,963] Trial 1575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,029] Trial 1576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,092] Trial 1577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,160] Trial 1578 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:40,223] Trial 1579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,322] Trial 1580 pruned. Trial was pruned at iteration 7.\n",
      "[I 2024-02-05 13:56:40,398] Trial 1581 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,483] Trial 1582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,551] Trial 1583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,620] Trial 1584 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:40,685] Trial 1585 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,749] Trial 1586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,821] Trial 1587 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,902] Trial 1588 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:40,972] Trial 1589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,043] Trial 1590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,116] Trial 1591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,184] Trial 1592 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,253] Trial 1593 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,333] Trial 1594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,397] Trial 1595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,465] Trial 1596 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:41,529] Trial 1597 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,595] Trial 1598 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,673] Trial 1599 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:41,752] Trial 1600 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,815] Trial 1601 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:41,886] Trial 1602 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:41,953] Trial 1603 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,021] Trial 1604 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,099] Trial 1605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,185] Trial 1606 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,250] Trial 1607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,315] Trial 1608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,379] Trial 1609 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,449] Trial 1610 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:42,512] Trial 1611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,584] Trial 1612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,666] Trial 1613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:42,801] Trial 1614 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:56:42,870] Trial 1615 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:42,933] Trial 1616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,010] Trial 1617 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,098] Trial 1618 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:43,177] Trial 1619 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,251] Trial 1620 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:43,555] Trial 1621 pruned. Trial was pruned at iteration 53.\n",
      "[I 2024-02-05 13:56:43,622] Trial 1622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,690] Trial 1623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,761] Trial 1624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,838] Trial 1625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:43,907] Trial 1626 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:43,972] Trial 1627 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,037] Trial 1628 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,101] Trial 1629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,186] Trial 1630 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:44,265] Trial 1631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,333] Trial 1632 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,407] Trial 1633 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:44,478] Trial 1634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,549] Trial 1635 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:44,618] Trial 1636 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,705] Trial 1637 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:44,794] Trial 1638 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,859] Trial 1639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,925] Trial 1640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:44,990] Trial 1641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,057] Trial 1642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,130] Trial 1643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,210] Trial 1644 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,277] Trial 1645 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,342] Trial 1646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,410] Trial 1647 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,478] Trial 1648 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:45,549] Trial 1649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,636] Trial 1650 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:45,702] Trial 1651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,769] Trial 1652 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,835] Trial 1653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,902] Trial 1654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:45,973] Trial 1655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,053] Trial 1656 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,140] Trial 1657 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:46,209] Trial 1658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,287] Trial 1659 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:46,357] Trial 1660 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:46,425] Trial 1661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,495] Trial 1662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,578] Trial 1663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,649] Trial 1664 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:46,714] Trial 1665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,781] Trial 1666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,847] Trial 1667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:46,918] Trial 1668 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,000] Trial 1669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,069] Trial 1670 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,137] Trial 1671 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,203] Trial 1672 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,267] Trial 1673 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,349] Trial 1674 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:47,430] Trial 1675 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,494] Trial 1676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,560] Trial 1677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,628] Trial 1678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,765] Trial 1679 pruned. Trial was pruned at iteration 19.\n",
      "[I 2024-02-05 13:56:47,839] Trial 1680 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,921] Trial 1681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:47,989] Trial 1682 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,056] Trial 1683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,124] Trial 1684 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,192] Trial 1685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,265] Trial 1686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,348] Trial 1687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,414] Trial 1688 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,674] Trial 1689 pruned. Trial was pruned at iteration 48.\n",
      "[I 2024-02-05 13:56:48,741] Trial 1690 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,815] Trial 1691 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:48,883] Trial 1692 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:48,958] Trial 1693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,040] Trial 1694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,106] Trial 1695 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,173] Trial 1696 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,241] Trial 1697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,309] Trial 1698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,397] Trial 1699 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:49,482] Trial 1700 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,548] Trial 1701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,614] Trial 1702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,685] Trial 1703 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:49,753] Trial 1704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,827] Trial 1705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:49,937] Trial 1706 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:50,004] Trial 1707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,073] Trial 1708 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,139] Trial 1709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,207] Trial 1710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,291] Trial 1711 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:50,374] Trial 1712 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,445] Trial 1713 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:50,512] Trial 1714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,586] Trial 1715 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:50,653] Trial 1716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,721] Trial 1717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,794] Trial 1718 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,876] Trial 1719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:50,955] Trial 1720 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:56:51,023] Trial 1721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,092] Trial 1722 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,161] Trial 1723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,235] Trial 1724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,341] Trial 1725 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:51,410] Trial 1726 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,670] Trial 1727 pruned. Trial was pruned at iteration 48.\n",
      "[I 2024-02-05 13:56:51,737] Trial 1728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,827] Trial 1729 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:56:51,903] Trial 1730 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:51,991] Trial 1731 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:56:52,061] Trial 1732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:52,135] Trial 1733 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:56:52,202] Trial 1734 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:52,531] Trial 1735 pruned. Trial was pruned at iteration 65.\n",
      "[I 2024-02-05 13:56:52,604] Trial 1736 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:56:52,685] Trial 1737 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate ==================================================\n",
      "========================= HyperTuning Results For Fixed Learning Rate = 0.01\n",
      "Best auc Score = 0.7975421312775182\n",
      "Best Boosting Round: 640\n",
      "========== Best Tree Params ==========\n",
      "tree_method : approx\n",
      "max_depth : 4\n",
      "min_child_weight : 8\n",
      "max_delta_step : 6\n",
      "subsample : 0.727343585571938\n",
      "colsample_bynode : 0.6699391190927029\n",
      "reg_alpha : 1.5556269062020258\n",
      " \n",
      "================================================== Stage 2 - Boosting Parameters ==================================================\n",
      "best scores (AUC , LOGLOSS) = (0.7963064491641222, 0.21277239879184384)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.001\n",
      "best boosting round: 3134\n",
      "best scores (AUC , LOGLOSS) = (0.7971087990688103, 0.21206692464631638)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.005\n",
      "best boosting round: 915\n",
      "best scores (AUC , LOGLOSS) = (0.7969058393360212, 0.21224623056703038)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.01\n",
      "best boosting round: 368\n",
      "best scores (AUC , LOGLOSS) = (0.7905798216906493, 0.21768140507458691)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.1\n",
      "best boosting round: 37\n",
      "     eta       auc   logloss   itr\n",
      "0  0.001  0.796306  0.212772  3134\n",
      "1  0.005  0.797109  0.212067   915\n",
      "2  0.010  0.796906  0.212246   368\n",
      "3  0.100  0.790580  0.217681    37\n",
      "Final Short-Handed Model ==========================\n",
      "test score against old data (AUC, LOGLOSS) = (0.8157232675848793, 0.21278876033936903)\n",
      "test score against current data (AUC, LOGLOSS) = (0.7956099456099457, 0.2385183008334204)\n",
      "test score against all test data (AUC, LOGLOSS) = (0.8112415807617074, 0.21808178016329113)\n",
      "parameters ---------------------------\n",
      "tree_method : approx\n",
      "max_depth : 4\n",
      "min_child_weight : 8\n",
      "max_delta_step : 6\n",
      "subsample : 0.727343585571938\n",
      "colsample_bynode : 0.6699391190927029\n",
      "reg_alpha : 1.5556269062020258\n",
      "learning_rate : 0.005\n",
      "num_boost_round: 915\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=71)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "tic = time.time()\n",
    "while time.time() - tic < 150:\n",
    "    study.optimize(lambda trial: objective(trial, dtrain = sh_dtrain, dvalid = sh_dvalid, lr = SH_eta), n_trials=1)\n",
    "\n",
    "print('='*50,'Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate', '='*50)\n",
    "print('='*25, f'HyperTuning Results For Fixed Learning Rate = {SH_eta}')\n",
    "print(f'Best {e_m} Score = {study.best_trial.value}')\n",
    "print(f'Best Boosting Round: {study.best_trial.user_attrs[\"best_iteration\"]}')\n",
    "print(\"=\"*10,'Best Tree Params',\"=\"*10)\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(k, ':', v)\n",
    "\n",
    "#### STAGE 2 ####\n",
    "print(\" \")\n",
    "print('='*50, 'Stage 2 - Boosting Parameters', '='*50)\n",
    "lr_list = []\n",
    "auc_score_list = []\n",
    "logloss_list = []\n",
    "iterations_list = []\n",
    "for i in [0.001, 0.005, 0.01, 0.1]:\n",
    "    low_learning_rate = i\n",
    "    params = {}\n",
    "    params.update(study.best_trial.params)\n",
    "    params['learning_rate'] = i\n",
    "    model_stage2 = xgb.train(params=params, dtrain=sh_dtrain, \n",
    "                             num_boost_round=10000,\n",
    "                             evals=[(sh_dtrain, 'train'), (sh_dvalid, 'valid')],\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=0)\n",
    "    \n",
    "    print(f'best scores (AUC , LOGLOSS) = {score_model(model_stage2, sh_dvalid)}')\n",
    "    print('boosting params ---------------------------')\n",
    "    print(f'learning rate: {params[\"learning_rate\"]}')\n",
    "    print(f'best boosting round: {model_stage2.best_iteration}')\n",
    "    auc_score, ll_score = score_model(model_stage2, sh_dvalid)\n",
    "\n",
    "    lr_list.append(i)\n",
    "    auc_score_list.append(auc_score)\n",
    "    logloss_list.append(ll_score)\n",
    "    iterations_list.append(model_stage2.best_iteration)\n",
    "\n",
    "lr_df = pd.DataFrame({\n",
    "    'eta': lr_list,\n",
    "    'auc': auc_score_list,\n",
    "    'logloss': logloss_list,\n",
    "    'itr': iterations_list\n",
    "})\n",
    "print(lr_df)\n",
    "\n",
    "best_lr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['eta'].iloc[0] \n",
    "best_itr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['itr'].iloc[0] \n",
    "\n",
    "params['learning_rate'] = best_lr\n",
    "sh_model_final = xgb.train(params=params, dtrain=sh_dtrainvalid, \n",
    "                        num_boost_round=best_itr,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "print('Final Short-Handed Model ==========================')\n",
    "print(f'test score against old data (AUC, LOGLOSS) = {score_model(sh_model_final, sh_dtest)}')\n",
    "print(f'test score against current data (AUC, LOGLOSS) = {score_model(sh_model_final, sh_dcurrent)}')\n",
    "print(f'test score against all test data (AUC, LOGLOSS) = {score_model(sh_model_final, sh_dtestall)}')\n",
    "print('parameters ---------------------------')\n",
    "for k, v in params.items():\n",
    "    print(k, ':', v)\n",
    "print(f'num_boost_round: {best_itr}')\n",
    "best_sh_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-05 13:57:06,461] A new study created in memory with name: no-name-a295ddc6-ca2f-4e6e-92cc-46a79cbf44b8\n",
      "[I 2024-02-05 13:57:06,648] Trial 0 finished with value: 0.6878095972765003 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 2, 'max_delta_step': 10, 'subsample': 0.8364932101915348, 'colsample_bynode': 0.8613021421899187, 'reg_alpha': 9.61121037604149}. Best is trial 0 with value: 0.6878095972765003.\n",
      "[I 2024-02-05 13:57:07,091] Trial 1 finished with value: 0.6919248104961844 and parameters: {'tree_method': 'approx', 'max_depth': 4, 'min_child_weight': 8, 'max_delta_step': 2, 'subsample': 0.780027204616762, 'colsample_bynode': 0.5681319489631267, 'reg_alpha': 3.953807603593903}. Best is trial 1 with value: 0.6919248104961844.\n",
      "[I 2024-02-05 13:57:07,325] Trial 2 finished with value: 0.6922451659792039 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 5, 'max_delta_step': 3, 'subsample': 0.7114885933939243, 'colsample_bynode': 0.7847035452441409, 'reg_alpha': 0.014133354078030192}. Best is trial 2 with value: 0.6922451659792039.\n",
      "[I 2024-02-05 13:57:07,479] Trial 3 finished with value: 0.6891499901183881 and parameters: {'tree_method': 'hist', 'max_depth': 3, 'min_child_weight': 4, 'max_delta_step': 4, 'subsample': 0.7881325935269794, 'colsample_bynode': 0.5377414858884355, 'reg_alpha': 0.00805544243490735}. Best is trial 2 with value: 0.6922451659792039.\n",
      "[I 2024-02-05 13:57:07,750] Trial 4 finished with value: 0.6952096495534149 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 3, 'max_delta_step': 3, 'subsample': 0.6554746583261235, 'colsample_bynode': 0.5686084314371924, 'reg_alpha': 0.08558113664471088}. Best is trial 4 with value: 0.6952096495534149.\n",
      "[I 2024-02-05 13:57:07,801] Trial 5 pruned. Trial was pruned at iteration 20.\n",
      "[I 2024-02-05 13:57:07,822] Trial 6 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:07,831] Trial 7 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:07,835] Trial 8 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:07,882] Trial 9 pruned. Trial was pruned at iteration 11.\n",
      "[I 2024-02-05 13:57:07,897] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:07,911] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:07,941] Trial 12 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:57:07,983] Trial 13 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:57:08,001] Trial 14 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:08,016] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,032] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,054] Trial 17 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:08,070] Trial 18 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,087] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,128] Trial 20 pruned. Trial was pruned at iteration 6.\n",
      "[I 2024-02-05 13:57:08,143] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,158] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,172] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,186] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,491] Trial 25 finished with value: 0.6937497210835347 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 8, 'max_delta_step': 4, 'subsample': 0.7442326237218588, 'colsample_bynode': 0.6311533498141819, 'reg_alpha': 0.32828562019133}. Best is trial 4 with value: 0.6952096495534149.\n",
      "[I 2024-02-05 13:57:08,508] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,539] Trial 27 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:57:08,562] Trial 28 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:08,577] Trial 29 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,704] Trial 30 pruned. Trial was pruned at iteration 29.\n",
      "[I 2024-02-05 13:57:08,731] Trial 31 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:08,747] Trial 32 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,853] Trial 33 pruned. Trial was pruned at iteration 29.\n",
      "[I 2024-02-05 13:57:08,880] Trial 34 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:08,912] Trial 35 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:08,928] Trial 36 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:08,949] Trial 37 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,180] Trial 38 finished with value: 0.6925687090789701 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 4, 'subsample': 0.8687142191782371, 'colsample_bynode': 0.8816370479377982, 'reg_alpha': 0.003816618881862098}. Best is trial 4 with value: 0.6952096495534149.\n",
      "[I 2024-02-05 13:57:09,202] Trial 39 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,236] Trial 40 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:57:09,254] Trial 41 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,273] Trial 42 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,292] Trial 43 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,315] Trial 44 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,335] Trial 45 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,353] Trial 46 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,371] Trial 47 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,389] Trial 48 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,508] Trial 49 pruned. Trial was pruned at iteration 28.\n",
      "[I 2024-02-05 13:57:09,651] Trial 50 finished with value: 0.6973708537075171 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 1, 'subsample': 0.7977884371379435, 'colsample_bynode': 0.5529392647795983, 'reg_alpha': 0.03252747728595236}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:09,667] Trial 51 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,682] Trial 52 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,698] Trial 53 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,713] Trial 54 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,728] Trial 55 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,745] Trial 56 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,764] Trial 57 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,781] Trial 58 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,798] Trial 59 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,819] Trial 60 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,834] Trial 61 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,849] Trial 62 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,864] Trial 63 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,881] Trial 64 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,905] Trial 65 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:09,924] Trial 66 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,946] Trial 67 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:09,965] Trial 68 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:09,985] Trial 69 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:10,003] Trial 70 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,023] Trial 71 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,051] Trial 72 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:57:10,074] Trial 73 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:10,091] Trial 74 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,110] Trial 75 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,129] Trial 76 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,147] Trial 77 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,181] Trial 78 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:57:10,200] Trial 79 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,222] Trial 80 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:10,245] Trial 81 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:10,273] Trial 82 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:10,292] Trial 83 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,620] Trial 84 finished with value: 0.692877907903377 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 8, 'max_delta_step': 5, 'subsample': 0.7774605752998995, 'colsample_bynode': 0.5348575721427613, 'reg_alpha': 0.5275196917603509}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:10,639] Trial 85 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,679] Trial 86 pruned. Trial was pruned at iteration 5.\n",
      "[I 2024-02-05 13:57:10,698] Trial 87 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,723] Trial 88 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:10,742] Trial 89 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,759] Trial 90 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,779] Trial 91 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,797] Trial 92 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,815] Trial 93 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,833] Trial 94 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,853] Trial 95 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:10,879] Trial 96 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:10,969] Trial 97 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:57:10,990] Trial 98 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:11,315] Trial 99 finished with value: 0.6940079180399982 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7428067367038619, 'colsample_bynode': 0.6979033196569664, 'reg_alpha': 0.007141273511831426}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:11,334] Trial 100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:11,740] Trial 101 finished with value: 0.6942517707211027 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7430353141972206, 'colsample_bynode': 0.6337474318588648, 'reg_alpha': 0.01138283437893149}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:11,769] Trial 102 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:11,788] Trial 103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:11,807] Trial 104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,022] Trial 105 finished with value: 0.6916427064141224 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7371103633984288, 'colsample_bynode': 0.7501830602676507, 'reg_alpha': 0.014265947382428307}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:12,052] Trial 106 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:12,076] Trial 107 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:12,095] Trial 108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,113] Trial 109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,138] Trial 110 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:12,161] Trial 111 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:12,181] Trial 112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,202] Trial 113 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:12,430] Trial 114 finished with value: 0.6917239906411572 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7434906061823349, 'colsample_bynode': 0.6768654894982963, 'reg_alpha': 0.0037943704192189703}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:12,449] Trial 115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,468] Trial 116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,785] Trial 117 finished with value: 0.6924698929598296 and parameters: {'tree_method': 'approx', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7298235463990885, 'colsample_bynode': 0.6488827220976163, 'reg_alpha': 0.003781676873289627}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:12,809] Trial 118 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:12,828] Trial 119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,850] Trial 120 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:12,868] Trial 121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,887] Trial 122 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,905] Trial 123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,948] Trial 124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:12,983] Trial 125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,002] Trial 126 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,053] Trial 127 pruned. Trial was pruned at iteration 9.\n",
      "[I 2024-02-05 13:57:13,072] Trial 128 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,092] Trial 129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,112] Trial 130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,133] Trial 131 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,151] Trial 132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,169] Trial 133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,187] Trial 134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,206] Trial 135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,234] Trial 136 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:13,255] Trial 137 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,275] Trial 138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,295] Trial 139 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,315] Trial 140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,334] Trial 141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,354] Trial 142 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,373] Trial 143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,395] Trial 144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,415] Trial 145 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,437] Trial 146 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,540] Trial 147 pruned. Trial was pruned at iteration 20.\n",
      "[I 2024-02-05 13:57:13,561] Trial 148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,582] Trial 149 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,603] Trial 150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,630] Trial 151 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:13,650] Trial 152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,670] Trial 153 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,691] Trial 154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,711] Trial 155 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,732] Trial 156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,753] Trial 157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,777] Trial 158 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:13,797] Trial 159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,817] Trial 160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,838] Trial 161 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,859] Trial 162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,880] Trial 163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,900] Trial 164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,922] Trial 165 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,942] Trial 166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,963] Trial 167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:13,984] Trial 168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,004] Trial 169 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,025] Trial 170 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,045] Trial 171 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,065] Trial 172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,084] Trial 173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,104] Trial 174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,133] Trial 175 pruned. Trial was pruned at iteration 3.\n",
      "[I 2024-02-05 13:57:14,158] Trial 176 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:14,215] Trial 177 pruned. Trial was pruned at iteration 21.\n",
      "[I 2024-02-05 13:57:14,235] Trial 178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,255] Trial 179 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,280] Trial 180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,391] Trial 181 finished with value: 0.6945386562282844 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.729559677297752, 'colsample_bynode': 0.6607579900331578, 'reg_alpha': 0.04838700584891865}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:14,410] Trial 182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,429] Trial 183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,450] Trial 184 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:14,469] Trial 185 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,490] Trial 186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,515] Trial 187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,539] Trial 188 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:14,558] Trial 189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,579] Trial 190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,660] Trial 191 pruned. Trial was pruned at iteration 35.\n",
      "[I 2024-02-05 13:57:14,679] Trial 192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,697] Trial 193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,717] Trial 194 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,737] Trial 195 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:14,756] Trial 196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,778] Trial 197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,801] Trial 198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,823] Trial 199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,844] Trial 200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:14,926] Trial 201 pruned. Trial was pruned at iteration 35.\n",
      "[I 2024-02-05 13:57:15,042] Trial 202 finished with value: 0.6936030907131974 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7311645413732605, 'colsample_bynode': 0.6348045404290686, 'reg_alpha': 0.07012207789137549}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:15,156] Trial 203 finished with value: 0.6935664331206131 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7312320151461493, 'colsample_bynode': 0.6338131164866951, 'reg_alpha': 0.07447660382919961}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:15,268] Trial 204 finished with value: 0.6935090560191767 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7309783137398106, 'colsample_bynode': 0.6395877465639176, 'reg_alpha': 0.07291176943338588}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:15,288] Trial 205 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:15,308] Trial 206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,327] Trial 207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,345] Trial 208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,364] Trial 209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,382] Trial 210 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,401] Trial 211 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,513] Trial 212 finished with value: 0.6938708505199003 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7386300558897082, 'colsample_bynode': 0.6402406334894167, 'reg_alpha': 0.0747109095264852}. Best is trial 50 with value: 0.6973708537075171.\n",
      "[I 2024-02-05 13:57:15,533] Trial 213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,552] Trial 214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,686] Trial 215 finished with value: 0.6980577851163798 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7239196645450878, 'colsample_bynode': 0.6530955957624922, 'reg_alpha': 0.05583268187893239}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:15,705] Trial 216 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,827] Trial 217 finished with value: 0.6939011328789917 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7381848980973317, 'colsample_bynode': 0.6433136868052627, 'reg_alpha': 0.0794127955236503}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:15,846] Trial 218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,866] Trial 219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,887] Trial 220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,906] Trial 221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:15,926] Trial 222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,034] Trial 223 finished with value: 0.693483555085205 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7335908954512699, 'colsample_bynode': 0.6446010615531753, 'reg_alpha': 0.056151256758706844}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:16,053] Trial 224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,073] Trial 225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,093] Trial 226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,114] Trial 227 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,134] Trial 228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,154] Trial 229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,176] Trial 230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,195] Trial 231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,214] Trial 232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,235] Trial 233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,255] Trial 234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,274] Trial 235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,390] Trial 236 finished with value: 0.697418667958714 and parameters: {'tree_method': 'hist', 'max_depth': 4, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7262040381771789, 'colsample_bynode': 0.6824635846150212, 'reg_alpha': 0.00464787412706213}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:16,410] Trial 237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,430] Trial 238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,449] Trial 239 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,468] Trial 240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,489] Trial 241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,509] Trial 242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,529] Trial 243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,548] Trial 244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,567] Trial 245 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,587] Trial 246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,607] Trial 247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,628] Trial 248 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,648] Trial 249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,668] Trial 250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,688] Trial 251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,708] Trial 252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,831] Trial 253 finished with value: 0.6916905206653193 and parameters: {'tree_method': 'hist', 'max_depth': 5, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.7347227282703936, 'colsample_bynode': 0.778642114384582, 'reg_alpha': 0.065966492600593}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:16,852] Trial 254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,872] Trial 255 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,893] Trial 256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,916] Trial 257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,937] Trial 258 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,958] Trial 259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,979] Trial 260 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:16,999] Trial 261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,019] Trial 262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,041] Trial 263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,061] Trial 264 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,083] Trial 265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,108] Trial 266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,132] Trial 267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,156] Trial 268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,180] Trial 269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,205] Trial 270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,230] Trial 271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,254] Trial 272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,275] Trial 273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,298] Trial 274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,322] Trial 275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,347] Trial 276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,376] Trial 277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,399] Trial 278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,542] Trial 279 finished with value: 0.6938820071785129 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8989439647720109, 'colsample_bynode': 0.623117451675722, 'reg_alpha': 0.10824108443231337}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:17,564] Trial 280 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,588] Trial 281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,615] Trial 282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,638] Trial 283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,708] Trial 284 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:57:17,731] Trial 285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,755] Trial 286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,778] Trial 287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,803] Trial 288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,828] Trial 289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,851] Trial 290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,877] Trial 291 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,901] Trial 292 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,925] Trial 293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,951] Trial 294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:17,977] Trial 295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,003] Trial 296 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,024] Trial 297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,048] Trial 298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,073] Trial 299 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,098] Trial 300 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,124] Trial 301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,148] Trial 302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,174] Trial 303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,195] Trial 304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,218] Trial 305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,245] Trial 306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,270] Trial 307 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,295] Trial 308 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,318] Trial 309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,355] Trial 310 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:57:18,382] Trial 311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,407] Trial 312 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,432] Trial 313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,454] Trial 314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,478] Trial 315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,506] Trial 316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,530] Trial 317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,555] Trial 318 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,578] Trial 319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,606] Trial 320 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:18,632] Trial 321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,656] Trial 322 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,681] Trial 323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,707] Trial 324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,733] Trial 325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,757] Trial 326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,783] Trial 327 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,810] Trial 328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,836] Trial 329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,862] Trial 330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,884] Trial 331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:18,908] Trial 332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,046] Trial 333 finished with value: 0.6910625601662661 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 3, 'subsample': 0.8923017767697188, 'colsample_bynode': 0.6624030149159303, 'reg_alpha': 0.11531857479718946}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:19,176] Trial 334 finished with value: 0.6916857392401997 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 3, 'subsample': 0.8913471561664438, 'colsample_bynode': 0.6706543974428744, 'reg_alpha': 0.13001919086466993}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:19,320] Trial 335 finished with value: 0.6953562799237523 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 3, 'subsample': 0.8934932099657306, 'colsample_bynode': 0.6633556076983309, 'reg_alpha': 0.10044170721845444}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:19,345] Trial 336 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,370] Trial 337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,398] Trial 338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,426] Trial 339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,459] Trial 340 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:19,484] Trial 341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,510] Trial 342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,533] Trial 343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,562] Trial 344 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:19,588] Trial 345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,613] Trial 346 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,641] Trial 347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,664] Trial 348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,689] Trial 349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,717] Trial 350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,742] Trial 351 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,768] Trial 352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,793] Trial 353 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,817] Trial 354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,844] Trial 355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,869] Trial 356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,896] Trial 357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,922] Trial 358 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,950] Trial 359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:19,975] Trial 360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,006] Trial 361 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:20,032] Trial 362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,057] Trial 363 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,085] Trial 364 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,108] Trial 365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,135] Trial 366 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,162] Trial 367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,188] Trial 368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,215] Trial 369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,239] Trial 370 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,265] Trial 371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,294] Trial 372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,320] Trial 373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,347] Trial 374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,374] Trial 375 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,400] Trial 376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,429] Trial 377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,456] Trial 378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,487] Trial 379 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:20,514] Trial 380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,543] Trial 381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,567] Trial 382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,594] Trial 383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,623] Trial 384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,649] Trial 385 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,680] Trial 386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,704] Trial 387 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,731] Trial 388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,788] Trial 389 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,823] Trial 390 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,851] Trial 391 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,875] Trial 392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,902] Trial 393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,931] Trial 394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,958] Trial 395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:20,986] Trial 396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,236] Trial 397 finished with value: 0.6930341011239537 and parameters: {'tree_method': 'approx', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 3, 'subsample': 0.7329271894365514, 'colsample_bynode': 0.6598888086542253, 'reg_alpha': 0.006582739913231449}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:21,266] Trial 398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,294] Trial 399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,324] Trial 400 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,352] Trial 401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,431] Trial 402 pruned. Trial was pruned at iteration 22.\n",
      "[I 2024-02-05 13:57:21,457] Trial 403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,483] Trial 404 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,511] Trial 405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,537] Trial 406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,685] Trial 407 finished with value: 0.6932492652543399 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 2, 'subsample': 0.8994317900716997, 'colsample_bynode': 0.6543057225599657, 'reg_alpha': 0.06510289626612493}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:21,711] Trial 408 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,737] Trial 409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,764] Trial 410 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,791] Trial 411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,820] Trial 412 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,845] Trial 413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,872] Trial 414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,901] Trial 415 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,929] Trial 416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,958] Trial 417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:21,985] Trial 418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:22,013] Trial 419 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:22,150] Trial 420 finished with value: 0.6938166610352104 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 4, 'subsample': 0.899218579665174, 'colsample_bynode': 0.6176170127985502, 'reg_alpha': 0.029851819996034368}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,178] Trial 421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:22,307] Trial 422 finished with value: 0.6938979452622452 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.8995458304709347, 'colsample_bynode': 0.6167816050898328, 'reg_alpha': 0.03611518371071103}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,340] Trial 423 pruned. Trial was pruned at iteration 4.\n",
      "[I 2024-02-05 13:57:22,483] Trial 424 finished with value: 0.6924938000854282 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.89244504721267, 'colsample_bynode': 0.6162219119644737, 'reg_alpha': 0.031186855508251978}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,511] Trial 425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:22,536] Trial 426 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:22,676] Trial 427 finished with value: 0.6975350159699599 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.893502306552618, 'colsample_bynode': 0.6190244428612082, 'reg_alpha': 0.02263993425389248}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,817] Trial 428 finished with value: 0.6914163856251235 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.8994560615549962, 'colsample_bynode': 0.599188041040013, 'reg_alpha': 0.03566059923550988}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,962] Trial 429 finished with value: 0.6930548206328057 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8894046421785032, 'colsample_bynode': 0.6137357537910975, 'reg_alpha': 0.02428356663915654}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:22,988] Trial 430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:23,130] Trial 431 finished with value: 0.6905174777026208 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.892963288029759, 'colsample_bynode': 0.5981321575072931, 'reg_alpha': 0.023421958867020812}. Best is trial 215 with value: 0.6980577851163798.\n",
      "[I 2024-02-05 13:57:23,279] Trial 432 finished with value: 0.6982952625639914 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.893399825144551, 'colsample_bynode': 0.6168548256939773, 'reg_alpha': 0.030348499145391672}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:23,414] Trial 433 finished with value: 0.690305501188981 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8999087794858043, 'colsample_bynode': 0.6186997837862042, 'reg_alpha': 0.03868898570090056}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:23,444] Trial 434 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:23,469] Trial 435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:23,495] Trial 436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:23,521] Trial 437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:23,669] Trial 438 finished with value: 0.6941641112605749 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8913914465321253, 'colsample_bynode': 0.6075391593363832, 'reg_alpha': 0.03942258293796762}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:23,816] Trial 439 finished with value: 0.6925862409710756 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.8892914972125544, 'colsample_bynode': 0.6081716412679419, 'reg_alpha': 0.03334658277201605}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:23,842] Trial 440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:23,987] Trial 441 finished with value: 0.6923264502062388 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8998047407816107, 'colsample_bynode': 0.5955316255790352, 'reg_alpha': 0.038396829156710346}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:24,014] Trial 442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,041] Trial 443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:24,067] Trial 444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,095] Trial 445 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:24,239] Trial 446 finished with value: 0.6930548206328057 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8896646300553642, 'colsample_bynode': 0.6102742206999798, 'reg_alpha': 0.030005972952882223}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:24,266] Trial 447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,412] Trial 448 finished with value: 0.6923407944815979 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8997268998066001, 'colsample_bynode': 0.5935248392851019, 'reg_alpha': 0.019724450942945778}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:24,438] Trial 449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,588] Trial 450 finished with value: 0.6920379708906839 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8898842431304903, 'colsample_bynode': 0.6224370808055235, 'reg_alpha': 0.04299186881890629}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:24,752] Trial 451 finished with value: 0.6930723525249112 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 7, 'subsample': 0.8903818197468385, 'colsample_bynode': 0.6309440073291902, 'reg_alpha': 0.035446977996024046}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:24,777] Trial 452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,810] Trial 453 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:24,838] Trial 454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:24,864] Trial 455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:25,016] Trial 456 finished with value: 0.693070758716538 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8898238617941414, 'colsample_bynode': 0.6099642191217389, 'reg_alpha': 0.037159641508964565}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,162] Trial 457 finished with value: 0.6969341502132516 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8948844307477505, 'colsample_bynode': 0.6352305485224016, 'reg_alpha': 0.03693240722675792}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,286] Trial 458 finished with value: 0.6910402468490409 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8999418506027549, 'colsample_bynode': 0.6342003554063634, 'reg_alpha': 0.03900103002863726}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,445] Trial 459 finished with value: 0.6969150245127728 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.895224457581744, 'colsample_bynode': 0.6355533693032275, 'reg_alpha': 0.04577744942272384}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,588] Trial 460 finished with value: 0.696910243087653 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.895612316099805, 'colsample_bynode': 0.6367563195915775, 'reg_alpha': 0.046615042731266675}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,617] Trial 461 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:25,646] Trial 462 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:25,674] Trial 463 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:25,816] Trial 464 finished with value: 0.6969213997462657 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8950101637999573, 'colsample_bynode': 0.6391239120832237, 'reg_alpha': 0.04819099734493717}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,956] Trial 465 finished with value: 0.696910243087653 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8952188205754826, 'colsample_bynode': 0.6392440095589116, 'reg_alpha': 0.04109978443948237}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:25,983] Trial 466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,010] Trial 467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,159] Trial 468 finished with value: 0.6969405254467445 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8947072195145523, 'colsample_bynode': 0.6398091062083596, 'reg_alpha': 0.042913565986225054}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:26,328] Trial 469 finished with value: 0.6969405254467445 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.894780079395763, 'colsample_bynode': 0.6387715178537839, 'reg_alpha': 0.0425983616338517}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:26,354] Trial 470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,381] Trial 471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,408] Trial 472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,546] Trial 473 finished with value: 0.6969006802374137 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8953716291522734, 'colsample_bynode': 0.6412022089563416, 'reg_alpha': 0.04325132587459033}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:26,574] Trial 474 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,601] Trial 475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,747] Trial 476 finished with value: 0.6970122468235399 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8947925389355657, 'colsample_bynode': 0.6465564681314449, 'reg_alpha': 0.03405672739109111}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:26,892] Trial 477 finished with value: 0.6969357440216248 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8949465293496272, 'colsample_bynode': 0.6467519122096111, 'reg_alpha': 0.03440100232286178}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:26,919] Trial 478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,945] Trial 479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:26,972] Trial 480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,001] Trial 481 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,028] Trial 482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,055] Trial 483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,082] Trial 484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,108] Trial 485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,138] Trial 486 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,165] Trial 487 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,193] Trial 488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,220] Trial 489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,248] Trial 490 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,275] Trial 491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,304] Trial 492 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,331] Trial 493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,364] Trial 494 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:27,392] Trial 495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,419] Trial 496 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,449] Trial 497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,477] Trial 498 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,509] Trial 499 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:27,536] Trial 500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,564] Trial 501 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,594] Trial 502 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,621] Trial 503 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,650] Trial 504 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,801] Trial 505 finished with value: 0.6914291360921093 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 10, 'subsample': 0.8888204148750736, 'colsample_bynode': 0.6544283561779529, 'reg_alpha': 0.025032723109220754}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:27,831] Trial 506 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:27,859] Trial 507 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,887] Trial 508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:27,916] Trial 509 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,070] Trial 510 finished with value: 0.6963428473067826 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 10, 'subsample': 0.8935808533840519, 'colsample_bynode': 0.6309121213956242, 'reg_alpha': 0.04545239131397908}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:28,100] Trial 511 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,128] Trial 512 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,157] Trial 513 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,187] Trial 514 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,215] Trial 515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,243] Trial 516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,271] Trial 517 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,303] Trial 518 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:28,332] Trial 519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,360] Trial 520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,389] Trial 521 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,417] Trial 522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,445] Trial 523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,475] Trial 524 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,635] Trial 525 finished with value: 0.6960145227818969 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.8928264777285243, 'colsample_bynode': 0.6405287389937347, 'reg_alpha': 0.028004399048613217}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:28,664] Trial 526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,695] Trial 527 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:28,724] Trial 528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,751] Trial 529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,778] Trial 530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:28,932] Trial 531 finished with value: 0.6954248136838012 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 6, 'subsample': 0.8935106783586905, 'colsample_bynode': 0.6541949598109368, 'reg_alpha': 0.03763684474823648}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:28,960] Trial 532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,103] Trial 533 finished with value: 0.6916443002224957 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 10, 'subsample': 0.891188530641215, 'colsample_bynode': 0.6771843421437409, 'reg_alpha': 0.052899146583944255}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:29,131] Trial 534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,161] Trial 535 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,312] Trial 536 finished with value: 0.695327591373034 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8933292825912933, 'colsample_bynode': 0.6515060524538243, 'reg_alpha': 0.03016270910612225}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:29,471] Trial 537 finished with value: 0.6954248136838012 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8935337208137419, 'colsample_bynode': 0.6593026626392062, 'reg_alpha': 0.02534247612391224}. Best is trial 432 with value: 0.6982952625639914.\n",
      "[I 2024-02-05 13:57:29,502] Trial 538 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:29,530] Trial 539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,560] Trial 540 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:29,589] Trial 541 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,617] Trial 542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,646] Trial 543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:29,785] Trial 544 finished with value: 0.7004994995441708 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8933703323758845, 'colsample_bynode': 0.6389055443252935, 'reg_alpha': 0.01639202665760776}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:29,935] Trial 545 finished with value: 0.696910243087653 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8953272392060763, 'colsample_bynode': 0.6407924647147222, 'reg_alpha': 0.02332966882795322}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:29,967] Trial 546 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:29,996] Trial 547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,028] Trial 548 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:30,056] Trial 549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,084] Trial 550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,113] Trial 551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,267] Trial 552 finished with value: 0.6968990864290404 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8951852864658849, 'colsample_bynode': 0.6360520972855768, 'reg_alpha': 0.01673483181414407}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:30,415] Trial 553 finished with value: 0.6969118368960263 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8951933799095069, 'colsample_bynode': 0.6342774715203758, 'reg_alpha': 0.021323521488157228}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:30,569] Trial 554 finished with value: 0.6968879297704278 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8954193584084489, 'colsample_bynode': 0.633018063061294, 'reg_alpha': 0.015380388020746847}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:30,709] Trial 555 finished with value: 0.6969341502132516 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8953561497811411, 'colsample_bynode': 0.6330919829032026, 'reg_alpha': 0.01524027027692033}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:30,868] Trial 556 finished with value: 0.696902274045787 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8950798012550131, 'colsample_bynode': 0.6337840115566239, 'reg_alpha': 0.015750748729588374}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:30,897] Trial 557 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,925] Trial 558 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,953] Trial 559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:30,980] Trial 560 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,012] Trial 561 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:31,044] Trial 562 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:31,072] Trial 563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,101] Trial 564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,249] Trial 565 finished with value: 0.6969054616625334 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.895196818231343, 'colsample_bynode': 0.6358993006238981, 'reg_alpha': 0.01977899282481649}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:31,277] Trial 566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,306] Trial 567 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,442] Trial 568 finished with value: 0.6968863359620546 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8949067310908962, 'colsample_bynode': 0.637890004438806, 'reg_alpha': 0.012344233589543431}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:31,475] Trial 569 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:31,505] Trial 570 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,650] Trial 571 finished with value: 0.696310971139318 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8960763776248131, 'colsample_bynode': 0.6380723562436327, 'reg_alpha': 0.012869319048015412}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:31,679] Trial 572 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,708] Trial 573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,739] Trial 574 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:31,889] Trial 575 finished with value: 0.6968193960103789 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.894566207808941, 'colsample_bynode': 0.6392830394304364, 'reg_alpha': 0.01134179100632021}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:31,918] Trial 576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,947] Trial 577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:31,977] Trial 578 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,009] Trial 579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,172] Trial 580 finished with value: 0.6968815545369349 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8948237485939414, 'colsample_bynode': 0.6428463815397689, 'reg_alpha': 0.01194565657122675}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:32,202] Trial 581 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,231] Trial 582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,260] Trial 583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,290] Trial 584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,318] Trial 585 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,348] Trial 586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,377] Trial 587 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,406] Trial 588 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,435] Trial 589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,466] Trial 590 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,496] Trial 591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,526] Trial 592 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,560] Trial 593 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:32,591] Trial 594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,620] Trial 595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,649] Trial 596 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,679] Trial 597 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:32,712] Trial 598 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:32,741] Trial 599 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,771] Trial 600 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,800] Trial 601 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,832] Trial 602 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:32,861] Trial 603 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,891] Trial 604 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:32,920] Trial 605 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,069] Trial 606 finished with value: 0.6968847421536813 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8949339785725731, 'colsample_bynode': 0.6443954987557525, 'reg_alpha': 0.00917841751330316}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:33,098] Trial 607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,128] Trial 608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,161] Trial 609 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:33,194] Trial 610 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:33,223] Trial 611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,253] Trial 612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,282] Trial 613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,316] Trial 614 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:33,347] Trial 615 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,377] Trial 616 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,524] Trial 617 finished with value: 0.6972082852534474 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8954864397997826, 'colsample_bynode': 0.654695926513952, 'reg_alpha': 0.024517146455451815}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:33,554] Trial 618 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,705] Trial 619 finished with value: 0.6963555977737684 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8934533764735608, 'colsample_bynode': 0.62074446545627, 'reg_alpha': 0.03224967359551418}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:33,735] Trial 620 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:33,765] Trial 621 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,796] Trial 622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,828] Trial 623 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,858] Trial 624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,918] Trial 625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:33,956] Trial 626 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:33,992] Trial 627 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:34,028] Trial 628 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:34,059] Trial 629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,089] Trial 630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,119] Trial 631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,151] Trial 632 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:34,181] Trial 633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,211] Trial 634 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,356] Trial 635 finished with value: 0.6969357440216248 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.8950589222896125, 'colsample_bynode': 0.6422657306392906, 'reg_alpha': 0.03532313092790373}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:34,386] Trial 636 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,416] Trial 637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,445] Trial 638 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,481] Trial 639 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:34,512] Trial 640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,543] Trial 641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,573] Trial 642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,604] Trial 643 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,634] Trial 644 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,786] Trial 645 finished with value: 0.696875179303442 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 8, 'subsample': 0.894462682861589, 'colsample_bynode': 0.640011508982643, 'reg_alpha': 0.038656030933716674}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:34,818] Trial 646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,850] Trial 647 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:34,880] Trial 648 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,913] Trial 649 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:34,943] Trial 650 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:34,975] Trial 651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,005] Trial 652 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,035] Trial 653 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,066] Trial 654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,097] Trial 655 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,131] Trial 656 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,162] Trial 657 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,197] Trial 658 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,228] Trial 659 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,261] Trial 660 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,292] Trial 661 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,326] Trial 662 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,360] Trial 663 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,394] Trial 664 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,427] Trial 665 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,458] Trial 666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,490] Trial 667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,521] Trial 668 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,552] Trial 669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,584] Trial 670 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,615] Trial 671 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,646] Trial 672 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,677] Trial 673 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,712] Trial 674 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,743] Trial 675 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,774] Trial 676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,805] Trial 677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,838] Trial 678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:35,873] Trial 679 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,907] Trial 680 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:35,939] Trial 681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,089] Trial 682 finished with value: 0.6969150245127728 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 10, 'max_delta_step': 9, 'subsample': 0.8945362850939654, 'colsample_bynode': 0.6408740223443761, 'reg_alpha': 0.051421986877002564}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:36,124] Trial 683 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:36,155] Trial 684 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,186] Trial 685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,217] Trial 686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,247] Trial 687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,278] Trial 688 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,314] Trial 689 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:36,345] Trial 690 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,376] Trial 691 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,422] Trial 692 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:36,459] Trial 693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,493] Trial 694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,527] Trial 695 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,565] Trial 696 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:36,599] Trial 697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,630] Trial 698 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,664] Trial 699 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,697] Trial 700 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,731] Trial 701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,763] Trial 702 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,796] Trial 703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,829] Trial 704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,864] Trial 705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,901] Trial 706 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:36,934] Trial 707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:36,967] Trial 708 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,000] Trial 709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,034] Trial 710 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,069] Trial 711 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,103] Trial 712 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,136] Trial 713 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,168] Trial 714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,200] Trial 715 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,233] Trial 716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,267] Trial 717 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,303] Trial 718 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,336] Trial 719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,373] Trial 720 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:37,406] Trial 721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,439] Trial 722 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,473] Trial 723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,506] Trial 724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,543] Trial 725 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,576] Trial 726 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,611] Trial 727 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,653] Trial 728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,686] Trial 729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,720] Trial 730 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,756] Trial 731 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,797] Trial 732 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,834] Trial 733 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,869] Trial 734 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,903] Trial 735 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:37,940] Trial 736 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:37,975] Trial 737 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,009] Trial 738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,043] Trial 739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,218] Trial 740 finished with value: 0.6967317365498511 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 8, 'subsample': 0.8943468216642781, 'colsample_bynode': 0.6463274880290868, 'reg_alpha': 0.025428357005324684}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:38,252] Trial 741 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,287] Trial 742 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:38,320] Trial 743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,353] Trial 744 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,387] Trial 745 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,421] Trial 746 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:38,453] Trial 747 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,487] Trial 748 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,519] Trial 749 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,554] Trial 750 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:38,586] Trial 751 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,619] Trial 752 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,656] Trial 753 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:38,689] Trial 754 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,722] Trial 755 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,757] Trial 756 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:38,789] Trial 757 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,822] Trial 758 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,854] Trial 759 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,887] Trial 760 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,921] Trial 761 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,954] Trial 762 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:38,988] Trial 763 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,021] Trial 764 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,054] Trial 765 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,091] Trial 766 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:39,127] Trial 767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,160] Trial 768 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,194] Trial 769 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,246] Trial 770 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:39,329] Trial 771 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,364] Trial 772 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,398] Trial 773 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,433] Trial 774 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:39,466] Trial 775 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,501] Trial 776 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,535] Trial 777 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,569] Trial 778 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:39,602] Trial 779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,764] Trial 780 finished with value: 0.6967205798912385 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8932116197069035, 'colsample_bynode': 0.6433132202696665, 'reg_alpha': 0.01996706366548918}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:39,798] Trial 781 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,835] Trial 782 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:39,868] Trial 783 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,901] Trial 784 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:39,935] Trial 785 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,084] Trial 786 finished with value: 0.6967731755675551 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8947952816771485, 'colsample_bynode': 0.6349738440647621, 'reg_alpha': 0.018137010108805786}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:40,120] Trial 787 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:40,153] Trial 788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,186] Trial 789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,221] Trial 790 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,255] Trial 791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,289] Trial 792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,326] Trial 793 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:40,360] Trial 794 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,396] Trial 795 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,430] Trial 796 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,467] Trial 797 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:40,502] Trial 798 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,536] Trial 799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,688] Trial 800 finished with value: 0.6971206257929197 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8948436102316576, 'colsample_bynode': 0.6655228200922911, 'reg_alpha': 0.01730766854764439}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:40,723] Trial 801 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,759] Trial 802 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,794] Trial 803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,828] Trial 804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:40,986] Trial 805 finished with value: 0.6972130666785671 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.895656474785403, 'colsample_bynode': 0.662174198667318, 'reg_alpha': 0.03841833572553035}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:41,025] Trial 806 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:41,062] Trial 807 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:41,097] Trial 808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,132] Trial 809 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,165] Trial 810 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,200] Trial 811 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,234] Trial 812 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,269] Trial 813 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:41,303] Trial 814 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,337] Trial 815 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,371] Trial 816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,409] Trial 817 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:41,444] Trial 818 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,479] Trial 819 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,645] Trial 820 finished with value: 0.6971206257929197 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8948212184335363, 'colsample_bynode': 0.6605849935623735, 'reg_alpha': 0.015319330637985148}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:41,680] Trial 821 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,714] Trial 822 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,748] Trial 823 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,898] Trial 824 finished with value: 0.6970696239249763 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8944184043553585, 'colsample_bynode': 0.6651024567045315, 'reg_alpha': 0.051814672609757084}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:41,933] Trial 825 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:41,968] Trial 826 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,005] Trial 827 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,041] Trial 828 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,078] Trial 829 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,113] Trial 830 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,150] Trial 831 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,185] Trial 832 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,223] Trial 833 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,260] Trial 834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,296] Trial 835 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,330] Trial 836 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,367] Trial 837 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,401] Trial 838 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,436] Trial 839 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,593] Trial 840 finished with value: 0.6970648424998566 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8944704048472105, 'colsample_bynode': 0.6539899025831659, 'reg_alpha': 0.05365220988713849}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:42,631] Trial 841 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,666] Trial 842 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,700] Trial 843 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,737] Trial 844 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:42,772] Trial 845 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:42,937] Trial 846 finished with value: 0.6971461267268914 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8947040783965781, 'colsample_bynode': 0.6549357710497973, 'reg_alpha': 0.06914592810068962}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:42,973] Trial 847 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,010] Trial 848 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,046] Trial 849 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,082] Trial 850 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,244] Trial 851 finished with value: 0.6970712177333495 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.8944054185365004, 'colsample_bynode': 0.665819397990725, 'reg_alpha': 0.06544910784605897}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:43,281] Trial 852 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,316] Trial 853 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,353] Trial 854 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,391] Trial 855 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,429] Trial 856 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,465] Trial 857 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,503] Trial 858 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,540] Trial 859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,578] Trial 860 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,615] Trial 861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,652] Trial 862 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:43,689] Trial 863 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,725] Trial 864 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:43,878] Trial 865 finished with value: 0.6971859719362221 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8949176336834151, 'colsample_bynode': 0.652158800406805, 'reg_alpha': 0.05367968820495087}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:43,915] Trial 866 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,076] Trial 867 finished with value: 0.6970999062840677 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8940936206106084, 'colsample_bynode': 0.6529245567438884, 'reg_alpha': 0.06209746017722476}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:44,112] Trial 868 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,149] Trial 869 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,186] Trial 870 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:44,227] Trial 871 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:44,263] Trial 872 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,300] Trial 873 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,337] Trial 874 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,376] Trial 875 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:44,414] Trial 876 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,588] Trial 877 finished with value: 0.6968943050039208 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.893202794539373, 'colsample_bynode': 0.6534745836189736, 'reg_alpha': 0.050660848579939924}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:44,629] Trial 878 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:44,665] Trial 879 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,702] Trial 880 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,896] Trial 881 finished with value: 0.6972146604869404 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8951169652722901, 'colsample_bynode': 0.6515317210131254, 'reg_alpha': 0.0719319085814502}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:44,932] Trial 882 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:44,970] Trial 883 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,007] Trial 884 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,046] Trial 885 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,082] Trial 886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,119] Trial 887 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,157] Trial 888 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,194] Trial 889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,231] Trial 890 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,395] Trial 891 finished with value: 0.6968098331601394 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8946888513507094, 'colsample_bynode': 0.6485134364551968, 'reg_alpha': 0.0587424432094119}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:45,432] Trial 892 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,468] Trial 893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,508] Trial 894 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,545] Trial 895 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,582] Trial 896 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,618] Trial 897 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,656] Trial 898 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,697] Trial 899 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,734] Trial 900 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,775] Trial 901 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,813] Trial 902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,849] Trial 903 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,886] Trial 904 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:45,927] Trial 905 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:45,964] Trial 906 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,001] Trial 907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,039] Trial 908 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,076] Trial 909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,115] Trial 910 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,152] Trial 911 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,191] Trial 912 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,231] Trial 913 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:46,269] Trial 914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,307] Trial 915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,347] Trial 916 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:46,384] Trial 917 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,422] Trial 918 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,463] Trial 919 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:46,502] Trial 920 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,539] Trial 921 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,577] Trial 922 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,615] Trial 923 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,652] Trial 924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,690] Trial 925 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,855] Trial 926 finished with value: 0.6966727656400415 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 9, 'subsample': 0.894260315029376, 'colsample_bynode': 0.64335226814462, 'reg_alpha': 0.06169366764233093}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:46,896] Trial 927 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:46,933] Trial 928 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:46,971] Trial 929 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,009] Trial 930 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,047] Trial 931 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,085] Trial 932 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,256] Trial 933 finished with value: 0.697130188643159 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8948293206846302, 'colsample_bynode': 0.6575553918358437, 'reg_alpha': 0.03496185821937619}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:47,295] Trial 934 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,334] Trial 935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,501] Trial 936 finished with value: 0.6970010901649273 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8944541128394957, 'colsample_bynode': 0.6624475395683607, 'reg_alpha': 0.036072225277849965}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:47,539] Trial 937 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,580] Trial 938 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:47,618] Trial 939 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,656] Trial 940 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,695] Trial 941 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,735] Trial 942 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:47,775] Trial 943 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:47,814] Trial 944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,854] Trial 945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,893] Trial 946 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:47,933] Trial 947 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:47,972] Trial 948 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,009] Trial 949 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,048] Trial 950 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,212] Trial 951 finished with value: 0.6970983124756944 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8940625283623166, 'colsample_bynode': 0.6655264635221443, 'reg_alpha': 0.04938800417804742}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:48,251] Trial 952 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,292] Trial 953 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:48,332] Trial 954 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:48,371] Trial 955 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,412] Trial 956 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,450] Trial 957 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,489] Trial 958 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,530] Trial 959 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:48,570] Trial 960 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:48,608] Trial 961 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,649] Trial 962 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,688] Trial 963 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,727] Trial 964 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,765] Trial 965 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,804] Trial 966 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,842] Trial 967 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,881] Trial 968 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:48,922] Trial 969 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:48,961] Trial 970 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,000] Trial 971 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,179] Trial 972 finished with value: 0.6971461267268914 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8945915630306988, 'colsample_bynode': 0.6561926336149082, 'reg_alpha': 0.06836006925359998}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:49,219] Trial 973 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,258] Trial 974 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,297] Trial 975 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,339] Trial 976 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:49,379] Trial 977 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,420] Trial 978 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,460] Trial 979 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,500] Trial 980 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,540] Trial 981 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,579] Trial 982 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,620] Trial 983 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,660] Trial 984 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,699] Trial 985 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,739] Trial 986 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,779] Trial 987 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:49,818] Trial 988 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:49,984] Trial 989 finished with value: 0.6971939409780883 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8953052336411498, 'colsample_bynode': 0.6523856497327722, 'reg_alpha': 0.046463073438168294}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:50,026] Trial 990 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,065] Trial 991 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,105] Trial 992 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,145] Trial 993 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,184] Trial 994 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,226] Trial 995 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:50,266] Trial 996 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,304] Trial 997 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,345] Trial 998 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,387] Trial 999 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:50,426] Trial 1000 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,465] Trial 1001 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,508] Trial 1002 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:50,549] Trial 1003 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,723] Trial 1004 finished with value: 0.6968018641182734 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8948397057018804, 'colsample_bynode': 0.648686961891341, 'reg_alpha': 0.07470010244787963}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:50,763] Trial 1005 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,804] Trial 1006 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,844] Trial 1007 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,883] Trial 1008 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,923] Trial 1009 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:50,967] Trial 1010 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:51,008] Trial 1011 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,048] Trial 1012 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,087] Trial 1013 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,127] Trial 1014 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,167] Trial 1015 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,212] Trial 1016 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:51,253] Trial 1017 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,294] Trial 1018 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,334] Trial 1019 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,378] Trial 1020 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:51,419] Trial 1021 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,460] Trial 1022 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,500] Trial 1023 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,542] Trial 1024 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,582] Trial 1025 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,624] Trial 1026 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,665] Trial 1027 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,708] Trial 1028 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:51,748] Trial 1029 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,789] Trial 1030 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:51,951] Trial 1031 finished with value: 0.699111292451086 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8936826435328519, 'colsample_bynode': 0.6432920152123802, 'reg_alpha': 0.07249063140547479}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:51,993] Trial 1032 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,033] Trial 1033 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,075] Trial 1034 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:52,116] Trial 1035 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,157] Trial 1036 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,198] Trial 1037 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,381] Trial 1038 finished with value: 0.6992451723544375 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.893458174730279, 'colsample_bynode': 0.6444825899108995, 'reg_alpha': 0.0872441318304883}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:52,423] Trial 1039 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,469] Trial 1040 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:52,635] Trial 1041 finished with value: 0.696806645543393 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8950557227787289, 'colsample_bynode': 0.6458496941835745, 'reg_alpha': 0.10716599194339867}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:52,675] Trial 1042 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,715] Trial 1043 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,760] Trial 1044 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:52,802] Trial 1045 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,842] Trial 1046 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,883] Trial 1047 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,924] Trial 1048 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:52,964] Trial 1049 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,006] Trial 1050 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,047] Trial 1051 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,088] Trial 1052 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,129] Trial 1053 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,171] Trial 1054 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:53,212] Trial 1055 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,254] Trial 1056 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,295] Trial 1057 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:53,338] Trial 1058 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,380] Trial 1059 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,544] Trial 1060 finished with value: 0.6967779569926749 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.894718191952385, 'colsample_bynode': 0.640649552928627, 'reg_alpha': 0.08969034013071475}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:53,589] Trial 1061 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:53,631] Trial 1062 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,672] Trial 1063 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,715] Trial 1064 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:53,884] Trial 1065 finished with value: 0.69721944191206 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8950729191323491, 'colsample_bynode': 0.6544051348192506, 'reg_alpha': 0.059210926794456845}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:53,931] Trial 1066 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:54,085] Trial 1067 finished with value: 0.697171627660863 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8954598374057248, 'colsample_bynode': 0.6531144163101443, 'reg_alpha': 0.10578182134232289}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:54,127] Trial 1068 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,276] Trial 1069 finished with value: 0.6970903434338283 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8948379529534595, 'colsample_bynode': 0.6534455051890928, 'reg_alpha': 0.15819143387002277}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:54,321] Trial 1070 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,363] Trial 1071 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,405] Trial 1072 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,450] Trial 1073 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:54,615] Trial 1074 finished with value: 0.6970520920328707 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8951585455605378, 'colsample_bynode': 0.6418071553657289, 'reg_alpha': 0.18235584606328398}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:54,659] Trial 1075 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,701] Trial 1076 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,745] Trial 1077 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:54,788] Trial 1078 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,831] Trial 1079 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,874] Trial 1080 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,916] Trial 1081 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:54,962] Trial 1082 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:55,027] Trial 1083 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,073] Trial 1084 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,115] Trial 1085 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,158] Trial 1086 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,199] Trial 1087 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,242] Trial 1088 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,286] Trial 1089 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:55,332] Trial 1090 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:55,374] Trial 1091 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,417] Trial 1092 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,460] Trial 1093 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,503] Trial 1094 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,547] Trial 1095 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,588] Trial 1096 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,634] Trial 1097 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:55,676] Trial 1098 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,718] Trial 1099 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,760] Trial 1100 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,804] Trial 1101 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,846] Trial 1102 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,890] Trial 1103 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:55,932] Trial 1104 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,107] Trial 1105 finished with value: 0.6971126567510535 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8946352995293999, 'colsample_bynode': 0.6623524403774054, 'reg_alpha': 0.09039463748611155}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:56,278] Trial 1106 finished with value: 0.6968209898187521 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8949712799420959, 'colsample_bynode': 0.6431028354271936, 'reg_alpha': 0.10250298804338609}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:56,322] Trial 1107 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,365] Trial 1108 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,408] Trial 1109 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,451] Trial 1110 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,494] Trial 1111 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,537] Trial 1112 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,581] Trial 1113 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,623] Trial 1114 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,666] Trial 1115 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,711] Trial 1116 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,754] Trial 1117 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,797] Trial 1118 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,841] Trial 1119 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,885] Trial 1120 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,927] Trial 1121 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:56,973] Trial 1122 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:57,016] Trial 1123 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,059] Trial 1124 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,103] Trial 1125 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,149] Trial 1126 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:57,193] Trial 1127 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,240] Trial 1128 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:57,284] Trial 1129 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,328] Trial 1130 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,501] Trial 1131 finished with value: 0.6968209898187521 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.895110340915574, 'colsample_bynode': 0.6479143728735789, 'reg_alpha': 0.07155162300969022}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:57,546] Trial 1132 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,591] Trial 1133 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,634] Trial 1134 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,678] Trial 1135 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,721] Trial 1136 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,767] Trial 1137 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:57,812] Trial 1138 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,859] Trial 1139 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:57,902] Trial 1140 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:57,945] Trial 1141 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,117] Trial 1142 finished with value: 0.6971795967027292 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8948922352888516, 'colsample_bynode': 0.6509327087183465, 'reg_alpha': 0.015400110360079794}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:58,160] Trial 1143 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,204] Trial 1144 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,252] Trial 1145 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:58,300] Trial 1146 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:58,344] Trial 1147 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,389] Trial 1148 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,434] Trial 1149 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:58,480] Trial 1150 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,524] Trial 1151 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,568] Trial 1152 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,615] Trial 1153 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:58,660] Trial 1154 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,824] Trial 1155 finished with value: 0.6991893890613744 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8937509889638269, 'colsample_bynode': 0.6434267168578456, 'reg_alpha': 0.020534654217394532}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:58,868] Trial 1156 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,912] Trial 1157 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,955] Trial 1158 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:58,998] Trial 1159 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,042] Trial 1160 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,088] Trial 1161 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:59,132] Trial 1162 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,177] Trial 1163 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,221] Trial 1164 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,268] Trial 1165 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:59,313] Trial 1166 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,357] Trial 1167 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,402] Trial 1168 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,450] Trial 1169 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:57:59,496] Trial 1170 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:57:59,677] Trial 1171 finished with value: 0.6972035038283277 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8949067562442152, 'colsample_bynode': 0.6652123716658658, 'reg_alpha': 0.010461269820262003}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:57:59,721] Trial 1172 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,766] Trial 1173 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,809] Trial 1174 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,854] Trial 1175 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,899] Trial 1176 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:57:59,957] Trial 1177 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,003] Trial 1178 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,050] Trial 1179 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:00,095] Trial 1180 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,139] Trial 1181 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,185] Trial 1182 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,230] Trial 1183 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,275] Trial 1184 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,323] Trial 1185 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:00,367] Trial 1186 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,412] Trial 1187 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,464] Trial 1188 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:00,509] Trial 1189 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,554] Trial 1190 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,599] Trial 1191 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,644] Trial 1192 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,688] Trial 1193 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,735] Trial 1194 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:00,780] Trial 1195 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,826] Trial 1196 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,873] Trial 1197 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,921] Trial 1198 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:00,966] Trial 1199 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,010] Trial 1200 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,055] Trial 1201 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,102] Trial 1202 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,147] Trial 1203 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,193] Trial 1204 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,237] Trial 1205 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,282] Trial 1206 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,327] Trial 1207 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,372] Trial 1208 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,417] Trial 1209 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,465] Trial 1210 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:01,514] Trial 1211 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:01,561] Trial 1212 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,606] Trial 1213 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,651] Trial 1214 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,700] Trial 1215 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,882] Trial 1216 finished with value: 0.6967779569926749 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 2, 'subsample': 0.8950684932806419, 'colsample_bynode': 0.6368461718909428, 'reg_alpha': 0.00292331791059406}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:01,928] Trial 1217 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:01,976] Trial 1218 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,021] Trial 1219 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,065] Trial 1220 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,112] Trial 1221 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,158] Trial 1222 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,205] Trial 1223 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:02,250] Trial 1224 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,296] Trial 1225 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,341] Trial 1226 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,389] Trial 1227 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:02,434] Trial 1228 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,479] Trial 1229 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,526] Trial 1230 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,572] Trial 1231 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,618] Trial 1232 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,665] Trial 1233 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,712] Trial 1234 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,762] Trial 1235 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:02,931] Trial 1236 finished with value: 0.6972050976367009 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8950296520355613, 'colsample_bynode': 0.6519652518088717, 'reg_alpha': 0.07236053658231453}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:02,978] Trial 1237 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,024] Trial 1238 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,074] Trial 1239 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:03,120] Trial 1240 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,166] Trial 1241 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,211] Trial 1242 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,259] Trial 1243 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,306] Trial 1244 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,353] Trial 1245 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:03,399] Trial 1246 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,446] Trial 1247 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,495] Trial 1248 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:03,543] Trial 1249 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,591] Trial 1250 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,638] Trial 1251 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,685] Trial 1252 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,733] Trial 1253 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,782] Trial 1254 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:03,958] Trial 1255 finished with value: 0.6971142505594268 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8946648034539425, 'colsample_bynode': 0.650376944161112, 'reg_alpha': 0.027485665205388123}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:04,005] Trial 1256 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,051] Trial 1257 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,101] Trial 1258 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:04,148] Trial 1259 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,198] Trial 1260 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:04,246] Trial 1261 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,293] Trial 1262 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,341] Trial 1263 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,389] Trial 1264 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:04,436] Trial 1265 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,483] Trial 1266 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,529] Trial 1267 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,575] Trial 1268 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,621] Trial 1269 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,667] Trial 1270 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,717] Trial 1271 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,767] Trial 1272 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,813] Trial 1273 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,860] Trial 1274 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,908] Trial 1275 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:04,954] Trial 1276 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,001] Trial 1277 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,049] Trial 1278 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,095] Trial 1279 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,150] Trial 1280 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:05,198] Trial 1281 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,246] Trial 1282 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,295] Trial 1283 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,343] Trial 1284 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,392] Trial 1285 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,441] Trial 1286 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,487] Trial 1287 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,534] Trial 1288 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,582] Trial 1289 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,633] Trial 1290 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,688] Trial 1291 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:05,738] Trial 1292 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:05,787] Trial 1293 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,836] Trial 1294 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,885] Trial 1295 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:05,934] Trial 1296 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:05,983] Trial 1297 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,032] Trial 1298 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,237] Trial 1299 finished with value: 0.6968464907527239 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8946127305030885, 'colsample_bynode': 0.6325490653097162, 'reg_alpha': 0.03335176203371258}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:06,443] Trial 1300 finished with value: 0.6968257712438718 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 2, 'subsample': 0.895011459678503, 'colsample_bynode': 0.6481368648762511, 'reg_alpha': 0.02256123890944188}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:06,492] Trial 1301 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,541] Trial 1302 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,608] Trial 1303 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,665] Trial 1304 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,713] Trial 1305 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,763] Trial 1306 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,814] Trial 1307 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:06,867] Trial 1308 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:06,915] Trial 1309 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:06,966] Trial 1310 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,019] Trial 1311 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,070] Trial 1312 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:07,121] Trial 1313 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,170] Trial 1314 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,218] Trial 1315 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,266] Trial 1316 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,315] Trial 1317 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,367] Trial 1318 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:07,416] Trial 1319 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,467] Trial 1320 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:07,516] Trial 1321 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,742] Trial 1322 finished with value: 0.6972146604869404 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.89328628720266, 'colsample_bynode': 0.628241456628412, 'reg_alpha': 0.014493689014771067}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:07,791] Trial 1323 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,838] Trial 1324 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,886] Trial 1325 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,934] Trial 1326 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:07,984] Trial 1327 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:08,035] Trial 1328 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,087] Trial 1329 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,142] Trial 1330 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,191] Trial 1331 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,241] Trial 1332 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,288] Trial 1333 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,336] Trial 1334 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,384] Trial 1335 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,438] Trial 1336 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:08,487] Trial 1337 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,536] Trial 1338 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,586] Trial 1339 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,635] Trial 1340 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,683] Trial 1341 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,732] Trial 1342 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,783] Trial 1343 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,835] Trial 1344 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,884] Trial 1345 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:08,935] Trial 1346 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:08,985] Trial 1347 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,036] Trial 1348 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,085] Trial 1349 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,134] Trial 1350 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,184] Trial 1351 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:09,233] Trial 1352 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,283] Trial 1353 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:09,332] Trial 1354 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,382] Trial 1355 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,430] Trial 1356 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,480] Trial 1357 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,530] Trial 1358 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:09,579] Trial 1359 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,628] Trial 1360 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,678] Trial 1361 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,729] Trial 1362 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,781] Trial 1363 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:09,834] Trial 1364 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:09,884] Trial 1365 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:09,942] Trial 1366 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:09,991] Trial 1367 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,041] Trial 1368 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,092] Trial 1369 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,144] Trial 1370 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:10,195] Trial 1371 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,245] Trial 1372 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,295] Trial 1373 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,344] Trial 1374 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,397] Trial 1375 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:10,447] Trial 1376 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,496] Trial 1377 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,544] Trial 1378 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,594] Trial 1379 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,644] Trial 1380 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,695] Trial 1381 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,744] Trial 1382 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,795] Trial 1383 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,848] Trial 1384 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:10,904] Trial 1385 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:10,955] Trial 1386 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,131] Trial 1387 finished with value: 0.6971381576850252 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8949979579465663, 'colsample_bynode': 0.6527373395304558, 'reg_alpha': 0.03553169751486962}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:11,182] Trial 1388 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,234] Trial 1389 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:11,285] Trial 1390 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,337] Trial 1391 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:11,386] Trial 1392 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,436] Trial 1393 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,485] Trial 1394 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,535] Trial 1395 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,586] Trial 1396 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,637] Trial 1397 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:11,687] Trial 1398 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,737] Trial 1399 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,791] Trial 1400 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:11,841] Trial 1401 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,895] Trial 1402 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:11,947] Trial 1403 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:11,998] Trial 1404 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:12,050] Trial 1405 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,104] Trial 1406 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,155] Trial 1407 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,336] Trial 1408 finished with value: 0.6971493143436378 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8947374385208772, 'colsample_bynode': 0.6591658071829718, 'reg_alpha': 0.06386273143669587}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:12,386] Trial 1409 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,561] Trial 1410 finished with value: 0.6972050976367009 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8949642108142225, 'colsample_bynode': 0.6517862639319049, 'reg_alpha': 0.07206057316350695}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:12,613] Trial 1411 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,666] Trial 1412 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:12,718] Trial 1413 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,768] Trial 1414 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,823] Trial 1415 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:12,874] Trial 1416 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,926] Trial 1417 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:12,978] Trial 1418 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,031] Trial 1419 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:13,081] Trial 1420 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,132] Trial 1421 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,184] Trial 1422 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,240] Trial 1423 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:13,293] Trial 1424 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,345] Trial 1425 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,521] Trial 1426 finished with value: 0.6971126567510535 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8944219793375426, 'colsample_bynode': 0.6624233055521828, 'reg_alpha': 0.10174955026615151}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:13,572] Trial 1427 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,625] Trial 1428 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:13,677] Trial 1429 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,727] Trial 1430 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,782] Trial 1431 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:13,832] Trial 1432 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,884] Trial 1433 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,936] Trial 1434 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:13,986] Trial 1435 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,038] Trial 1436 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,089] Trial 1437 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,143] Trial 1438 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,194] Trial 1439 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,245] Trial 1440 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,298] Trial 1441 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,352] Trial 1442 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,407] Trial 1443 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:14,458] Trial 1444 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,511] Trial 1445 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:14,563] Trial 1446 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,616] Trial 1447 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,669] Trial 1448 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,719] Trial 1449 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,769] Trial 1450 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,820] Trial 1451 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:14,872] Trial 1452 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,044] Trial 1453 finished with value: 0.6971238134096661 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8947409260151495, 'colsample_bynode': 0.649803624943424, 'reg_alpha': 0.12179940356069119}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:15,095] Trial 1454 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,147] Trial 1455 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,199] Trial 1456 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,254] Trial 1457 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:15,305] Trial 1458 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,358] Trial 1459 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,411] Trial 1460 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,583] Trial 1461 finished with value: 0.697109469134307 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8942311145184485, 'colsample_bynode': 0.6629310468202538, 'reg_alpha': 0.0925709773287912}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:15,635] Trial 1462 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,687] Trial 1463 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,740] Trial 1464 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,792] Trial 1465 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,844] Trial 1466 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,898] Trial 1467 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:15,950] Trial 1468 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,122] Trial 1469 finished with value: 0.697109469134307 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8948325293810647, 'colsample_bynode': 0.6557730928914344, 'reg_alpha': 0.04041129048622355}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:16,174] Trial 1470 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,226] Trial 1471 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,278] Trial 1472 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,330] Trial 1473 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,387] Trial 1474 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:16,440] Trial 1475 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,494] Trial 1476 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,546] Trial 1477 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,598] Trial 1478 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,652] Trial 1479 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,707] Trial 1480 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,764] Trial 1481 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:16,817] Trial 1482 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,870] Trial 1483 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,922] Trial 1484 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:16,976] Trial 1485 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,031] Trial 1486 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:17,086] Trial 1487 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:17,138] Trial 1488 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,191] Trial 1489 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,245] Trial 1490 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,298] Trial 1491 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,354] Trial 1492 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:17,406] Trial 1493 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,459] Trial 1494 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,512] Trial 1495 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,565] Trial 1496 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:17,621] Trial 1497 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,699] Trial 1498 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,756] Trial 1499 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,810] Trial 1500 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,863] Trial 1501 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,916] Trial 1502 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:17,968] Trial 1503 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,020] Trial 1504 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,074] Trial 1505 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,128] Trial 1506 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,180] Trial 1507 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,234] Trial 1508 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,287] Trial 1509 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,339] Trial 1510 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,394] Trial 1511 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,447] Trial 1512 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,502] Trial 1513 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:18,558] Trial 1514 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:18,612] Trial 1515 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,668] Trial 1516 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,857] Trial 1517 finished with value: 0.6971254072180394 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8945817636345003, 'colsample_bynode': 0.6534888163051551, 'reg_alpha': 0.030418142298613282}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:18,911] Trial 1518 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:18,964] Trial 1519 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,018] Trial 1520 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,073] Trial 1521 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,128] Trial 1522 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,181] Trial 1523 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,237] Trial 1524 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:19,292] Trial 1525 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,346] Trial 1526 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,400] Trial 1527 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,455] Trial 1528 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,509] Trial 1529 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,562] Trial 1530 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,616] Trial 1531 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,672] Trial 1532 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,725] Trial 1533 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,778] Trial 1534 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,833] Trial 1535 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:19,889] Trial 1536 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:19,946] Trial 1537 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,000] Trial 1538 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,054] Trial 1539 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,110] Trial 1540 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:20,170] Trial 1541 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:20,227] Trial 1542 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,282] Trial 1543 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,336] Trial 1544 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,391] Trial 1545 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,449] Trial 1546 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:20,503] Trial 1547 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,680] Trial 1548 finished with value: 0.6971684400441166 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8950531903561114, 'colsample_bynode': 0.6511837514529825, 'reg_alpha': 0.03085251874310807}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:20,735] Trial 1549 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,789] Trial 1550 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,845] Trial 1551 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,900] Trial 1552 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:20,955] Trial 1553 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,011] Trial 1554 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,067] Trial 1555 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,127] Trial 1556 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,184] Trial 1557 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:21,239] Trial 1558 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,294] Trial 1559 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,349] Trial 1560 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,407] Trial 1561 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:21,464] Trial 1562 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:21,521] Trial 1563 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,576] Trial 1564 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,631] Trial 1565 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,685] Trial 1566 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,738] Trial 1567 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,795] Trial 1568 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:21,852] Trial 1569 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:21,909] Trial 1570 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:21,965] Trial 1571 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:22,021] Trial 1572 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,075] Trial 1573 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,131] Trial 1574 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,191] Trial 1575 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,246] Trial 1576 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,302] Trial 1577 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,360] Trial 1578 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:22,416] Trial 1579 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,471] Trial 1580 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,528] Trial 1581 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:22,582] Trial 1582 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,638] Trial 1583 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,695] Trial 1584 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,753] Trial 1585 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:22,810] Trial 1586 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:22,992] Trial 1587 finished with value: 0.6971030939008142 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 7, 'subsample': 0.8947468370176256, 'colsample_bynode': 0.6607345274823351, 'reg_alpha': 0.03724568432028401}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:23,050] Trial 1588 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:23,105] Trial 1589 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,163] Trial 1590 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:23,222] Trial 1591 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,284] Trial 1592 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:23,340] Trial 1593 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,395] Trial 1594 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,450] Trial 1595 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,506] Trial 1596 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,564] Trial 1597 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,621] Trial 1598 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,682] Trial 1599 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:23,738] Trial 1600 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,796] Trial 1601 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,855] Trial 1602 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:23,917] Trial 1603 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:23,979] Trial 1604 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,038] Trial 1605 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:24,099] Trial 1606 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:24,155] Trial 1607 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,211] Trial 1608 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,268] Trial 1609 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,326] Trial 1610 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,387] Trial 1611 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,444] Trial 1612 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,500] Trial 1613 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,557] Trial 1614 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,615] Trial 1615 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:24,674] Trial 1616 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:24,730] Trial 1617 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,786] Trial 1618 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,842] Trial 1619 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:24,898] Trial 1620 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,118] Trial 1621 finished with value: 0.6969309625965051 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 8, 'subsample': 0.894389747362532, 'colsample_bynode': 0.6651871225857723, 'reg_alpha': 0.002460932974989214}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:25,176] Trial 1622 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,234] Trial 1623 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:25,292] Trial 1624 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,348] Trial 1625 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,403] Trial 1626 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,461] Trial 1627 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,519] Trial 1628 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,575] Trial 1629 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,631] Trial 1630 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,690] Trial 1631 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,749] Trial 1632 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:25,806] Trial 1633 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,866] Trial 1634 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:25,923] Trial 1635 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:25,978] Trial 1636 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,036] Trial 1637 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,095] Trial 1638 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:26,152] Trial 1639 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,210] Trial 1640 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,267] Trial 1641 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,324] Trial 1642 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,384] Trial 1643 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:26,446] Trial 1644 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:26,503] Trial 1645 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,561] Trial 1646 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,619] Trial 1647 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,677] Trial 1648 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,737] Trial 1649 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,796] Trial 1650 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,854] Trial 1651 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,911] Trial 1652 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:26,970] Trial 1653 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:27,028] Trial 1654 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,085] Trial 1655 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,151] Trial 1656 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:27,208] Trial 1657 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,266] Trial 1658 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,444] Trial 1659 finished with value: 0.6968385217108577 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8946546969979537, 'colsample_bynode': 0.6329114883129542, 'reg_alpha': 0.022489386564010456}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:27,501] Trial 1660 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,562] Trial 1661 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:27,619] Trial 1662 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,679] Trial 1663 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,736] Trial 1664 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,797] Trial 1665 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:27,856] Trial 1666 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,917] Trial 1667 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:27,974] Trial 1668 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,035] Trial 1669 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,092] Trial 1670 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,289] Trial 1671 finished with value: 0.6971668462357434 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 4, 'subsample': 0.894913901900825, 'colsample_bynode': 0.6595244679836945, 'reg_alpha': 0.02108740269834527}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:28,347] Trial 1672 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,404] Trial 1673 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,462] Trial 1674 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,525] Trial 1675 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:28,583] Trial 1676 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,640] Trial 1677 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,697] Trial 1678 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,756] Trial 1679 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,814] Trial 1680 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,871] Trial 1681 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,930] Trial 1682 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:28,987] Trial 1683 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,047] Trial 1684 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:29,105] Trial 1685 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,164] Trial 1686 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,227] Trial 1687 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,285] Trial 1688 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,344] Trial 1689 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,525] Trial 1690 finished with value: 0.6971429391101449 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 4, 'subsample': 0.8949525362874197, 'colsample_bynode': 0.6537931839762275, 'reg_alpha': 0.022207340153285657}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:29,584] Trial 1691 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,665] Trial 1692 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:29,726] Trial 1693 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,785] Trial 1694 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:29,978] Trial 1695 finished with value: 0.6970377477575116 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 4, 'subsample': 0.894414489214453, 'colsample_bynode': 0.6528732768321265, 'reg_alpha': 0.02525145771737816}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:30,036] Trial 1696 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,096] Trial 1697 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,156] Trial 1698 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:30,215] Trial 1699 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,273] Trial 1700 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,331] Trial 1701 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,391] Trial 1702 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:30,450] Trial 1703 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,510] Trial 1704 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,570] Trial 1705 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,632] Trial 1706 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,690] Trial 1707 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,750] Trial 1708 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:30,812] Trial 1709 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,871] Trial 1710 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,930] Trial 1711 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:30,988] Trial 1712 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,049] Trial 1713 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:31,110] Trial 1714 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,170] Trial 1715 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,230] Trial 1716 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,288] Trial 1717 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,347] Trial 1718 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,405] Trial 1719 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,465] Trial 1720 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,523] Trial 1721 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,583] Trial 1722 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,643] Trial 1723 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,704] Trial 1724 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,766] Trial 1725 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,826] Trial 1726 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:31,890] Trial 1727 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:31,950] Trial 1728 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,010] Trial 1729 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,071] Trial 1730 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:32,130] Trial 1731 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,190] Trial 1732 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,251] Trial 1733 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:32,313] Trial 1734 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,373] Trial 1735 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,433] Trial 1736 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,495] Trial 1737 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:32,554] Trial 1738 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,613] Trial 1739 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,673] Trial 1740 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,732] Trial 1741 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,793] Trial 1742 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,858] Trial 1743 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:32,921] Trial 1744 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:32,985] Trial 1745 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:33,045] Trial 1746 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,109] Trial 1747 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:33,169] Trial 1748 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,233] Trial 1749 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:33,295] Trial 1750 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,355] Trial 1751 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,415] Trial 1752 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,476] Trial 1753 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,536] Trial 1754 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,598] Trial 1755 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:33,660] Trial 1756 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,720] Trial 1757 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,781] Trial 1758 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,842] Trial 1759 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,902] Trial 1760 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:33,966] Trial 1761 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,033] Trial 1762 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,095] Trial 1763 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,156] Trial 1764 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,217] Trial 1765 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,277] Trial 1766 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,337] Trial 1767 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,397] Trial 1768 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,462] Trial 1769 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:34,524] Trial 1770 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:34,584] Trial 1771 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,645] Trial 1772 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,705] Trial 1773 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,765] Trial 1774 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,832] Trial 1775 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:34,893] Trial 1776 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:34,956] Trial 1777 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,018] Trial 1778 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,081] Trial 1779 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,145] Trial 1780 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,208] Trial 1781 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:35,270] Trial 1782 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,446] Trial 1783 finished with value: 0.6971509081520111 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 4, 'subsample': 0.8952533443536271, 'colsample_bynode': 0.6492016035951818, 'reg_alpha': 0.011045147623562825}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:35,514] Trial 1784 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:35,579] Trial 1785 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:35,642] Trial 1786 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:35,704] Trial 1787 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,764] Trial 1788 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,825] Trial 1789 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,886] Trial 1790 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:35,947] Trial 1791 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,009] Trial 1792 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,069] Trial 1793 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,132] Trial 1794 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:36,194] Trial 1795 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,255] Trial 1796 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,316] Trial 1797 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,381] Trial 1798 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:36,443] Trial 1799 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,507] Trial 1800 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,576] Trial 1801 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,639] Trial 1802 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,702] Trial 1803 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,766] Trial 1804 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,831] Trial 1805 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,896] Trial 1806 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:36,959] Trial 1807 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,021] Trial 1808 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,085] Trial 1809 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,153] Trial 1810 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:37,217] Trial 1811 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,281] Trial 1812 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,350] Trial 1813 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:37,415] Trial 1814 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,479] Trial 1815 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,543] Trial 1816 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,609] Trial 1817 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,676] Trial 1818 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,741] Trial 1819 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,804] Trial 1820 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,868] Trial 1821 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,931] Trial 1822 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:37,998] Trial 1823 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:38,063] Trial 1824 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,128] Trial 1825 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,193] Trial 1826 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,256] Trial 1827 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,319] Trial 1828 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,383] Trial 1829 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,448] Trial 1830 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,513] Trial 1831 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,582] Trial 1832 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:38,647] Trial 1833 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:38,709] Trial 1834 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,777] Trial 1835 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:38,840] Trial 1836 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,905] Trial 1837 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:38,971] Trial 1838 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,037] Trial 1839 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:39,102] Trial 1840 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,165] Trial 1841 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,233] Trial 1842 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:39,297] Trial 1843 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,359] Trial 1844 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,423] Trial 1845 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,485] Trial 1846 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,551] Trial 1847 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:39,616] Trial 1848 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:39,678] Trial 1849 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,742] Trial 1850 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,807] Trial 1851 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,869] Trial 1852 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,933] Trial 1853 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:39,996] Trial 1854 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,061] Trial 1855 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,127] Trial 1856 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,199] Trial 1857 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,272] Trial 1858 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,334] Trial 1859 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,403] Trial 1860 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:40,469] Trial 1861 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,531] Trial 1862 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,730] Trial 1863 finished with value: 0.697130188643159 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 5, 'subsample': 0.8946052431887146, 'colsample_bynode': 0.662529708192995, 'reg_alpha': 0.028368555010471426}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:40,795] Trial 1864 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,860] Trial 1865 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,924] Trial 1866 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:40,989] Trial 1867 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:41,055] Trial 1868 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:41,119] Trial 1869 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,183] Trial 1870 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,245] Trial 1871 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,311] Trial 1872 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,376] Trial 1873 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,443] Trial 1874 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,505] Trial 1875 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,570] Trial 1876 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:41,636] Trial 1877 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,700] Trial 1878 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,767] Trial 1879 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:41,832] Trial 1880 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,895] Trial 1881 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:41,960] Trial 1882 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,029] Trial 1883 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:42,094] Trial 1884 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,161] Trial 1885 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:42,226] Trial 1886 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,294] Trial 1887 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:42,364] Trial 1888 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,428] Trial 1889 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,492] Trial 1890 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,556] Trial 1891 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,622] Trial 1892 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,690] Trial 1893 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,757] Trial 1894 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,823] Trial 1895 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:42,888] Trial 1896 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:42,952] Trial 1897 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,019] Trial 1898 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:43,084] Trial 1899 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,152] Trial 1900 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:43,219] Trial 1901 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,283] Trial 1902 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,348] Trial 1903 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,416] Trial 1904 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:43,480] Trial 1905 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,546] Trial 1906 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,610] Trial 1907 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,675] Trial 1908 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,741] Trial 1909 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,805] Trial 1910 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,871] Trial 1911 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:43,938] Trial 1912 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,003] Trial 1913 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,069] Trial 1914 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,134] Trial 1915 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,198] Trial 1916 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,264] Trial 1917 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:44,329] Trial 1918 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,394] Trial 1919 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,461] Trial 1920 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,655] Trial 1921 finished with value: 0.6971142505594268 and parameters: {'tree_method': 'hist', 'max_depth': 6, 'min_child_weight': 9, 'max_delta_step': 6, 'subsample': 0.8947052803932917, 'colsample_bynode': 0.6593964392593419, 'reg_alpha': 0.04296447102817064}. Best is trial 544 with value: 0.7004994995441708.\n",
      "[I 2024-02-05 13:58:44,721] Trial 1922 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,788] Trial 1923 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:44,856] Trial 1924 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,921] Trial 1925 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:44,987] Trial 1926 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,055] Trial 1927 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:45,120] Trial 1928 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,185] Trial 1929 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,252] Trial 1930 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,320] Trial 1931 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,388] Trial 1932 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:45,454] Trial 1933 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,520] Trial 1934 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,586] Trial 1935 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,651] Trial 1936 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,717] Trial 1937 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,784] Trial 1938 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,851] Trial 1939 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:45,920] Trial 1940 pruned. Trial was pruned at iteration 1.\n",
      "[I 2024-02-05 13:58:45,986] Trial 1941 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,052] Trial 1942 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,118] Trial 1943 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,183] Trial 1944 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,249] Trial 1945 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,320] Trial 1946 pruned. Trial was pruned at iteration 2.\n",
      "[I 2024-02-05 13:58:46,386] Trial 1947 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,454] Trial 1948 pruned. Trial was pruned at iteration 0.\n",
      "[I 2024-02-05 13:58:46,523] Trial 1949 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate ==================================================\n",
      "========================= HyperTuning Results For Fixed Learning Rate = 0.001\n",
      "Best auc Score = 0.7004994995441708\n",
      "Best Boosting Round: 2\n",
      "========== Best Tree Params ==========\n",
      "tree_method : hist\n",
      "max_depth : 6\n",
      "min_child_weight : 10\n",
      "max_delta_step : 8\n",
      "subsample : 0.8933703323758845\n",
      "colsample_bynode : 0.6389055443252935\n",
      "reg_alpha : 0.01639202665760776\n",
      " \n",
      "================================================== Stage 2 - Boosting Parameters ==================================================\n",
      "best scores (AUC , LOGLOSS) = (0.6908649279279855, 0.6177222370838386)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.0001\n",
      "best boosting round: 9999\n",
      "best scores (AUC , LOGLOSS) = (0.7031627533358409, 0.5988051427589927)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.001\n",
      "best boosting round: 4296\n",
      "best scores (AUC , LOGLOSS) = (0.7056937210325328, 0.5977066541625503)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.005\n",
      "best boosting round: 893\n",
      "best scores (AUC , LOGLOSS) = (0.6997456281836322, 0.6002195265769564)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.01\n",
      "best boosting round: 371\n",
      "best scores (AUC , LOGLOSS) = (0.7012342452042306, 0.6176130023829782)\n",
      "boosting params ---------------------------\n",
      "learning rate: 0.1\n",
      "best boosting round: 39\n",
      "      eta       auc   logloss   itr\n",
      "0  0.0001  0.690865  0.617722  9999\n",
      "1  0.0010  0.703163  0.598805  4296\n",
      "2  0.0050  0.705694  0.597707   893\n",
      "3  0.0100  0.699746  0.600220   371\n",
      "4  0.1000  0.701234  0.617613    39\n",
      "Final Empty Net Model ==========================\n",
      "test score against old data (AUC, LOGLOSS) = (0.7164271881308366, 0.5802192315343008)\n",
      "test score against current data (AUC, LOGLOSS) = (0.636001245717845, 0.6422989517475547)\n",
      "test score against current data (AUC, LOGLOSS) = (0.6983937913493243, 0.5948691174575566)\n",
      "parameters ---------------------------\n",
      "tree_method : hist\n",
      "max_depth : 6\n",
      "min_child_weight : 10\n",
      "max_delta_step : 8\n",
      "subsample : 0.8933703323758845\n",
      "colsample_bynode : 0.6389055443252935\n",
      "reg_alpha : 0.01639202665760776\n",
      "learning_rate : 0.005\n",
      "num_boost_round: 893\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=71)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "tic = time.time()\n",
    "while time.time() - tic < 100:\n",
    "    study.optimize(lambda trial: objective(trial, dtrain = en_dtrain, dvalid = en_dvalid, lr = EN_eta), n_trials=1)\n",
    "\n",
    "print('='*50,'Stage 1 - Hypertune Tree Parameters at Fixed Learning Rate', '='*50)\n",
    "print('='*25, f'HyperTuning Results For Fixed Learning Rate = {EN_eta}')\n",
    "print(f'Best {e_m} Score = {study.best_trial.value}')\n",
    "print(f'Best Boosting Round: {study.best_trial.user_attrs[\"best_iteration\"]}')\n",
    "print(\"=\"*10,'Best Tree Params',\"=\"*10)\n",
    "for k, v in study.best_trial.params.items():\n",
    "    print(k, ':', v)\n",
    "\n",
    "#### STAGE 2 ####\n",
    "print(\" \")\n",
    "print('='*50, 'Stage 2 - Boosting Parameters', '='*50)\n",
    "lr_list = []\n",
    "auc_score_list = []\n",
    "logloss_list = []\n",
    "iterations_list = []\n",
    "for i in [0.0001, 0.001, 0.005, 0.01, 0.1]:\n",
    "    low_learning_rate = i\n",
    "    params = {}\n",
    "    params.update(study.best_trial.params)\n",
    "    params['learning_rate'] = i\n",
    "    model_stage2 = xgb.train(params=params, dtrain=en_dtrain, \n",
    "                             num_boost_round=10000,\n",
    "                             evals=[(en_dtrain, 'train'), (en_dvalid, 'valid')],\n",
    "                             early_stopping_rounds=50,\n",
    "                             verbose_eval=0)\n",
    "    \n",
    "    print(f'best scores (AUC , LOGLOSS) = {score_model(model_stage2, en_dvalid)}')\n",
    "    print('boosting params ---------------------------')\n",
    "    print(f'learning rate: {params[\"learning_rate\"]}')\n",
    "    print(f'best boosting round: {model_stage2.best_iteration}')\n",
    "    auc_score, ll_score = score_model(model_stage2, en_dvalid)\n",
    "\n",
    "    lr_list.append(i)\n",
    "    auc_score_list.append(auc_score)\n",
    "    logloss_list.append(ll_score)\n",
    "    iterations_list.append(model_stage2.best_iteration)\n",
    "\n",
    "lr_df = pd.DataFrame({\n",
    "    'eta': lr_list,\n",
    "    'auc': auc_score_list,\n",
    "    'logloss': logloss_list,\n",
    "    'itr': iterations_list\n",
    "})\n",
    "print(lr_df)\n",
    "\n",
    "best_lr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['eta'].iloc[0] \n",
    "best_itr = lr_df[lr_df['auc'] == lr_df['auc'].max()]['itr'].iloc[0] \n",
    "\n",
    "params['learning_rate'] = best_lr\n",
    "en_model_final = xgb.train(params=params, dtrain=en_dtrainvalid, \n",
    "                        num_boost_round=best_itr,\n",
    "                        verbose_eval=0)\n",
    "\n",
    "print('Final Empty Net Model ==========================')\n",
    "print(f'test score against old data (AUC, LOGLOSS) = {score_model(en_model_final, en_dtest)}')\n",
    "print(f'test score against current data (AUC, LOGLOSS) = {score_model(en_model_final, en_dcurrent)}')\n",
    "print(f'test score against current data (AUC, LOGLOSS) = {score_model(en_model_final, en_dtestall)}')\n",
    "print('parameters ---------------------------')\n",
    "for k, v in params.items():\n",
    "    print(k, ':', v)\n",
    "print(f'num_boost_round: {best_itr}')\n",
    "best_en_params = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Model To DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# EV\n",
    "with open('Models/EvenStrength_xG_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(ev_model_final, file)\n",
    "\n",
    "# PP\n",
    "with open('Models/PowerPlay_xG_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(pp_model_final, file)\n",
    "\n",
    "# SH\n",
    "with open('Models/ShortHanded_xG_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(sh_model_final, file)\n",
    "\n",
    "# EN\n",
    "with open('Models/EmptyNet_xG_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(en_model_final, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "with open('Models/EvenStrength_xG_Model.pkl', 'rb') as file:\n",
    "    ev_model_final = pickle.load(file)\n",
    "\n",
    "with open('Models/PowerPlay_xG_Model.pkl', 'rb') as file:\n",
    "    pp_model_final = pickle.load(file)\n",
    "\n",
    "with open('Models/ShortHanded_xG_Model.pkl', 'rb') as file:\n",
    "    sh_model_final = pickle.load(file)\n",
    "\n",
    "with open('Models/EmptyNet_xG_Model.pkl', 'rb') as file:\n",
    "    en_model_final = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 34)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>season</th><th>game_id</th><th>event_idx</th><th>event_angle_change</th><th>event_angle_change_speed</th><th>seconds_since_last</th><th>distance_from_last</th><th>puck_speed_since_last</th><th>pos_F</th><th>pos_D</th><th>pos_G</th><th>hand_R</th><th>hand_L</th><th>event_team_shift_time_diff</th><th>prior_shot_same</th><th>prior_miss_same</th><th>prior_block_same</th><th>prior_shot_opp</th><th>prior_miss_opp</th><th>prior_block_opp</th><th>prior_give_opp</th><th>prior_give_same</th><th>prior_take_opp</th><th>prior_take_same</th><th>prior_hit_opp</th><th>prior_hit_same</th><th>prior_face_win</th><th>prior_face_lose</th><th>off_wing</th><th>is_rebound</th><th>is_post_miss_shot</th><th>is_set_play</th><th>is_rush_play</th><th>is_fast_rush_play</th></tr><tr><td>i32</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i64</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td><td>i32</td></tr></thead><tbody><tr><td>20232024</td><td>2023020001</td><td>22</td><td>2.250969</td><td>0.750323</td><td>3.0</td><td>56.035703</td><td>18.678568</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>20232024</td><td>2023020001</td><td>23</td><td>3.439805</td><td>0.382201</td><td>9.0</td><td>40.496913</td><td>4.499657</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>20232024</td><td>2023020001</td><td>31</td><td>24.387667</td><td>2.217061</td><td>11.0</td><td>120.432554</td><td>10.948414</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>20232024</td><td>2023020001</td><td>47</td><td>25.380754</td><td>0.793149</td><td>32.0</td><td>21.213203</td><td>0.662913</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>20232024</td><td>2023020001</td><td>59</td><td>37.484003</td><td>1.972842</td><td>19.0</td><td>129.799846</td><td>6.831571</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>19</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 34)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┐\n",
       "│ sea ┆ gam ┆ eve ┆ eve ┆ eve ┆ sec ┆ dis ┆ puc ┆ pos ┆ pos ┆ pos ┆ han ┆ han ┆ eve ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ pri ┆ off ┆ is_ ┆ is_ ┆ is_ ┆ is_ ┆ is_ │\n",
       "│ son ┆ e_i ┆ nt_ ┆ nt_ ┆ nt_ ┆ ond ┆ tan ┆ k_s ┆ _F  ┆ _D  ┆ _G  ┆ d_R ┆ d_L ┆ nt_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ or_ ┆ _wi ┆ reb ┆ pos ┆ set ┆ rus ┆ fas │\n",
       "│ --- ┆ d   ┆ idx ┆ ang ┆ ang ┆ s_s ┆ ce_ ┆ pee ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ tea ┆ sho ┆ mis ┆ blo ┆ sho ┆ mis ┆ blo ┆ giv ┆ giv ┆ tak ┆ tak ┆ hit ┆ hit ┆ fac ┆ fac ┆ ng  ┆ oun ┆ t_m ┆ _pl ┆ h_p ┆ t_r │\n",
       "│ i32 ┆ --- ┆ --- ┆ le_ ┆ le_ ┆ inc ┆ fro ┆ d_s ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ m_s ┆ t_s ┆ s_s ┆ ck_ ┆ t_o ┆ s_o ┆ ck_ ┆ e_o ┆ e_s ┆ e_o ┆ e_s ┆ _op ┆ _sa ┆ e_w ┆ e_l ┆ --- ┆ d   ┆ iss ┆ ay  ┆ lay ┆ ush │\n",
       "│     ┆ i32 ┆ i32 ┆ cha ┆ cha ┆ e_l ┆ m_l ┆ inc ┆     ┆     ┆     ┆     ┆     ┆ hif ┆ ame ┆ ame ┆ sam ┆ pp  ┆ pp  ┆ opp ┆ pp  ┆ ame ┆ pp  ┆ ame ┆ p   ┆ me  ┆ in  ┆ ose ┆ i32 ┆ --- ┆ _sh ┆ --- ┆ --- ┆ _pl │\n",
       "│     ┆     ┆     ┆ nge ┆ nge ┆ ast ┆ ast ┆ e_l ┆     ┆     ┆     ┆     ┆     ┆ t_t ┆ --- ┆ --- ┆ e   ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆ --- ┆     ┆ i32 ┆ ot  ┆ i32 ┆ i32 ┆ ay  │\n",
       "│     ┆     ┆     ┆ --- ┆ _sp ┆ --- ┆ --- ┆ ast ┆     ┆     ┆     ┆     ┆     ┆ ime ┆ i32 ┆ i32 ┆ --- ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆ i32 ┆     ┆     ┆ --- ┆     ┆     ┆ --- │\n",
       "│     ┆     ┆     ┆ f64 ┆ eed ┆ f64 ┆ f64 ┆ --- ┆     ┆     ┆     ┆     ┆     ┆ _di ┆     ┆     ┆ i32 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ i32 ┆     ┆     ┆ i32 │\n",
       "│     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆ f64 ┆     ┆     ┆     ┆     ┆     ┆ ff  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆ f64 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ --- ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ i64 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╡\n",
       "│ 202 ┆ 202 ┆ 22  ┆ 2.2 ┆ 0.7 ┆ 3.0 ┆ 56. ┆ 18. ┆ 0   ┆ 1   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
       "│ 320 ┆ 302 ┆     ┆ 509 ┆ 503 ┆     ┆ 035 ┆ 678 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 24  ┆ 000 ┆     ┆ 69  ┆ 23  ┆     ┆ 703 ┆ 568 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 202 ┆ 202 ┆ 23  ┆ 3.4 ┆ 0.3 ┆ 9.0 ┆ 40. ┆ 4.4 ┆ 1   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
       "│ 320 ┆ 302 ┆     ┆ 398 ┆ 822 ┆     ┆ 496 ┆ 996 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 24  ┆ 000 ┆     ┆ 05  ┆ 01  ┆     ┆ 913 ┆ 57  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 202 ┆ 202 ┆ 31  ┆ 24. ┆ 2.2 ┆ 11. ┆ 120 ┆ 10. ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
       "│ 320 ┆ 302 ┆     ┆ 387 ┆ 170 ┆ 0   ┆ .43 ┆ 948 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 24  ┆ 000 ┆     ┆ 667 ┆ 61  ┆     ┆ 255 ┆ 414 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ 1   ┆     ┆     ┆     ┆     ┆ 4   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 202 ┆ 202 ┆ 47  ┆ 25. ┆ 0.7 ┆ 32. ┆ 21. ┆ 0.6 ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
       "│ 320 ┆ 302 ┆     ┆ 380 ┆ 931 ┆ 0   ┆ 213 ┆ 629 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 24  ┆ 000 ┆     ┆ 754 ┆ 49  ┆     ┆ 203 ┆ 13  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 202 ┆ 202 ┆ 59  ┆ 37. ┆ 1.9 ┆ 19. ┆ 129 ┆ 6.8 ┆ 1   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 19  ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   ┆ 0   │\n",
       "│ 320 ┆ 302 ┆     ┆ 484 ┆ 728 ┆ 0   ┆ .79 ┆ 315 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│ 24  ┆ 000 ┆     ┆ 003 ┆ 42  ┆     ┆ 984 ┆ 71  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "│     ┆ 1   ┆     ┆     ┆     ┆     ┆ 6   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┘"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slim_pbp(df):\n",
    "    df = (\n",
    "        df\n",
    "        .select(['season', 'game_id', 'event_idx',\n",
    "               'event_angle_change', 'event_angle_change_speed', 'seconds_since_last', 'distance_from_last',\n",
    "               'puck_speed_since_last','pos_F','pos_D','pos_G','hand_R','hand_L',\n",
    "               'event_team_shift_time_diff',\n",
    "               'prior_shot_same','prior_miss_same','prior_block_same',\n",
    "               'prior_shot_opp','prior_miss_opp','prior_block_opp',\n",
    "               'prior_give_opp','prior_give_same','prior_take_opp','prior_take_same',\n",
    "               'prior_hit_opp', 'prior_hit_same', 'prior_face_win', 'prior_face_lose',\n",
    "               'off_wing', 'is_rebound', 'is_post_miss_shot', 'is_set_play', 'is_rush_play','is_fast_rush_play'])\n",
    "        .filter(pl.col('season') == 20232024)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "BASE_DF = slim_pbp(EV_PBP)\n",
    "for i in [PP_PBP, SH_PBP, EN_PBP]:\n",
    "    BASE_DF = BASE_DF.extend(slim_pbp(i))\n",
    "\n",
    "# Build Prediction DataFrame\n",
    "prediction_df = pl.DataFrame({\n",
    "    'season': pd.concat([ev_df, pp_df, sh_df, en_df])['season'],\n",
    "    'game_id': pd.concat([ev_df, pp_df, sh_df, en_df])['game_id'],\n",
    "    'event_idx': pd.concat([ev_df, pp_df, sh_df, en_df])['event_idx'],\n",
    "    'xG': pl.concat([\n",
    "        pl.Series(ev_model_final.predict(data=ev_dcurrent)),\n",
    "        pl.Series(pp_model_final.predict(data=pp_dcurrent)),\n",
    "        pl.Series(sh_model_final.predict(data=sh_dcurrent)),\n",
    "        pl.Series(en_model_final.predict(data=en_dcurrent))\n",
    "    ])\n",
    "}).sort(['season', 'game_id', 'event_idx'])\n",
    "\n",
    "BASE_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ColumnNotFoundError",
     "evalue": "game_id, event_idx\n\nError originated just after this operation:\nDF [\"game_id\", \"game_date\", \"season\", \"event_idx\"]; PROJECT */103 COLUMNS; SELECTION: \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mColumnNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m Current_PlayByPlay_DF \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[43mCURRENT_DF\u001b[49m\n\u001b[0;32m----> 3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgame_id, event_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m Current_PlayByPlay_DF\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/polars/dataframe/frame.py:6350\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, left_on, right_on, suffix, validate, join_nulls)\u001b[0m\n\u001b[1;32m   6333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, DataFrame):\n\u001b[1;32m   6334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6335\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected `other` join table to be a DataFrame, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6336\u001b[0m     )\n\u001b[1;32m   6338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   6339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   6341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6346\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_nulls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin_nulls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6349\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m-> 6350\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   6351\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/polars/lazyframe/frame.py:1749\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m background:\n\u001b[1;32m   1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InProcessQuery(ldf\u001b[38;5;241m.\u001b[39mcollect_concurrently())\n\u001b[0;32m-> 1749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(ldf\u001b[38;5;241m.\u001b[39mcollect())\n",
      "\u001b[0;31mColumnNotFoundError\u001b[0m: game_id, event_idx\n\nError originated just after this operation:\nDF [\"game_id\", \"game_date\", \"season\", \"event_idx\"]; PROJECT */103 COLUMNS; SELECTION: \"None\""
     ]
    }
   ],
   "source": [
    "Current_PlayByPlay_DF = (\n",
    "    CURRENT_DF\n",
    "    .join(BASE_DF, on = ['season', 'game_id', 'event_idx'], how = 'inner')\n",
    "    .join(prediction_df, on = ['season', 'game_id', 'event_idx'], how = 'inner')\n",
    "    .with_columns('xG', pl.col('xG').fillna(0))\n",
    ")\n",
    "\n",
    "Current_PlayByPlay_DF.head()\n",
    "\n",
    "Current_PlayByPlay_DF.write_parquet('CurrentPBP_WithxG.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a doozy but is super helpful in creating a classification model.\n",
    "\n",
    "2. Train and Fit Model:\n",
    "    - Here I am using a binary classification model (xGBoost Classifier) to create a probability that each Corsi Event (Shot, Missed Shot, Goal) results in a goal.\n",
    "3. Test and Evaluate Model\n",
    "    - Tests conducted on 2022-2024 NHL Play-By-Play Data.\n",
    "    - Evaluation Metrics used are:\n",
    "        - Log Loss\n",
    "        - AUC\n",
    "        - R2\n",
    "        - Confusion Matrix\n",
    "        - Classification Report\n",
    "    - I also want to evaluate most important features based on the three types that xGBoost offers (weight, gain, cover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyize_model(model: xgb.core.Booster, dmat: xgb.core.DMatrix):\n",
    "    \"\"\"\n",
    "    Train and evaluate an XGBoost model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load True and Predict \n",
    "    y_test = dmat.get_label() \n",
    "    y_pred = model.predict(dmat)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    lg_lss = log_loss(y_test, y_pred)\n",
    "    f_fpr, f_tpr, f_thresholds = roc_curve(y_test, y_pred)\n",
    "    f_roc_auc = auc(f_fpr, f_tpr)\n",
    "    f_youdens_j = f_tpr - f_fpr\n",
    "    f_optimal_threshold_index = np.argmax(f_youdens_j)\n",
    "    f_optimal_threshold = f_thresholds[f_optimal_threshold_index]\n",
    "    y_pred_binary = np.where(y_pred >= f_optimal_threshold, 1, 0)\n",
    "\n",
    "    # Plot ROC curves\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Labels\n",
    "    title_label = \"Classification Model - Receiver Operating Characteristic (ROC) Curves\"\n",
    "    # Curves\n",
    "    plt.plot(f_fpr, f_tpr, color='blue', lw=2, label=f'ROC curve (AUC = {f_roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title_label)\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    print('XGBoost Classifier R2 on Test Data: %.3f' % np.round(r2, 2))\n",
    "    print('XGBoost Classifier Log Loss on Test Data: %.3f' % np.round(lg_lss, 3))\n",
    "    print('XGBoost Classifier AUC: %.3f' % np.round(f_roc_auc, 3))\n",
    "    print('XGBoost Classifier Optimal Treshold: %.3f' % np.round(f_optimal_threshold, 3))\n",
    "\n",
    "\n",
    "    print('Confusion Matrix:')\n",
    "    print('-'* 17)\n",
    "    print(confusion_matrix(y_test, y_pred_binary))\n",
    "    print('='*53, '\\n')\n",
    "    print('Classification Report:')\n",
    "    print('-'* 22)\n",
    "    print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_top_features(model, n):\n",
    "    # Get feature importance values for weight, gain, and cover\n",
    "    weight_importance = model.get_booster().get_score(importance_type='weight')\n",
    "    gain_importance = model.get_booster().get_score(importance_type='gain')\n",
    "    cover_importance = model.get_booster().get_score(importance_type='cover')\n",
    "\n",
    "    # Convert feature importance dictionaries to data frames\n",
    "    weight_df = pd.DataFrame(weight_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "    gain_df = pd.DataFrame(gain_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "    cover_df = pd.DataFrame(cover_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "\n",
    "    ## PLOT ##\n",
    "\n",
    "    # Enable LaTex rendering\n",
    "    plt.rcParams['text.usetex'] = False\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(16, 16))\n",
    "    # Define data frames and titles for the subplots\n",
    "    dfs = [weight_df, gain_df, cover_df]\n",
    "    titles = ['Weight Importance', 'Gain Importance', 'Cover Importance']\n",
    "    subtitles = [\"Weight importance represents the number of times a feature appears in a tree across all trees in the model\",\n",
    "                 \"Gain importance represents the average gain of the feature when it's used in trees and measures the improvement in accuracy brought by a feature\",\n",
    "                 \"Cover importance measures the relative quantity of observations concerned with a feature (i.e., the average coverage of the feature when it's used in trees)\"]\n",
    "    for i in range(3):\n",
    "        # Create an axis for each subplot\n",
    "        ax = axs[i]\n",
    "\n",
    "        # Get the data frame and title for the current subplot\n",
    "        df = dfs[i]\n",
    "        title = 'Top '+ str(n) + ' Features - Importance Type: ' + titles[i]\n",
    "        subtitle = subtitles[i]\n",
    "        \n",
    "        # Trim the feature names to 20 characters\n",
    "        df['Feature'] = df['Feature'].str[:30]\n",
    "\n",
    "        # Plot the bar chart for the current data frame\n",
    "        ax.barh(df['Feature'], df['Score'], color='b', align='center')\n",
    "        title_pad = 20  # Increase the pad value to add more space\n",
    "        ax.set_title(title, pad=title_pad)\n",
    "        ax.text(0.5, 1.02, subtitle, fontsize=10, fontstyle = 'italic', verticalalignment='center', horizontalalignment='center', transform=ax.transAxes)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterOptimizer:\n",
    "    \"\"\"Optimizes hyperparameters using Optuna.\"\"\"\n",
    "\n",
    "    def __init__(self, n_startup_trials, n_trials):\n",
    "        \"\"\"\n",
    "        Initialize the HyperparameterOptimizer.\n",
    "\n",
    "        Parameters:\n",
    "        - n_startup_trials (int): Number of initial trials for TPESampler.\n",
    "        - n_trials (int): Total number of trials for optimization.\n",
    "        \"\"\"\n",
    "        self.n_startup_trials = n_startup_trials\n",
    "        self.n_trials = n_trials\n",
    "\n",
    "    def optimize_hyperparameters(self, x_train, y_train, x_test, y_test, type):\n",
    "        def objective(trial):\n",
    "\n",
    "            # Set Max Depth:\n",
    "            if type == 'EV':\n",
    "                md = trial.suggest_int('max_depth', 4, 4)\n",
    "                lr = trial.suggest_float('learning_rate', 0.030, 0.070)\n",
    "                ne = trial.suggest_int('n_estimators', 600, 850)\n",
    "                mcw = trial.suggest_int('min_child_weight', 1, 3)\n",
    "                alph = trial.suggest_int('reg_alpha', 0, 7)\n",
    "                lam = trial.suggest_int('reg_lambda', 0, 7)\n",
    "                gam = trial.suggest_float('gamma', .015, .025)\n",
    "                sed = trial.suggest_int('seed', 87, 87)\n",
    "                mds = trial.suggest_int('max_delta_step', 3, 7)\n",
    "            elif type == 'PP':\n",
    "                md = trial.suggest_int('max_depth', 5, 5)\n",
    "                lr = trial.suggest_float('learning_rate', 0.014, 0.0165)\n",
    "                ne = trial.suggest_int('n_estimators', 550, 750)\n",
    "                mcw = trial.suggest_int('min_child_weight', 2, 5)\n",
    "                alph = trial.suggest_int('reg_alpha', 0, 4)\n",
    "                lam = trial.suggest_int('reg_lambda', 0, 4)\n",
    "                gam = trial.suggest_float('gamma', .004, .03)\n",
    "                sed = trial.suggest_int('seed', 87, 87)\n",
    "                mds = trial.suggest_int('max_delta_step', 0, 5)\n",
    "            elif type == 'SH':\n",
    "                md = trial.suggest_int('max_depth', 4, 4)\n",
    "                lr = trial.suggest_float('learning_rate', 0.021, 0.024)\n",
    "                ne = trial.suggest_int('n_estimators', 350, 450)\n",
    "                mcw = trial.suggest_int('min_child_weight', 0, 3)\n",
    "                alph = trial.suggest_int('reg_alpha', 4, 6)\n",
    "                lam = trial.suggest_int('reg_lambda', 0, 2)\n",
    "                gam = trial.suggest_float('gamma', 0.008, 0.012)\n",
    "                sed = trial.suggest_int('seed', 87, 87)\n",
    "                mds = trial.suggest_int('max_delta_step', 1, 4)\n",
    "            elif type == 'EN':\n",
    "                md = trial.suggest_int('max_depth', 2, 4)\n",
    "                lr = trial.suggest_float('learning_rate', 0.02, 0.04)\n",
    "                ne = trial.suggest_int('n_estimators', 300, 500)\n",
    "                mcw = trial.suggest_float('min_child_weight', 0, 7)\n",
    "                alph = trial.suggest_float('reg_alpha', 0, 2)\n",
    "                lam = trial.suggest_float('reg_lambda', 0, 2)\n",
    "                gam = trial.suggest_float('gamma', 0.00, 0.6)\n",
    "                sed = trial.suggest_int('seed', 87, 87)\n",
    "                mds = trial.suggest_int('max_delta_step', 1, 3)\n",
    "            else:\n",
    "                md = trial.suggest_int('max_depth', 3, 9)\n",
    "                lr = 0.3\n",
    "                ne = trial.suggest_int('n_estimators', 300, 1000)\n",
    "                mcw = trial.suggest_int('min_child_weight', 0, 7)\n",
    "                alph = trial.suggest_int('reg_alpha', 0, 6)\n",
    "                lam = trial.suggest_int('reg_lambda', 0, 6)\n",
    "                gam = trial.suggest_float('gamma', 0.00, 0.6)\n",
    "                sed = trial.suggest_int('seed', 87, 87)\n",
    "                mds = trial.suggest_int('max_delta_step', 5, 5)\n",
    "\n",
    "            param = {\n",
    "                'objective': 'binary:logistic',\n",
    "                'eval_metric': 'logloss',\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.75, 0.85),\n",
    "                'gamma': gam,\n",
    "                'max_depth': md,\n",
    "                'learning_rate': lr,\n",
    "                'min_child_weight': mcw,\n",
    "                'reg_alpha': alph,\n",
    "                'reg_lambda': lam,\n",
    "                'subsample': trial.suggest_float('subsample', 0.8, 0.9),\n",
    "                'n_estimators': ne,\n",
    "                'max_delta_step': mds,\n",
    "                'seed' : sed\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**param)\n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict_proba(x_test)[:, 1]\n",
    "            f_fpr, f_tpr, f_thresholds = roc_curve(y_test, y_pred)\n",
    "            f_roc_auc = auc(f_fpr, f_tpr)\n",
    "            logloss = log_loss(y_test, y_pred)\n",
    "            return logloss\n",
    "        \n",
    "        study = optuna.create_study(direction='minimize', study_name='XGBoost Classification Optimization', \n",
    "                                    sampler=TPESampler(n_startup_trials=self.n_startup_trials))\n",
    "        study.optimize(objective, n_trials=self.n_trials)\n",
    "\n",
    "        print('Best', type,'hyperparameters: %s', study.best_params)\n",
    "        return study.best_params, study.trials_dataframe()\n",
    "\n",
    "class XGBoostTrainer:\n",
    "    \"\"\"Trains an XGBoost model and saves predictions.\"\"\"\n",
    "\n",
    "    def train_and_evaluate_xgboost(self, x_train, y_train, x_test, y_test, best_params):\n",
    "        \"\"\"\n",
    "        Train and evaluate an XGBoost model.\n",
    "\n",
    "        \"\"\"\n",
    "        if best_params == {'colsample_bytree': 1, 'gamma': 0, 'max_depth': 6, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1, 'n_estimators': 250}:\n",
    "            model_lab = \"Baseline xGoal\"\n",
    "        else:\n",
    "            model_lab = \"Optimized xGoal\"\n",
    "\n",
    "        opt_xgb = xgb.XGBClassifier(**best_params)\n",
    "        opt_xgb.fit(x_train, y_train)\n",
    "        y_pred = opt_xgb.predict_proba(x_test)[:, 1]\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        lg_lss = log_loss(y_test, y_pred)\n",
    "        f_fpr, f_tpr, f_thresholds = roc_curve(y_test, y_pred)\n",
    "        f_roc_auc = auc(f_fpr, f_tpr)\n",
    "        f_youdens_j = f_tpr - f_fpr\n",
    "        f_optimal_threshold_index = np.argmax(f_youdens_j)\n",
    "        f_optimal_threshold = f_thresholds[f_optimal_threshold_index]\n",
    "        y_pred_binary = np.where(y_pred >= f_optimal_threshold, 1, 0)\n",
    "\n",
    "        # Plot ROC curves\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "        # Labels\n",
    "        title_label = model_lab + \" Model - Receiver Operating Characteristic (ROC) Curves\"\n",
    "        # Curves\n",
    "        plt.plot(f_fpr, f_tpr, color='blue', lw=2, label=f'ROC curve (AUC = {f_roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(title_label)\n",
    "        plt.legend(loc='lower right')\n",
    "\n",
    "        print(model_lab + ' XGBoost Classifier R2 on Test Data: %.3f' % np.round(r2, 2))\n",
    "        print(model_lab + ' XGBoost Classifier Log Loss on Test Data: %.3f' % np.round(lg_lss, 3))\n",
    "        print(model_lab + ' XGBoost Classifier AUC: %.3f' % np.round(f_roc_auc, 3))\n",
    "        print(model_lab + ' XGBoost Classifier Optimal Treshold: %.3f' % np.round(f_optimal_threshold, 3))\n",
    "\n",
    "\n",
    "        print('Confusion Matrix:')\n",
    "        print('-'* 17)\n",
    "        print(confusion_matrix(y_test, y_pred_binary))\n",
    "        print('='*53, '\\n')\n",
    "        print('Classification Report:')\n",
    "        print('-'* 22)\n",
    "        print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        return opt_xgb, y_pred, lg_lss, f_roc_auc, f_optimal_threshold\n",
    "\n",
    "class Feature_Analysis:\n",
    "    \"\"\"Prints a plot showing the top features sorted by the 3 methods of evaluation\"\"\"\n",
    "\n",
    "    def plot_top_features(self, model, n):\n",
    "        # Get feature importance values for weight, gain, and cover\n",
    "        weight_importance = model.get_booster().get_score(importance_type='weight')\n",
    "        gain_importance = model.get_booster().get_score(importance_type='gain')\n",
    "        cover_importance = model.get_booster().get_score(importance_type='cover')\n",
    "\n",
    "        # Convert feature importance dictionaries to data frames\n",
    "        weight_df = pd.DataFrame(weight_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "        gain_df = pd.DataFrame(gain_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "        cover_df = pd.DataFrame(cover_importance.items(), columns=['Feature', 'Score']).sort_values(by='Score', ascending=False).head(n)\n",
    "\n",
    "        ## PLOT ##\n",
    "\n",
    "        # Enable LaTex rendering\n",
    "        plt.rcParams['text.usetex'] = False\n",
    "\n",
    "        # Create a figure with subplots\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(16, 16))\n",
    "        # Define data frames and titles for the subplots\n",
    "        dfs = [weight_df, gain_df, cover_df]\n",
    "        titles = ['Weight Importance', 'Gain Importance', 'Cover Importance']\n",
    "        subtitles = [\"Weight importance represents the number of times a feature appears in a tree across all trees in the model\",\n",
    "                     \"Gain importance represents the average gain of the feature when it's used in trees and measures the improvement in accuracy brought by a feature\",\n",
    "                     \"Cover importance measures the relative quantity of observations concerned with a feature (i.e., the average coverage of the feature when it's used in trees)\"]\n",
    "        for i in range(3):\n",
    "            # Create an axis for each subplot\n",
    "            ax = axs[i]\n",
    "\n",
    "            # Get the data frame and title for the current subplot\n",
    "            df = dfs[i]\n",
    "            title = 'Top '+ str(n) + ' Features - Importance Type: ' + titles[i]\n",
    "            subtitle = subtitles[i]\n",
    "\n",
    "            # Trim the feature names to 20 characters\n",
    "            df['Feature'] = df['Feature'].str[:30]\n",
    "\n",
    "            # Plot the bar chart for the current data frame\n",
    "            ax.barh(df['Feature'], df['Score'], color='b', align='center')\n",
    "            title_pad = 20  # Increase the pad value to add more space\n",
    "            ax.set_title(title, pad=title_pad)\n",
    "            ax.text(0.5, 1.02, subtitle, fontsize=10, fontstyle = 'italic', verticalalignment='center', horizontalalignment='center', transform=ax.transAxes)\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "        # Adjust spacing between subplots\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *b) Convert Polars To Pandas + Clean Nulls*\n",
    "\n",
    "I am chosing to convert my polars DF to pandas here as the code written in the function above deals with Pandas dataframes. This may be altered in the future to be compatable with a Polars dataframe but for now conversion from Polars to Pandas + cleaning a Pandas dataframe is performative enough to be able to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#= EV_PBP.filter(pl.col('pos_F').is_null()).select('event_player_1_id').unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PD = EV_PBP.to_pandas()\n",
    "PP_PD = PP_PBP.to_pandas()\n",
    "SH_PD = SH_PBP.to_pandas()\n",
    "EN_PD = EN_PBP.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *i) Check and Remove Nulls*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [EV_PD, PP_PD, SH_PD, EN_PD]:\n",
    "    # Get the count of null values in each column\n",
    "    null_counts = df.isnull().sum()\n",
    "    # Filter columns with count > 0\n",
    "    filtered_columns = null_counts[null_counts > 0]\n",
    "    # Show the filtered DataFrame\n",
    "    print(filtered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PD.dropna(how = 'any', inplace = True)\n",
    "PP_PD.dropna(how = 'any', inplace = True)\n",
    "SH_PD.dropna(how = 'any', inplace = True)\n",
    "EN_PD.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = EV_PD.drop('event_idx', axis = 1).corr()\n",
    "\n",
    "# Find the pairs of variables with their absolute correlations\n",
    "correlation_pairs = []\n",
    "threshold = 0.7  # Define your correlation threshold\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        corr_value = correlation_matrix.iloc[i, j]\n",
    "        corr_abs_value = abs(corr_value)\n",
    "        var1 = correlation_matrix.columns[i]\n",
    "        var2 = correlation_matrix.columns[j]\n",
    "\n",
    "        # Change corr_value to \"positive\" or \"negative\"\n",
    "        if corr_value > 0:\n",
    "            corr_value_str = \"Positive\"\n",
    "        elif corr_value < 0:\n",
    "            corr_value_str = \"Negative\"\n",
    "        else:\n",
    "            corr_value_str = \"None\"\n",
    "\n",
    "        correlation_pairs.append([var1, var2, corr_abs_value, corr_value_str])\n",
    "\n",
    "# Create Result DF\n",
    "Correlation_DF = pd.DataFrame(correlation_pairs, columns=['var1', 'var2', 'ABS_Corr_Val', 'Corr_Type'])\n",
    "\n",
    "\n",
    "# Assuming 'var1' and 'var2' represent highly correlated columns\n",
    "High_Corr_DF = Correlation_DF[Correlation_DF['ABS_Corr_Val'] > threshold]  # Filter based on correlation threshold\n",
    "High_Corr_DF = High_Corr_DF.sort_values(by='ABS_Corr_Val', ascending=False)\n",
    "\n",
    "#Goal Correlation\n",
    "Goal_Corr_DF = Correlation_DF[(Correlation_DF['var1'] == 'is_goal') | (Correlation_DF['var2'] == 'is_goal')]\n",
    "\n",
    "Goal_Corr_DF.sort_values(by='ABS_Corr_Val', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Tests - Sample of Non-Current Year Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Even Strength Model - True Sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "ev_train_data = EV_PD[EV_PD['season'] != 20232024].sample(frac=0.8, random_state=87)\n",
    "ev_test_data = EV_PD[EV_PD['season'] != 20232024].drop(ev_train_data.index)\n",
    "\n",
    "# Define the features, target variable, and cols to exclude\n",
    "ev_exclude_cols = ['season', 'game_id', 'event_idx']\n",
    "ev_features = [t_col for t_col in EV_PD.columns if t_col not in ev_exclude_cols and t_col != \"is_goal\"]\n",
    "\n",
    "ev_X_train, ev_y_train = ev_train_data[ev_features], ev_train_data[\"is_goal\"]\n",
    "ev_X_test, ev_y_test = ev_test_data[ev_features], ev_test_data[\"is_goal\"]\n",
    "\n",
    "# Manually Identify BASELINE Params if Session Stops\n",
    "baseline_params = {'colsample_bytree': 1,\n",
    "                   'gamma': 0.15,\n",
    "                   'max_depth': 4,\n",
    "                   'min_child_weight': 3,\n",
    "                   'reg_alpha': 3,\n",
    "                   'reg_lambda': 0,\n",
    "                   'subsample': 1,\n",
    "                   'learning_rate': 0.058,\n",
    "                   'n_estimators': 700}\n",
    "\n",
    "# Train Baseline Model\n",
    "xgboost_trainer = XGBoostTrainer()\n",
    "ev_baseline_model_sample, ev_y_pred_sample, ev_logloss_sample, ev_auc_sample, ev_OT_sample = xgboost_trainer.train_and_evaluate_xgboost(ev_X_train, ev_y_train, ev_X_test, ev_y_test, baseline_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Man-Advantage Model - True Sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "pp_train_data = PP_PD[~PP_PD['season'].isin([20232024])].sample(frac=0.8, random_state=87)\n",
    "pp_test_data = PP_PD[~PP_PD['season'].isin([20232024])].drop(pp_train_data.index)\n",
    "\n",
    "# Define the features, target variable, and cols to exclude\n",
    "pp_exclude_cols = ['season', 'game_id', 'event_idx']\n",
    "pp_features = [t_col for t_col in PP_PD.columns if t_col not in pp_exclude_cols and t_col != \"is_goal\"]\n",
    "\n",
    "pp_X_train, pp_y_train = pp_train_data[pp_features], pp_train_data[\"is_goal\"]\n",
    "pp_X_test, pp_y_test = pp_test_data[pp_features], pp_test_data[\"is_goal\"]\n",
    "\n",
    "# Manually Identify BASELINE Params if Session Stops\n",
    "baseline_params = {'colsample_bytree': 1, 'gamma': 0, 'max_depth': 4, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1, 'n_estimators': 250}\n",
    "\n",
    "# Train Baseline Model\n",
    "xgboost_trainer = XGBoostTrainer()\n",
    "pp_baseline_model_sample, pp_y_pred_sample, pp_logloss_sample, pp_auc_sample, pp_OT_sample = xgboost_trainer.train_and_evaluate_xgboost(pp_X_train, pp_y_train, pp_X_test, pp_y_test, baseline_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Short Handed Model - True Sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "sh_train_data = SH_PD[SH_PD['season'] != 20232024].sample(frac=0.8, random_state=87)\n",
    "sh_test_data = SH_PD[SH_PD['season'] != 20232024].drop(sh_train_data.index)\n",
    "\n",
    "# Define the features, target variable, and cols to exclude\n",
    "sh_exclude_cols = ['season', 'game_id', 'event_idx']\n",
    "sh_features = [t_col for t_col in SH_PD.columns if t_col not in sh_exclude_cols and t_col != \"is_goal\"]\n",
    "\n",
    "sh_X_train, sh_y_train = sh_train_data[sh_features], sh_train_data[\"is_goal\"]\n",
    "sh_X_test, sh_y_test = sh_test_data[sh_features], sh_test_data[\"is_goal\"]\n",
    "\n",
    "# Manually Identify BASELINE Params if Session Stops\n",
    "baseline_params = {'colsample_bytree': 1, 'gamma': 0, 'max_depth': 3, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1, 'n_estimators': 250}\n",
    "\n",
    "# Train Baseline Model\n",
    "xgboost_trainer = XGBoostTrainer()\n",
    "sh_baseline_model_sample, sh_y_pred_sample, sh_logloss_sample, sh_auc_sample, sh_OT_sample = xgboost_trainer.train_and_evaluate_xgboost(sh_X_train, sh_y_train, sh_X_test, sh_y_test, baseline_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Empty Net Model - True Sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "en_train_data = EN_PD[EN_PD['season'] != 20232024].sample(frac=0.8, random_state=87)\n",
    "en_test_data = EN_PD[EN_PD['season'] != 20232024].drop(en_train_data.index)\n",
    "\n",
    "# Define the features, target variable, and cols to exclude\n",
    "en_exclude_cols = ['season', 'game_id', 'event_idx']\n",
    "en_features = [t_col for t_col in EN_PD.columns if t_col not in en_exclude_cols and t_col != \"is_goal\"]\n",
    "\n",
    "en_X_train, en_y_train = en_train_data[en_features], en_train_data[\"is_goal\"]\n",
    "en_X_test, en_y_test = en_test_data[en_features], en_test_data[\"is_goal\"]\n",
    "\n",
    "# Manually Identify BASELINE Params if Session Stops\n",
    "baseline_params = {'colsample_bytree': 1, 'gamma': 0, 'max_depth': 5, 'min_child_weight': 1, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 1, 'n_estimators': 250}\n",
    "\n",
    "# Train Baseline Model\n",
    "xgboost_trainer = XGBoostTrainer()\n",
    "en_baseline_model_sample, en_y_pred_sample, en_logloss_sample, en_auc_sample, en_OT_sample = xgboost_trainer.train_and_evaluate_xgboost(en_X_train, en_y_train, en_X_test, en_y_test, baseline_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune Parameters\n",
    "\n",
    "Here, I want to hypertune my parameters and use the most current data as the test rather than a sample. If hypertuning is able to help the model be more predictive on the most current data (rather than testing against a sample of data that includes 2012-2013 data), then it will likely be more predictive in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize hyperparameters\n",
    "hyperparameter_optimizer = HyperparameterOptimizer(n_startup_trials=10000, n_trials=1000)\n",
    "alt_hyperparameter_optimizer = HyperparameterOptimizer(n_startup_trials=10000, n_trials=100)\n",
    "\n",
    "# EV - Max Depth = 4\n",
    "print(\"Begin Even Strength Hypertuning\")\n",
    "ev_best_params, ev_param_df = alt_hyperparameter_optimizer.optimize_hyperparameters(ev_X_train, ev_y_train, ev_X_test, ev_y_test, type = 'EV')\n",
    "\n",
    "# PP\n",
    "print(\"Begin Man Advantage Hypertuning\")\n",
    "#pp_best_params, pp_param_df = alt_hyperparameter_optimizer.optimize_hyperparameters(pp_X_train, pp_y_train, pp_X_test, pp_y_test, type = 'PP')\n",
    "\n",
    "# SH\n",
    "print(\"Begin Shorthanded Hypertuning\")\n",
    "#sh_best_params, sh_param_df = alt_hyperparameter_optimizer.optimize_hyperparameters(sh_X_train, sh_y_train, sh_X_test, sh_y_test, type = 'SH')\n",
    "\n",
    "# EN\n",
    "print(\"Begin Empty Net Hypertuning\")\n",
    "#en_best_params, en_param_df = hyperparameter_optimizer.optimize_hyperparameters(en_X_train, en_y_train, en_X_test, en_y_test, type = 'EN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_param_df.sort_values('value').head(20)\n",
    "#{'max_depth': 4, 'learning_rate': 0.03310457341378971, 'n_estimators': 324, 'min_child_weight': 0.9206244284355457, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 0.505513194675373, 'seed': 87, 'max_delta_step': 3, 'colsample_bytree': 0.8, 'subsample': 0.8}\n",
    "# 0.594411442774224\n",
    "#ev_param_df.groupby('params_max_depth').mean('value').sort_values(['value'])\n",
    "#en_param_df.groupby('params_max_delta_step').mean('value').sort_values(['value'])\n",
    "#en_param_df[en_param_df['params_max_depth'].isin([2,3,4])].groupby(['params_reg_alpha','params_reg_lambda']).mean('value').sort_values(['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Plotting\n",
    "df = ev_param_df[ev_param_df['params_max_depth'] == 4].sort_values(by='params_learning_rate')\n",
    "plt.scatter(df['params_learning_rate'], df['value'], alpha=0.7)\n",
    "sns.regplot(x='params_learning_rate', y='value', data=df, scatter=False, label='Lowess Smoothed Line')\n",
    "plt.xlabel('params_learning_rate')\n",
    "plt.ylabel('value')\n",
    "plt.title('Line Chart of Value vs params_learning_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Even Strength Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HyperTuned Model\n",
    "xgboost_trainer = XGBoostTrainer()\n",
    "best_ev_model, y_pred_ev, best_ev_logloss, best_ev_auc, best_ev_OT = xgboost_trainer.train_and_evaluate_xgboost(ev_X_train, ev_y_train, ev_X_test, ev_y_test, ev_best_params)\n",
    "\n",
    "# Return Feature Analysis Plot\n",
    "Feature_Analysis().plot_top_features(best_ev_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Man-Advantage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pp_best_params = {'max_depth': 5, 'learning_rate': 0.016415367992596373, 'n_estimators': 716, 'min_child_weight': 5, 'reg_alpha': 2, 'reg_lambda': 1, 'gamma': 0.027577027992315935, 'seed': 87, 'max_delta_step': 5, 'colsample_bytree': 0.8, 'subsample': 0.8}\n",
    "# Train HyperTuned Model\n",
    "best_pp_model, y_pred_pp, best_pp_logloss, best_pp_auc, best_pp_OT = xgboost_trainer.train_and_evaluate_xgboost(pp_X_train, pp_y_train, pp_X_test, pp_y_test, pp_best_params)\n",
    "\n",
    "# Return Feature Analysis Plot\n",
    "print(f\"Best Params: {pp_best_params}\")\n",
    "Feature_Analysis().plot_top_features(best_pp_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Short-Handed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Params #\n",
    "#{'max_depth': 4, 'learning_rate': 0.02270896103337748, 'n_estimators': 411, 'min_child_weight': 2, 'reg_alpha': 4, 'reg_lambda': 0, 'gamma': 0.008800184988203343, 'seed': 87, 'max_delta_step': 3, 'colsample_bytree': 0.8, 'subsample': 0.8}\n",
    "\n",
    "# Train HyperTuned Model\n",
    "best_sh_model, y_pred_sh, best_sh_logloss, best_sh_auc, best_sh_OT = xgboost_trainer.train_and_evaluate_xgboost(sh_X_train, sh_y_train, sh_X_test, sh_y_test, sh_best_params)\n",
    "\n",
    "# Return Feature Analysis Plot\n",
    "print(f\"Best Params: {sh_best_params}\")\n",
    "Feature_Analysis().plot_top_features(best_sh_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Empty Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Parameters (Hard-Code)\n",
    "en_best_params = {'max_depth': 4, 'learning_rate': 0.03310457341378971, 'n_estimators': 324, 'min_child_weight': 0.9206244284355457, 'reg_alpha': 0, 'reg_lambda': 0, 'gamma': 0.505513194675373, 'seed': 87, 'max_delta_step': 3, 'colsample_bytree': 0.9, 'subsample': 0.9}\n",
    "\n",
    "# Train HyperTuned Model\n",
    "best_en_model, y_pred_en, best_en_logloss, best_en_auc, best_en_OT = xgboost_trainer.train_and_evaluate_xgboost(en_X_train, en_y_train, en_X_test, en_y_test, en_best_params)\n",
    "\n",
    "# Return Feature Analysis Plot\n",
    "Feature_Analysis().plot_top_features(best_en_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = pd.DataFrame({\n",
    "    'Strength_Type': ['EV', 'EV', 'PP', 'PP', 'SH', 'SH', 'EN', 'EN'],\n",
    "    'Test_Type': ['Sample', 'Optimized','Sample', 'Optimized','Sample', 'Optimized','Sample', 'Optimized'],\n",
    "    'Log_Loss': [ev_logloss_sample, best_ev_logloss, pp_logloss_sample, best_pp_logloss, sh_logloss_sample, best_sh_logloss, en_logloss_sample, best_en_logloss],\n",
    "    'AUC': [ev_auc_sample, best_ev_auc,  pp_auc_sample, best_pp_auc, sh_auc_sample, best_sh_auc, en_auc_sample, best_en_auc],\n",
    "    'Optimal_Threshold': [ev_OT_sample, best_ev_OT, pp_OT_sample, best_pp_OT, sh_OT_sample, best_sh_OT, en_OT_sample, best_en_OT],\n",
    "})\n",
    "\n",
    "print(analysis_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Apply Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Test Seasons\n",
    "EV_DF = EV_PD[EV_PD['season'] > 2022]\n",
    "PP_DF = PP_PD[PP_PD['season'] > 2022]\n",
    "SH_DF = SH_PD[SH_PD['season'] > 2022]\n",
    "EN_DF = EN_PD[EN_PD['season'] > 2022]\n",
    "\n",
    "## Add xGoals and Model Type\n",
    "#EV_DF['xG'] = y_pred_ev\n",
    "#PP_DF['xG'] = y_pred_pp\n",
    "#SH_DF['xG'] = y_pred_sh\n",
    "#EN_DF['xG'] = y_pred_en\n",
    "#\n",
    "#EV_DF['model_type'] = pd.lit('EV')\n",
    "#PP_DF['model_type'] = pd.lit('PP')\n",
    "#SH_DF['model_type'] = pd.lit('SH')\n",
    "#EN_DF['model_type'] = pd.lit('EN')\n",
    "\n",
    "# Add xGoals and Model Type using assign\n",
    "EV_DF = EV_DF.assign(xG=y_pred_ev, model_type='EV')\n",
    "PP_DF = PP_DF.assign(xG=y_pred_pp, model_type='PP')\n",
    "SH_DF = SH_DF.assign(xG=y_pred_sh, model_type='SH')\n",
    "EN_DF = EN_DF.assign(xG=y_pred_en, model_type='EN', reb_angle_change=0.0, reb_angle_change_speed=0.0).astype({'reb_angle_change': 'float64', 'reb_angle_change_speed': 'float64'})\n",
    "\n",
    "# Select Relevant Features\n",
    "keep_cols = ['season', 'game_id', 'event_idx', 'model_type', 'xG', 'is_goal',\n",
    "             'event_distance', 'event_angle', 'x_abs', 'y_abs',\n",
    "             'is_set_play', 'is_rebound', 'event_angle_change', 'event_angle_change_speed',\n",
    "             'off_wing', 'hand_R', 'hand_L', 'pos_F', 'pos_D', 'pos_G', 'prior_shot_same',\n",
    "             'is_rush_play', 'seconds_since_last', 'puck_speed_since_last']\n",
    "EV_DF = EV_DF[keep_cols]\n",
    "PP_DF = PP_DF[keep_cols]\n",
    "SH_DF = SH_DF[keep_cols]\n",
    "EN_DF = EN_DF[keep_cols]\n",
    "\n",
    "\n",
    "# To Polars\n",
    "EV_DF = pl.DataFrame(EV_DF)\n",
    "PP_DF = pl.DataFrame(PP_DF)\n",
    "SH_DF = pl.DataFrame(SH_DF)\n",
    "EN_DF = pl.DataFrame(EN_DF)\n",
    "\n",
    "# Combine\n",
    "df_list = [EV_DF, PP_DF, SH_DF, EN_DF]\n",
    "\n",
    "PRED = df_list[0]\n",
    "for df in df_list[1:]:\n",
    "    PRED = PRED.extend(df)\n",
    "print(str(PRED.height) + \" Total Shots in Prediction DF\")\n",
    "\n",
    "PBP = sdv.nhl.load_nhl_pbp(seasons=range(2023,2024)).select(nhl_pbp_cols).extend(sdv.nhl.load_nhl_pbp(seasons=range(2024,2025)).select(nhl_pbp_cols))\n",
    "print(\"Max Date:\", PBP['game_date'].str.to_date().max())\n",
    "\n",
    "PBP_xG = PBP.join(PRED, on = ['season','game_id','event_idx'], how= \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results and Analysis DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_xG.head()\n",
    "#PBP_xG['reb_angle_change_speed'].max()\n",
    "\n",
    "## Network X Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "xG_path = \"FinalExpectedGoalsPredictions.parquet\"\n",
    "PBP_xG.write_parquet(\n",
    "    xG_path,\n",
    "    use_pyarrow=True,\n",
    ")\n",
    "\n",
    "#PBP_xG.write_arrow('FinalExpectedGoalsPredictions.csv')\n",
    "analysis_df.to_csv('ModelAccuracyScores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peek_cols = [\"game_date\", 'period', 'game_seconds',\n",
    "             'home_abbreviation', 'away_abbreviation','home_score', 'away_score', 'model_type',\n",
    "             'event_player_1_name', \"event_type\", \"secondary_type\", \"shot_distance\", \"shot_angle\", 'xG']\n",
    "\n",
    "PBP_xG.filter((pl.col('event_type') == 'GOAL') & (pl.col('model_type') == 'EV')).sort('xG', descending=False).select(peek_cols).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## League Standings - Goal Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Schedule\n",
    "\n",
    "#PBP_xG.agg((pl.col('game_date').str.to_date().max()).alias('max_game_date'))\n",
    "print(PBP_xG['game_date'].str.to_date().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_teams = ['TOR', 'DET']\n",
    "pythag_exp = 1.86\n",
    "\n",
    "Def = (\n",
    "    PBP_xG\n",
    "    .with_columns((pl.when(pl.col('event_team_abbr') == pl.col('home_abbreviation'))\n",
    "                     .then(pl.col('away_abbreviation'))\n",
    "                     .otherwise(pl.col('home_abbreviation'))).alias('team'))\n",
    "     .filter(((pl.col('season')==2024)) & (pl.col('season_type') == 'R') & (pl.col('model_type') != 'EN'))\n",
    "     .groupby('team')\n",
    "     .agg([\n",
    "         (pl.col('xG').sum()).alias('xGoals_Against'),\n",
    "         ((pl.when(pl.col('event_type') == 'GOAL')\n",
    "             .then(pl.lit(1)).otherwise(pl.lit(0))).sum())\n",
    "             .alias('Goals_Against')\n",
    "          ])\n",
    "     .with_columns((pl.col('Goals_Against') - pl.col('xGoals_Against')).alias('D_Diff_Over_Under'))\n",
    "     .sort('xGoals_Against', descending = True)\n",
    ")\n",
    "\n",
    "Off = (\n",
    "    PBP_xG\n",
    "    .with_columns(pl.col('event_team_abbr').alias('team'))\n",
    "    .filter(((pl.col('season')==2024)) & (pl.col('season_type') == 'R') & (pl.col('model_type') != 'EN'))\n",
    "    .groupby('team')\n",
    "    .agg([(pl.col('xG').sum()).alias('xGoals_For'),\n",
    "          ((pl.when(pl.col('event_type') == 'GOAL')\n",
    "              .then(pl.lit(1))\n",
    "              .otherwise(pl.lit(0))).sum()).alias('Goals_For')\n",
    "          ])\n",
    "     .with_columns((pl.col('Goals_For') - pl.col('xGoals_For')).alias('O_Diff_Over_Under'))\n",
    "     .sort('xGoals_For', descending = True)\n",
    ")\n",
    "\n",
    "NHL_Stats = (\n",
    "    Off\n",
    "    .join(Def, on = 'team', how = \"inner\")\n",
    "    .with_columns([\n",
    "    (pl.col('xGoals_For') - pl.col('xGoals_Against')).alias('xG_Difference'),\n",
    "    (pl.col('Goals_For') - pl.col('Goals_Against')).alias('G_Difference')\n",
    "     ])\n",
    "     .with_columns(\n",
    "         (pl.col('G_Difference') - (pl.col('xG_Difference') )).alias('Diff_Over_Under'),\n",
    "         ((pl.col('xGoals_For').pow(pythag_exp)) / ((pl.col('xGoals_For').pow(pythag_exp)) + (pl.col('xGoals_Against').pow(pythag_exp)))).alias('xGWin_Pct'),\n",
    "         ((pl.col('Goals_For').pow(pythag_exp)) / ((pl.col('Goals_For').pow(pythag_exp)) + (pl.col('Goals_Against').pow(pythag_exp)))).alias('GWin_Pct')\n",
    "         )\n",
    "     .sort('xGWin_Pct', descending=True)\n",
    ")\n",
    "\n",
    "NHL_Stats.head(32) #.filter(pl.col('team').is_in(bet_teams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Variables\n",
    "date_str = \"2023-11-17\"\n",
    "\n",
    "# Create Predictions\n",
    "sched_link = \"https://api-web.nhle.com/v1/schedule/\"+date_str\n",
    "response = requests.get(sched_link)\n",
    "\n",
    "# Parse the JSON content of the response\n",
    "raw_data = pd.json_normalize(response.json())\n",
    "sched_data = pd.json_normalize(raw_data['gameWeek'][0])\n",
    "\n",
    "# Get Odds\n",
    "odds_data = pd.json_normalize(raw_data['oddsPartners'][0])\n",
    "US_Prov_ID = int(odds_data[odds_data['country'] == 'US']['partnerId'].iloc[0])\n",
    "sched_data = pd.json_normalize(sched_data['games'][0])\n",
    "game_df = sched_data[['id', 'season', 'gameState', 'awayTeam.abbrev', 'homeTeam.abbrev', 'homeTeam.odds', 'awayTeam.odds', 'gameCenterLink']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_dfs = []\n",
    "idx = 0\n",
    "\n",
    "## Existing Game Odds\n",
    "exist_id = [2023020251]\n",
    "exist_home_odds = [ 165]\n",
    "exist_away_odds = [-180]\n",
    "\n",
    "exist_df = pd.DataFrame({\n",
    "    'id': exist_id,\n",
    "    'home_odds': exist_home_odds,\n",
    "    'away_odds': exist_away_odds\n",
    "})\n",
    "\n",
    "\n",
    "for i in game_df['id']:\n",
    "\n",
    "    raw_df = game_df[game_df['id'] == i]\n",
    "\n",
    "    try:\n",
    "        # Load Game Data\n",
    "        home_odds_df = pd.json_normalize(raw_df['homeTeam.odds'][idx])\n",
    "        away_odds_df = pd.json_normalize(raw_df['awayTeam.odds'][idx])\n",
    "\n",
    "        home_odd = home_odds_df[home_odds_df['providerId'] == US_Prov_ID]['value'].iloc[0]\n",
    "        away_odd = away_odds_df[away_odds_df['providerId'] == US_Prov_ID]['value'].iloc[0]\n",
    "\n",
    "        df = raw_df[['id', 'season', 'awayTeam.abbrev', 'homeTeam.abbrev', 'gameState']]\n",
    "        df = df.assign(home_odds=home_odd, away_odds=away_odd, game_date=date_str)\n",
    "\n",
    "        game_dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        # Load Game Data\n",
    "        df = raw_df[raw_df['id'] == i]\n",
    "\n",
    "        home_odd = exist_df[exist_df['id'] == i]['home_odds'].iloc[0]\n",
    "        away_odd = exist_df[exist_df['id'] == i]['away_odds'].iloc[0]\n",
    "\n",
    "        df = raw_df[['id', 'season', 'awayTeam.abbrev', 'homeTeam.abbrev','gameState']]\n",
    "        df = df.assign(home_odds=home_odd, away_odds=away_odd, game_date=date_str).astype({'home_odds': 'float64', 'away_odds': 'float64'})\n",
    "\n",
    "        gme_lab = str(df['awayTeam.abbrev'].iloc[0])+ ' ('+ str(round(away_odd, 0)) + ') @ '+str(df['homeTeam.abbrev'].iloc[0]+ ' ('+ str(round(home_odd, 0)) + ')')\n",
    "\n",
    "        print(f\"{gme_lab} Has Already Started\")\n",
    "\n",
    "        game_dfs.append(df)\n",
    "\n",
    "    # Move To Next Game\n",
    "    idx += 1\n",
    "\n",
    "# Concatenate all DataFrames in the game_dfs list into a single polarsDataFrame\n",
    "result_df = pd.concat(game_dfs, ignore_index=True).astype({'home_odds': 'float64', 'away_odds': 'float64'})\n",
    "result_df = pl.DataFrame(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bet_DF = (\n",
    "    result_df\n",
    "    .join(NHL_Stats.select([(pl.col(col).alias(f'away_{col}')) for col in NHL_Stats.columns]), left_on=['awayTeam.abbrev'], right_on=['away_team'])\n",
    "    .join(NHL_Stats.select([(pl.col(col).alias(f'home_{col}')) for col in NHL_Stats.columns]), left_on=['homeTeam.abbrev'], right_on=['home_team'])\n",
    "    .with_columns([\n",
    "        ((pl.col('home_xGWin_Pct')) * (1 - pl.col('away_xGWin_Pct'))).alias('home_win'),\n",
    "        ((pl.col('away_xGWin_Pct')) * (1 - pl.col('home_xGWin_Pct'))).alias('away_win'),\n",
    "        (pl.when(pl.col('home_odds') < 0).then((-1*(pl.col('home_odds'))) / ((-1*(pl.col('home_odds')) + 100))).otherwise(100 / (pl.col('home_odds') + 100))).alias('home_imp_prob'),\n",
    "        (pl.when(pl.col('away_odds') < 0).then((-1*(pl.col('away_odds'))) / ((-1*(pl.col('away_odds')) + 100))).otherwise(100 / (pl.col('away_odds') + 100))).alias('away_imp_prob')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        ((pl.col('home_win')) / (pl.col('home_win') + pl.col('away_win'))).alias('home_win'),\n",
    "        ((pl.col('away_win')) / (pl.col('home_win') + pl.col('away_win'))).alias('away_win')\n",
    "        \n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.col('home_win') - pl.col('home_imp_prob')).alias('home_xAdvantage'),\n",
    "        (pl.col('away_win') - pl.col('away_imp_prob')).alias('away_xAdvantage')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        (pl.when(pl.col('home_xAdvantage') > pl.col('away_xAdvantage')).then(pl.col('home_xAdvantage')).otherwise(pl.col('away_xAdvantage'))).alias('Advantage'),\n",
    "        (pl.when(pl.col('home_xAdvantage') > pl.col('away_xAdvantage')).then(pl.col('homeTeam.abbrev')).otherwise(pl.col('awayTeam.abbrev'))).alias('Bet_Team')\n",
    "    ])\n",
    "    .rename({\"awayTeam.abbrev\":\"away_team\", \"homeTeam.abbrev\":\"home_team\"})\n",
    "    .select('id', \"game_date\", 'away_team', 'away_odds', 'away_imp_prob', 'away_win', 'home_team','home_odds', 'home_imp_prob', 'home_win', 'Bet_Team', 'Advantage')\n",
    ")\n",
    "\n",
    "Pretty_Bet_DF = (\n",
    "    Bet_DF\n",
    "    .select([\n",
    "        pl.col(\"game_date\").alias('Date'),\n",
    "        pl.col(\"id\").alias(\"Game ID\"),\n",
    "        pl.col(\"away_team\").alias('Away Team'),\n",
    "        pl.col('away_odds').round(0).alias('Away Odds'),\n",
    "        pl.format(\"{}%\", (pl.col('away_imp_prob')*100).round(2)).alias('Away ImpProb'),\n",
    "        pl.format(\"{}%\", (pl.col('away_win')*100).round(2)).alias('Away ExpWin'),\n",
    "        pl.col(\"home_team\").alias('Home Team'),\n",
    "        pl.col('home_odds').round(0).alias('Home Odds'),\n",
    "        pl.format(\"{}%\", (pl.col('home_imp_prob')*100).round(2)).alias('Home ImpProb'),\n",
    "        pl.format(\"{}%\", (pl.col('home_win')*100).round(2)).alias('Home ExpWin'),\n",
    "        pl.col(\"Bet_Team\").alias(\"Bet Team\"),\n",
    "        pl.col(\"Advantage\").alias('AdvNum'),\n",
    "    ])\n",
    "    .with_columns(pl.format(\"{}%\", (pl.col('AdvNum')*100).round(2)).alias('Advantage'))\n",
    "    .sort(\"AdvNum\", descending=True)\n",
    "    .drop('AdvNum')\n",
    ")\n",
    "\n",
    "\n",
    "with pl.Config(tbl_formatting=\"ASCII_FULL\", tbl_hide_column_data_types=True, tbl_hide_dataframe_shape=True) as cfg:\n",
    "    cfg.set_tbl_width_chars(200)\n",
    "    print(Pretty_Bet_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "def shiftedColorMap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n",
    "    '''\n",
    "    Function to offset the \"center\" of a colormap. Useful for\n",
    "    data with a negative min and positive max and you want the\n",
    "    middle of the colormap's dynamic range to be at zero.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "      cmap : The matplotlib colormap to be altered\n",
    "      start : Offset from lowest point in the colormap's range.\n",
    "          Defaults to 0.0 (no lower offset). Should be between\n",
    "          0.0 and `midpoint`.\n",
    "      midpoint : The new center of the colormap. Defaults to \n",
    "          0.5 (no shift). Should be between 0.0 and 1.0. In\n",
    "          general, this should be  1 - vmax / (vmax + abs(vmin))\n",
    "          For example if your data range from -15.0 to +5.0 and\n",
    "          you want the center of the colormap at 0.0, `midpoint`\n",
    "          should be set to  1 - 5/(5 + 15)) or 0.75\n",
    "      stop : Offset from highest point in the colormap's range.\n",
    "          Defaults to 1.0 (no upper offset). Should be between\n",
    "          `midpoint` and 1.0.\n",
    "    '''\n",
    "    cdict = {\n",
    "        'red': [],\n",
    "        'green': [],\n",
    "        'blue': [],\n",
    "        'alpha': []\n",
    "    }\n",
    "\n",
    "    # regular index to compute the colors\n",
    "    reg_index = np.linspace(start, stop, 257)\n",
    "\n",
    "    # shifted index to match the data\n",
    "    shift_index = np.hstack([\n",
    "        np.linspace(0.0, midpoint, 128, endpoint=False), \n",
    "        np.linspace(midpoint, 1.0, 129, endpoint=True)\n",
    "    ])\n",
    "\n",
    "    for ri, si in zip(reg_index, shift_index):\n",
    "        r, g, b, a = cmap(ri)\n",
    "\n",
    "        cdict['red'].append((si, r, r))\n",
    "        cdict['green'].append((si, g, g))\n",
    "        cdict['blue'].append((si, b, b))\n",
    "        cdict['alpha'].append((si, a, a))\n",
    "\n",
    "    newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)\n",
    "    plt.colormaps.register(cmap=newcmap)\n",
    "\n",
    "    return newcmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EV_PBP.filter(pl.col('shot_distance') != pl.col('event_distance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_player = 'Sidney.Crosby'\n",
    "#\n",
    "#plot_data = (\n",
    "#    PBP_xG.filter((pl.col('x_fixed') > 26) & (pl.col('model_type') == 'EV'))\n",
    "#    .with_columns(pl.when(pl.col(\"event_player_1_name\") == tgt_player).then(pl.lit(tgt_player.replace(\".\", \" \"))).otherwise(pl.lit(\"NHL Average\")).alias('Grouping'))\n",
    "#    .with_columns([\n",
    "#        pl.when(pl.col('event_type') == 'GOAL').then(pl.lit(1)).otherwise(pl.lit(0)).alias('Goals'),\n",
    "#        pl.when(pl.col('event_type').is_in(['SHOT', \"MISSED_SHOT\"])).then(pl.lit(1)).otherwise(pl.lit(0)).alias('Shots')\n",
    "#    ])\n",
    "#    .groupby(\"x_fixed\", \"y_fixed\")\n",
    "#    .agg([\n",
    "#        (pl.col('xG').sum()).alias(\"NHL_xG_Pct\"),\n",
    "#        (((pl.col('Goals') == 1).sum()) ).alias(\"Ply_Shot_Pct\")\n",
    "#    ])\n",
    "#    .with_columns([\n",
    "#        ((pl.col(\"NHL_xG_Pct\")) - (pl.col(\"Ply_Shot_Pct\"))).alias(\"Shot_Pct_Diff\")\n",
    "#    ])\n",
    "#    .select([\"x_fixed\", \"y_fixed\", \"Shot_Pct_Diff\"])\n",
    "#    .to_pandas()\n",
    "#)\n",
    "\n",
    "plot_data = sdv.nhl.load_nhl_pbp(seasons=range(2023,2024)).select(nhl_pbp_cols).extend(sdv.nhl.load_nhl_pbp(seasons=range(2024,2025)).select(nhl_pbp_cols))\n",
    "\n",
    "plot_data = (\n",
    "    plot_data\n",
    "    .filter((pl.col('event_type').is_in(fenwick_events)))\n",
    "    .filter(~((pl.col('x_fixed').is_null()) & (pl.col('y_fixed').is_null())))\n",
    "    .filter((pl.col('event_team_type') == 'away') & (pl.col('period') == 2))\n",
    "    .with_columns((pl.lit(1)).alias('is_shot'))\n",
    "    .groupby(\"x_fixed\", \"y_fixed\", 'period')\n",
    "    .agg(pl.col('is_shot').sum().alias('shots'))\n",
    "    .select('x_fixed', 'y_fixed', 'shots', 'period')\n",
    "    .to_pandas()\n",
    ")\n",
    "\n",
    "print(plot_data.period.unique())\n",
    "\n",
    "#plot_data = (\n",
    "#    EV_PBP\n",
    "#    .select('x_fixed', 'y_fixed', 'is_goal')\n",
    "#    .groupby(\"x_fixed\", \"y_fixed\")\n",
    "#    .agg(pl.col('is_goal').count().alias('shots'))\n",
    "#    .to_pandas()\n",
    "#)\n",
    "\n",
    "\n",
    "plot_data.dropna(inplace = True)\n",
    "plot_data.head()\n",
    "\n",
    "rink = NHLRink(rotation=270, net={\"visible\": False})\n",
    "\n",
    "## Define the axis limits\n",
    "x_min, x_max = -100, 100\n",
    "y_min, y_max = -42.5, 42.5\n",
    "\n",
    "#shrunk_cmap = shiftedColorMap(matplotlib.cm.RdYlGn, start=plot_data['Shot_Pct_Diff'].min(), midpoint=0, stop=plot_data['Shot_Pct_Diff'].max(), name = 'NHL Total2')\n",
    "\n",
    "\n",
    "# Create a custom colormap\n",
    "colors = [(1, 0, 0), (1, 1, 1), (0, 1, 0)]  # Red to white to green\n",
    "n_bins = 256\n",
    "cmap_name = \"custom\"\n",
    "#cmap = LinearSegmentedColormap.from_list(cmap_name, colors, N=n_bins)\n",
    "\n",
    "# Modify the colormap to make 0 white\n",
    "#cmap(np.linspace(0, 1, n_bins))\n",
    "#cmap.set_bad('white')\n",
    "\n",
    "\n",
    "\n",
    "## Create a heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "hb = plt.hexbin(plot_data['x_fixed'], plot_data['y_fixed'], C=plot_data['shots'], gridsize=500, cmap=\"bwr\", extent=(plot_data['x_fixed'].min(), plot_data['x_fixed'].max(), plot_data['y_fixed'].min(), plot_data['y_fixed'].max()))\n",
    "cbar = plt.colorbar(hb)\n",
    "cbar.set_label('Shot_Pct_Diff')\n",
    "\n",
    "# Set the axis limits\n",
    "plt.xlim(x_min, x_max)\n",
    "print(\"X Min and Max: \", x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "print(\"Y Min and Max: \", y_min, y_max)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X_Coord')\n",
    "plt.ylabel('Y_Coord')\n",
    "plt.title('2022-2024 NHL Expected Goals by Shot Location')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del shrunk_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hockey_rink import NHLRink\n",
    "\n",
    "# Set Up Data\n",
    "plot_data = (\n",
    "    PBP_xG\n",
    "    .filter(\n",
    "        (pl.col('model_type') == 'EV')\n",
    "    )\n",
    ").to_pandas()\n",
    "\n",
    "fig = plt.plot(figsize=(28,16))\n",
    "rink = NHLRink(rotation=0)\n",
    "rink.draw(display_range=\"ozone\")\n",
    "\n",
    "contour_img = rink.contourf(plot_data.x_abs, plot_data.y_abs, values=plot_data.xG, cmap=\"bwr\", \n",
    "                            plot_range=\"ozone\", binsize=10, levels=50, statistic=\"mean\")\n",
    "plt.colorbar(contour_img, orientation=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PBP_xG.filter(\n",
    "        (pl.col('model_type') == 'EV') &\n",
    "        (pl.col('event_team_abbr') == 'PIT') &\n",
    "        (pl.col('x_abs') > 89) &\n",
    "        (pl.col('is_goal') == 1)\n",
    "    ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "color_map = plt.cm.winter\n",
    "from matplotlib.patches import RegularPolygon\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "# Needed for custom colour mapping!\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Target Player\n",
    "full_name = 'Sidney Crosby'\n",
    "\n",
    "# Load Data\n",
    "filter_var = ''\n",
    "plot_keep_cols = ['event_player_1_name', 'event_player_1_id', 'x_abs', 'y_abs', 'is_goal', 'secondary_tpye', 'is_rebound', '']\n",
    "\n",
    "plot_data = (\n",
    "    PBP_xG\n",
    "    .filter()\n",
    ")\n",
    "\n",
    "\n",
    "# Color Map\n",
    "c = mcolors.ColorConverter().to_rgb()\n",
    "positive_cm = ListedColormap([c(\"#e1e5e5\"),c(\"#d63b36\")])\n",
    "negative_cm = ListedColormap([c(\"#e1e5e5\"),c(\"#d63b36\")])\n",
    "\n",
    "# Set Plot Variables\n",
    "gridsize=30;mincnt=0\n",
    "\n",
    "# Player Data Creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = sdv.nhl.load_nhl_pbp(seasons=range(2023,2024)).select(nhl_pbp_cols).extend(sdv.nhl.load_nhl_pbp(seasons=range(2024,2025)).select(nhl_pbp_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw[['event_type', 'event_player_2_type']].groupby(['event_type', 'event_player_2_type']).agg(pl.col('event_type').count().alias('count'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.filter((pl.col('event_type') == 'GOAL') & (pl.col('empty_net') == True)).height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.filter((pl.col('event_type') == 'MISSED_SHOT') & (pl.col('event_player_2_type') == 'Unknown')).select('event_player_1_id', 'event_player_1_type', 'event_player_2_id', 'event_player_2_type', 'event_goalie_id').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.filter(~pl.col('empty_net').is_null())['event_type'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
